@article{DBLP:journals/mia/GerberNEPDSAE23,
  author       = {Samuel Gerber and
                  Marc Niethammer and
                  Ebrahim Ebrahim and
                  Joseph Piven and
                  Stephen R. Dager and
                  Martin Styner and
                  Stephen R. Aylward and
                  Andinet Enquobahrie},
  title        = {Optimal transport features for morphometric population analysis},
  journal      = {Medical Image Anal.},
  volume       = {84},
  pages        = {102696},
  year         = {2023},
  url          = {https://doi.org/10.1016/j.media.2022.102696},
  doi          = {10.1016/j.media.2022.102696},
  timestamp    = {Sun, 12 Feb 2023 18:49:22 +0100},
  biburl       = {https://dblp.org/rec/journals/mia/GerberNEPDSAE23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract     = {Brain pathologies often manifest as partial or complete loss of tissue. The goal of many neuroimaging studies is to capture the location and amount of tissue changes with respect to a clinical variable of interest, such as disease progression. Morphometric analysis approaches capture local differences in the distribution of tissue or other quantities of interest in relation to a clinical variable. We propose to augment morphometric analysis with an additional feature extraction step based on unbalanced optimal transport. The optimal transport feature extraction step increases statistical power for pathologies that cause spatially dispersed tissue loss, minimizes sensitivity to shifts due to spatial misalignment or differences in brain topology, and separates changes due to volume differences from changes due to tissue location. We demonstrate the proposed optimal transport feature extraction step in the context of a volumetric morphometric analysis of the OASIS-1 study for Alzheimer’s disease. The results demonstrate that the proposed approach can identify tissue changes and differences that are not otherwise measurable.},
  keywords     = {brain,MEDIA}
}

@article{DBLP:journals/corr/abs-2303-06493,
  author       = {Qin Liu and
                  Meng Zheng and
                  Benjamin Planche and
                  Zhongpai Gao and
                  Terrence Chen and
                  Marc Niethammer and
                  Ziyan Wu},
  title        = {Exploring Cycle Consistency Learning in Interactive Volume Segmentation},
  journal      = {CoRR},
  volume       = {abs/2303.06493},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.06493},
  doi          = {10.48550/arXiv.2303.06493},
  eprinttype    = {arXiv},
  eprint       = {2303.06493},
  timestamp    = {Thu, 16 Mar 2023 16:04:57 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2303-06493.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract     = {Interactive volume segmentation can be approached via two decoupled modules: interaction-to-segmentation and segmentation propagation. Given a medical volume, a user first segments a slice (or several slices) via the interaction module and then propagates the segmentation(s) to the remaining slices. The user may repeat this process multiple times until a sufficiently high volume segmentation quality is achieved. However, due to the lack of human correction during propagation, segmentation errors are prone to accumulate in the intermediate slices and may lead to sub-optimal performance. To alleviate this issue, we propose a simple yet effective cycle consistency loss that regularizes an intermediate segmentation by referencing the accurate segmentation in the starting slice. To this end, we introduce a backward segmentation path that propagates the intermediate segmentation back to the starting slice using the same propagation network. With cycle consistency training, the propagation network is better regularized than in standard forward-only training approaches. Evaluation results on challenging benchmarks such as AbdomenCT-1k and OAI-ZIB demonstrate the effectiveness of our method. To the best of our knowledge, we are the first to explore cycle consistency learning in interactive volume segmentation.},
  keywords = {deep learning,segmentation,interactive}
}

@article{DBLP:journals/corr/abs-2303-09234,
  author       = {Yining Jiao and
                  Carlton J. Zdanski and
                  Julia S. Kimbell and
                  Andrew Prince and
                  Cameron Worden and
                  Samuel Kirse and
                  Christopher Rutter and
                  Benjamin Shields and
                  William Dunn and
                  Jisan Mahmud and
                  Marc Niethammer},
  title        = {{NAISR:} {A} 3D Neural Additive Model for Interpretable Shape Representation},
  journal      = {CoRR},
  volume       = {abs/2303.09234},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.09234},
  doi          = {10.48550/arXiv.2303.09234},
  eprinttype    = {arXiv},
  eprint       = {2303.09234},
  timestamp    = {Mon, 20 Mar 2023 15:23:19 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2303-09234.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Deep implicit functions (DIFs) have emerged as a powerful paradigm for many computer vision tasks such as 3D shape reconstruction, generation, registration, completion, editing, and understanding. However, given a set of 3D shapes with associated covariates there is at present no shape representation method which allows to precisely represent the shapes while capturing the individual dependencies on each covariate. Such a method would be of high utility to researchers to discover knowledge hidden in a population of shapes. We propose a 3D Neural Additive Model for Interpretable Shape Representation (NAISR) which describes individual shapes by deforming a shape atlas in accordance to the effect of disentangled covariates. Our approach captures shape population trends and allows for patient-specific predictions through shape transfer. NAISR is the first approach to combine the benefits of deep implicit shape representations with an atlas deforming according to specified covariates. Although our driving problem is the construction of an airway atlas, NAISR is a general approach for modeling, representing, and investigating shape populations. We evaluate NAISR with respect to shape reconstruction, shape disentanglement, shape evolution, and shape transfer for the pediatric upper airway. Our experiments demonstrate that NAISR achieves competitive shape reconstruction performance while retaining interpretability.},
  keywords = {deep learning,shape,interpretability}
}


@inproceedings{DBLP:conf/iccv/GreerKVN21,
  author       = {Hastings Greer and
                  Roland Kwitt and
                  Fran{\c{c}}ois{-}Xavier Vialard and
                  Marc Niethammer},
  title        = {{ICON:} Learning Regular Maps Through Inverse Consistency},
  booktitle    = {2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
                  2021, Montreal, QC, Canada, October 10-17, 2021},
  pages        = {3376--3385},
  publisher    = {{IEEE}},
  year         = {2021},
  url          = {https://drive.google.com/file/d/1kaqRx9DXqB4ksDZ1ztuCKETVN9s8F8lg},
  doi          = {10.1109/ICCV48922.2021.00338},
  timestamp    = {Fri, 11 Mar 2022 10:01:59 +0100},
  biburl       = {https://dblp.org/rec/conf/iccv/GreerKVN21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Learning maps between data samples is fundamental. Applications range from representation learning, image translation and generative modeling, to the estimation of spatial deformations. Such maps relate feature vectors, or map between feature spaces. Well-behaved maps should be regular, which can be imposed explicitly or may emanate from the data itself. We explore what induces regularity for spatial transformations, e.g., when computing image registrations. Classical optimization-based models compute maps between pairs of samples and rely on an appropriate regularizer for well-posedness. Recent deep learning approaches have attempted to avoid using such regularizers altogether by relying on the sample population instead. We explore if it is possible to obtain spatial regularity using an inverse consistency loss only and elucidate what explains map regularity in such a context. We find that deep networks combined with an inverse consistency loss and randomized off-grid interpolation yield well behaved, approximately diffeomorphic, spatial transformations. Despite the simplicity of this approach, our experiments present compelling evidence, on both synthetic and real data, that regular maps can be obtained without carefully tuned explicit regularizers, while achieving competitive registration performance.},
  keywords = {deep learning,knee,registration,ICCV}
}

@inproceedings{DBLP:conf/nips/ShenFLCEEN21,
  author       = {Zhengyang Shen and
                  Jean Feydy and
                  Peirong Liu and
                  Ariel Hern{\'{a}}n Curiale and
                  Rub{\'{e}}n San Jos{\'{e}} Est{\'{e}}par and
                  Ra{\'{u}}l San Jos{\'{e}} Est{\'{e}}par and
                  Marc Niethammer},
  editor       = {Marc'Aurelio Ranzato and
                  Alina Beygelzimer and
                  Yann N. Dauphin and
                  Percy Liang and
                  Jennifer Wortman Vaughan},
  title        = {Accurate Point Cloud Registration with Robust Optimal Transport},
  booktitle    = {Advances in Neural Information Processing Systems 34: Annual Conference
                  on Neural Information Processing Systems 2021, NeurIPS 2021, December
                  6-14, 2021, virtual},
  pages        = {5373--5389},
  year         = {2021},
  url          = {https://drive.google.com/file/d/1gquq0Ha8bDUeXMl03ujYSKbIJzop5KVS},
  timestamp    = {Tue, 03 May 2022 16:20:47 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/ShenFLCEEN21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {This work investigates the use of robust optimal transport (OT) for shape matching. Specifically, we show that recent OT solvers improve both optimization-based and deep learning methods for point cloud registration, boosting accuracy at an affordable computational cost. This manuscript starts with a practical overview of modern OT theory. We then provide solutions to the main difficulties in using this framework for shape matching. Finally, we showcase the performance of transport-enhanced registration models on a wide range of challenging tasks: rigid registration for partial shapes; scene flow estimation on the Kitti dataset; and nonparametric registration of lung vascular trees between inspiration and expiration. Our OT-based methods achieve state-of-the-art results on Kitti and for the challenging lung registration task, both in terms of accuracy and scalability. We also release PVT1010, a new public dataset of 1,010 pairs of lung vascular trees with densely sampled points. This dataset provides a challenging use case for point cloud registration algorithms with highly complex shapes and deformations. Our work demonstrates that robust OT enables fast pre-alignment and fine-tuning for a wide range of registration models, thereby providing a new key method for the computer vision toolbox. Our code and dataset are available online at: https://github.com/uncbiag/robot.},
  keywords = {registration,point cloud,lung,deep learning,NeurIPS}
}

@article{DBLP:journals/corr/abs-2303-10249,
  author       = {Boqi Chen and
                  Marc Niethammer},
  title        = {{MRIS:} {A} Multi-modal Retrieval Approach for Image Synthesis on
                  Diverse Modalities},
  journal      = {CoRR},
  volume       = {abs/2303.10249},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.10249},
  doi          = {10.48550/arXiv.2303.10249},
  eprinttype    = {arXiv},
  eprint       = {2303.10249},
  timestamp    = {Wed, 22 Mar 2023 14:41:36 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2303-10249.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Multiple imaging modalities are often used for disease diagnosis, prediction, or population-based analyses. However, not all modalities might be available due to cost, different study designs, or changes in imaging technology. If the differences between the types of imaging are small, data harmonization approaches can be used; for larger changes, direct image synthesis approaches have been explored. In this paper, we develop an approach based on multi-modal metric learning to synthesize images of diverse modalities. We use metric learning via multi-modal image retrieval, resulting in embeddings that can relate images of different modalities. Given a large image database, the learned image embeddings allow us to use k-nearest neighbor (k-NN) regression for image synthesis. Our driving medical problem is knee osteoarthritis (KOA), but our developed method is general after proper image alignment. We test our approach by synthesizing cartilage thickness maps obtained from 3D magnetic resonance (MR) images using 2D radiographs. Our experiments show that the proposed method outperforms direct image synthesis and that the synthesized thickness maps retain information relevant to downstream tasks such as progression prediction and Kellgren-Lawrence grading (KLG). Our results suggest that retrieval approaches can be used to obtain high-quality and meaningful image synthesis results given large image databases.},
  keywords = {deep learning,embedding,retrieval,knee,MICCAI}
}

@article{DBLP:journals/corr/abs-2305-00067,
  author       = {Nurislam Tursynbek and
                  Marc Niethammer},
  title        = {Unsupervised Discovery of 3D Hierarchical Structure with Generative
                  Diffusion Features},
  journal      = {CoRR},
  volume       = {abs/2305.00067},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.00067},
  doi          = {10.48550/arXiv.2305.00067},
  eprinttype    = {arXiv},
  eprint       = {2305.00067},
  timestamp    = {Thu, 04 May 2023 16:57:18 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-00067.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Inspired by recent findings that generative diffusion models learn semantically meaningful representations, we use them to discover the intrinsic hierarchical structure in biomedical 3D images using unsupervised segmentation. We show that features of diffusion models from different stages of a U-Net-based ladder-like architecture capture different hierarchy levels in 3D biomedical images. We design three losses to train a predictive unsupervised segmentation network that encourages the decomposition of 3D volumes into meaningful nested subvolumes that represent a hierarchy. First, we pretrain 3D diffusion models and use the consistency of their features across subvolumes. Second, we use the visual consistency between subvolumes. Third, we use the invariance to photometric augmentations as a regularizer. Our models achieve better performance than prior unsupervised structure discovery approaches on challenging biologically-inspired synthetic datasets and on a real-world brain tumor MRI dataset.},
  keywords = {deep learning,segmentation,unsupervised,diffusion,MICCAI}
}

@article{DBLP:journals/corr/abs-2305-00087,
  author       = {Hastings Greer and
                  Lin Tian and
                  Fran{\c{c}}ois{-}Xavier Vialard and
                  Roland Kwitt and
                  Sylvain Bouix and
                  Ra{\'{u}}l San Jos{\'{e}} Est{\'{e}}par and
                  Richard Rushmore and
                  Marc Niethammer},
  title        = {Inverse Consistency by Construction for Multistep Deep Registration},
  journal      = {CoRR},
  volume       = {abs/2305.00087},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.00087},
  doi          = {10.48550/arXiv.2305.00087},
  eprinttype    = {arXiv},
  eprint       = {2305.00087},
  timestamp    = {Thu, 04 May 2023 16:57:18 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-00087.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Inverse consistency is a desirable property for image registration. We propose a simple technique to make a neural registration network inverse consistent by construction, as a consequence of its structure, as long as it parameterizes its output transform by a Lie group. We extend this technique to multi-step neural registration by composing many such networks in a way that preserves inverse consistency. This multi-step approach also allows for inverse-consistent coarse to fine registration. We evaluate our technique on synthetic 2-D data and four 3-D medical image registration tasks and obtain excellent registration accuracy while assuring inverse consistency.},
  keywords = {deep learning,registration,inverse consistent}
}

@article{DBLP:journals/corr/abs-2305-03125,
  author       = {Yifeng Shi and
                  Marc Niethammer},
  title        = {Multimodal Understanding Through Correlation Maximization and Minimization},
  journal      = {CoRR},
  volume       = {abs/2305.03125},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.03125},
  doi          = {10.48550/arXiv.2305.03125},
  eprinttype    = {arXiv},
  eprint       = {2305.03125},
  timestamp    = {Wed, 10 May 2023 16:08:41 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-03125.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Multimodal learning has mainly focused on learning large models on, and fusing feature representations from, different modalities for better performances on downstream tasks. In this work, we take a detour from this trend and study the intrinsic nature of multimodal data by asking the following questions: 1) Can we learn more structured latent representations of general multimodal data?; and 2) can we intuitively understand, both mathematically and visually, what the latent representations capture? To answer 1), we propose a general and lightweight framework, Multimodal Understanding Through Correlation Maximization and Minimization (MUCMM), that can be incorporated into any large pre-trained network. MUCMM learns both the common and individual representations. The common representations capture what is common between the modalities; the individual representations capture the unique aspect of the modalities. To answer 2), we propose novel scores that summarize the learned common and individual structures and visualize the score gradients with respect to the input, visually discerning what the different representations capture. We further provide mathematical intuitions of the computed gradients in a linear setting, and demonstrate the effectiveness of our approach through a variety of experiments.},
  keywords = {deep learning,multi modal,interpretability}
}

@article{DBLP:journals/cmbbeiv/Ben-ZikriHFSACN22,
  author       = {Yehuda K. Ben{-}Zikri and
                  Mar{\'{\i}}a Helguera and
                  David Fetzer and
                  David A. Shrier and
                  Stephen R. Aylward and
                  Deepak Chittajallu and
                  Marc Niethammer and
                  Nathan D. Cahill and
                  Cristian A. Linte},
  title        = {A feature-based affine registration method for capturing background
                  lung tissue deformation for ground glass nodule tracking},
  journal      = {Comput. methods Biomech. Biomed. Eng. Imaging Vis.},
  volume       = {10},
  number       = {5},
  pages        = {521--539},
  year         = {2022},
  url          = {https://doi.org/10.1080/21681163.2021.1994471},
  doi          = {10.1080/21681163.2021.1994471},
  timestamp    = {Tue, 06 Dec 2022 13:15:05 +0100},
  biburl       = {https://dblp.org/rec/journals/cmbbeiv/Ben-ZikriHFSACN22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract     = {Apparent changes in lung nodule size assessed via simple image-based measurements from computed tomography (CT) images may be compromised by the effect of the background lung tissue deformation on the nodule, leading to erroneous nodule tracking. We propose a feature-based affine registration method and study its performance vis-a-vis several other registration methods. We implement and test each registration method using a lung- and a lesion-centred region of interest on 10 patient CT datasets featuring 12 nodules. We evaluate each registration method according to the target registration error (TRE) computed across 30–50 homologous fiducial landmarks selected by expert radiologists. Our results show that the proposed feature-based affine lesion-centred registration yielded a 1.11.2 mm TRE, while a Symmetric Normalisation deformable registration yielded a 1.21.2 mm TRE, with a baseline least-square fit of the validation fiducial landmarks of 1.51.2 mm TRE. The proposed feature-based affine registration is computationally efficient, eliminates the need for nodule segmentation, and reduces the susceptibility of artificial deformations. We also conducted a pilot pre-clinical study that showed the proposed featurebased lesion-centred affine registration effectively compensates for the background lung tissue deformation and serves as a reliable baseline registration method prior to assessing lung nodule changes due to disease.},
  keywords     = {registration,lung}
}

@article{DBLP:journals/mia/HuangXSLLNNGNZ22,
  author       = {Chao Huang and
                  Zhenlin Xu and
                  Zhengyang Shen and
                  Tianyou Luo and
                  Tengfei Li and
                  Daniel Nissman and
                  Amanda Nelson and
                  Yvonne Golightly and
                  Marc Niethammer and
                  Hongtu Zhu},
  title        = {{DADP:} Dynamic abnormality detection and progression for longitudinal
                  knee magnetic resonance images from the Osteoarthritis Initiative},
  journal      = {Medical Image Anal.},
  volume       = {77},
  pages        = {102343},
  year         = {2022},
  url          = {https://doi.org/10.1016/j.media.2021.102343},
  doi          = {10.1016/j.media.2021.102343},
  timestamp    = {Wed, 07 Dec 2022 13:34:33 +0100},
  biburl       = {https://dblp.org/rec/journals/mia/HuangXSLLNNGNZ22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract     = {Osteoarthritis (OA) is the most common disabling joint disease. Magnetic resonance (MR) imaging has been commonly used to assess knee joint degeneration due to its distinct advantage in detecting morphologic cartilage changes. Although several statistical methods over conventional radiography have been developed to perform quantitative cartilage analyses, little work has been done capturing the development and progression of cartilage lesions (or abnormal regions) and how they naturally progress. There are two major challenges, including (i) the lack of building spatial-temporal correspondences and correlations in cartilage thickness and (ii) the spatio-temporal heterogeneity in abnormal regions. The goal of this work is to propose a dynamic abnormality detection and progression (DADP) framework for quantitative cartilage analysis, while addressing the two challenges. First, spatial correspondences are established on flattened 2D cartilage thickness maps extracted from 3D knee MR images both across time within each subject and across all subjects. Second, a dynamic functional mixed effects model (DFMEM) is proposed to quantify abnormality progression across time points and subjects, while accounting for the spatio-temporal heterogeneity. We systematically evaluate our DADP using simulations and real data from the Osteoarthritis Initiative (OAI). Our results show that DADP not only effectively detects subject-specific dynamic abnormal regions, but also provides population-level statistical disease mapping and subgroup analysis.},
  keywords     = {knee,MRI,cartilage,MEDIA}
}

@article{DBLP:journals/sadm/WeiN22,
  author       = {Susan Wei and
                  Marc Niethammer},
  title        = {The fairness-accuracy Pareto front},
  journal      = {Stat. Anal. Data Min.},
  volume       = {15},
  number       = {3},
  pages        = {287--302},
  year         = {2022},
  url          = {https://drive.google.com/file/d/1vni9fw5azk7pFof9CSJbBinSqQwHGxlq},
  doi          = {10.1002/sam.11560},
  timestamp    = {Thu, 02 Jun 2022 16:43:02 +0200},
  biburl       = {https://dblp.org/rec/journals/sadm/WeiN22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Algorithmic fairness seeks to identify and correct sources of bias in machine learning algorithms. Confoundingly, ensuring fairness often comes at the cost of accuracy. We provide formal tools in this work for reconciling this fundamental tension in algorithm fairness. Specifically, we put to use the concept of Pareto optimality from multiobjective optimization and seek the fairness‐accuracy Pareto front of a neural network classifier. We demonstrate that many existing algorithmic fairness methods are performing the so‐called linear scalarization scheme, which has severe limitations in recovering Pareto optimal solutions. We instead apply the Chebyshev scalarization scheme which is provably superior theoretically and no more computationally burdensome at recovering Pareto optimal solutions compared to the linear scheme.},
  keywords = {fairness,Pareto front}
}

@inproceedings{DBLP:conf/cvpr/DingN22,
  author       = {Zhipeng Ding and
                  Marc Niethammer},
  title        = {Aladdin: Joint Atlas Building and Diffeomorphic Registration Learning
                  with Pairwise Alignment},
  booktitle    = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2022, New Orleans, LA, USA, June 18-24, 2022},
  pages        = {20752--20761},
  publisher    = {{IEEE}},
  year         = {2022},
  url          = {https://drive.google.com/file/d/1gdceCsBTiSute52GcgIHdf3lh9OkhjQa},
  doi          = {10.1109/CVPR52688.2022.02012},
  timestamp    = {Wed, 05 Oct 2022 16:31:19 +0200},
  biburl       = {https://dblp.org/rec/conf/cvpr/DingN22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Atlas building and image registration are important tasks for medical image analysis. Once one or multiple atlases from an image population have been constructed, commonly (1) images are warped into an atlas space to study intra-subject or inter-subject variations or (2) a possibly probabilistic atlas is warped into image space to assign anatomical labels. Atlas estimation and nonparametric transformations are computationally expensive as they usually require numerical optimization. Additionally, previous approaches for atlas building often define similarity measures between a fuzzy atlas and each individual image, which may cause alignment difficulties because a fuzzy atlas does not exhibit clear anatomical structures in contrast to the individual images. This work explores using a convolutional neural network (CNN) to jointly predict the atlas and a stationary velocity field (SVF) parameterization for
diffeomorphic image registration with respect to the atlas. Our approach does not require affine pre-registrations and utilizes pairwise image alignment losses to increase registration accuracy. We evaluate our model on 3D knee magnetic resonance images (MRI) from the OAI-ZIB dataset. Our results show that the proposed framework achieves better performance than other state-of-the-art image registration algorithms, allows for end-to-end training, and for fast inference at test time.},
keywords = {MRI,atlas,knee,CVPR}
}

@inproceedings{DBLP:conf/cvpr/LiuLAN22,
  author       = {Peirong Liu and
                  Yueh Z. Lee and
                  Stephen R. Aylward and
                  Marc Niethammer},
  title        = {Deep Decomposition for Stochastic Normal-Abnormal Transport},
  booktitle    = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2022, New Orleans, LA, USA, June 18-24, 2022},
  pages        = {18769--18779},
  publisher    = {{IEEE}},
  year         = {2022},
  url          = {https://drive.google.com/file/d/1E64NrDAHZyIXs21CC_qAEPlfTsHGASmU},
  doi          = {10.1109/CVPR52688.2022.01823},
  timestamp    = {Wed, 05 Oct 2022 16:31:19 +0200},
  biburl       = {https://dblp.org/rec/conf/cvpr/LiuLAN22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Advection-diffusion equations describe a large family of natural transport processes, e.g., fluid flow, heat transfer,
and wind transport. They are also used for optical flow and perfusion imaging computations. We develop a machine learning model, D2-SONATA, built upon a stochastic advection-diffusion equation, which predicts the velocity and diffusion fields that drive 2D/3D image time-series of transport. In particular, our proposed model incorporates a model of transport atypicality, which isolates abnormal differences between expected normal transport behavior and the observed transport. In a medical context such a normal-abnormal decomposition can be used, for example, to quantify pathologies. Specifically, our model identifies the advection and diffusion contributions from the transport time-series and simultaneously predicts an anomaly value field to provide a decomposition into normal and abnormal advection and diffusion behavior. To achieve improved estimation performance for the velocity and diffusion-tensor fields underlying the advection-diffusion process and for the estimation of the anomaly fields, we create a 2D/3D anomaly-encoded advection-diffusion simulator, which allows for supervised learning. We further apply our model on a brain perfusion dataset from ischemic stroke patients via transfer learning. Extensive comparisons demonstrate that our model successfully distinguishes stroke lesions (abnormal) from normal brain regions, while reconstructing the underlying velocity and diffusion tensor fields.},
keywords = {perfusion,stroke,CVPR}
}

@inproceedings{DBLP:conf/eccv/LiuZPKCNW22,
  author       = {Qin Liu and
                  Meng Zheng and
                  Benjamin Planche and
                  Srikrishna Karanam and
                  Terrence Chen and
                  Marc Niethammer and
                  Ziyan Wu},
  editor       = {Shai Avidan and
                  Gabriel J. Brostow and
                  Moustapha Ciss{\'{e}} and
                  Giovanni Maria Farinella and
                  Tal Hassner},
  title        = {PseudoClick: Interactive Image Segmentation with Click Imitation},
  booktitle    = {Computer Vision - {ECCV} 2022 - 17th European Conference, Tel Aviv,
                  Israel, October 23-27, 2022, Proceedings, Part {VI}},
  series       = {Lecture Notes in Computer Science},
  volume       = {13666},
  pages        = {728--745},
  publisher    = {Springer},
  year         = {2022},
  url          = {https://arxiv.org/pdf/2207.05282.pdf},
  doi          = {10.1007/978-3-031-20068-7\_42},
  timestamp    = {Mon, 05 Dec 2022 13:35:31 +0100},
  biburl       = {https://dblp.org/rec/conf/eccv/LiuZPKCNW22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {The goal of click-based interactive image segmentation is to obtain precise object segmentation masks with limited user interaction, i.e., by a minimal number of user clicks. Existing methods require users to provide all the clicks: by first inspecting the segmentation mask and then providing points on mislabeled regions, iteratively. We ask the question: can our model directly predict where to click, so as to further reduce the user interaction cost? To this end, we propose PseudoClick, a generic framework that enables existing segmentation networks to propose candidate next clicks. These automatically generated clicks, termed pseudo clicks in this work, serve as an imitation of human clicks to refine the segmentation mask. We build PseudoClick on existing segmentation backbones and show how the click prediction mechanism leads to improved performance. We evaluate PseudoClick on 10 public datasets from different domains and modalities, showing that our model not only outperforms existing approaches but also demonstrates strong generalization capability in cross-domain evaluation. We obtain new state-of-theart results on several popular benchmarks, e.g., on the Pascal dataset, our model significantly outperforms existing state-of-the-art by reducing 12.4\% number of clicks to achieve 85\% IoU.},
  keyword = {deep learning,segmentation,interactive,ECCV}
}

@inproceedings{DBLP:conf/miccai/LiuXJN22,
  author       = {Qin Liu and
                  Zhenlin Xu and
                  Yining Jiao and
                  Marc Niethammer},
  editor       = {Linwei Wang and
                  Qi Dou and
                  P. Thomas Fletcher and
                  Stefanie Speidel and
                  Shuo Li},
  title        = {iSegFormer: Interactive Segmentation via Transformers with Application
                  to 3D Knee {MR} Images},
  booktitle    = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}
                  2022 - 25th International Conference, Singapore, September 18-22,
                  2022, Proceedings, Part {V}},
  series       = {Lecture Notes in Computer Science},
  volume       = {13435},
  pages        = {464--474},
  publisher    = {Springer},
  year         = {2022},
  url          = {https://drive.google.com/file/d/1CwtA_P7m1cwTI1YLRGOEc3LM7oXiJO5m},
  doi          = {10.1007/978-3-031-16443-9\_45},
  timestamp    = {Tue, 13 Dec 2022 14:39:06 +0100},
  biburl       = {https://dblp.org/rec/conf/miccai/LiuXJN22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Interactive image segmentation has been widely applied to obtain high-quality voxel-level labels for medical images. The recent success of Transformers on various vision tasks has paved the road for developing Transformer-based interactive image segmentation approaches. However, these approaches remain unexplored and, in particular, have not been developed for 3D medical image segmentation. To fill this research gap, we investigate Transformer-based interactive image segmentation and its application to 3D medical images. This is a nontrivial task due to two main challenges: 1) limited memory for computationally inefficient Transformers and 2) limited labels for 3D medical images. To tackle the first challenge, we propose iSegFormer, a memory-efficient Transformer that combines a Swin Transformer with a lightweight multilayer perceptron (MLP) decoder. To address the second challenge, we pretrain iSegFormer on large amount of unlabeled datasets and then finetune it with only a limited number of segmented 2D slices. We further propagate the 2D segmentations obtained by iSegFormer to unsegmented slices in 3D images using a pre-existing segmentation propagation model pretrained on videos. We evaluate iSegFormer on the public OAI-ZIB dataset for interactive knee cartilage segmentation. Evaluation results show that iSegFormer outperforms its convolutional neural network (CNN) counterparts on interactive 2D knee cartilage segmentation, with competitive computational efficiency. When propagating the 2D interactive segmentations of 5 slices to other unprocessed slices within the same 3D volume, we achieve 82.2\% Dice score for 3D knee cartilage segmentation. Code is available at https://github.com/uncbiag/iSegFormer.},
  keywords = {MICCAI,deep learning,segmentation,interactive}
}

@inproceedings{DBLP:conf/miccai/TianLEN22,
  author       = {Lin Tian and
                  Yueh Z. Lee and
                  Ra{\'{u}}l San Jos{\'{e}} Est{\'{e}}par and
                  Marc Niethammer},
  editor       = {Linwei Wang and
                  Qi Dou and
                  P. Thomas Fletcher and
                  Stefanie Speidel and
                  Shuo Li},
  title        = {LiftReg: Limited Angle 2D/3D Deformable Registration},
  booktitle    = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}
                  2022 - 25th International Conference, Singapore, September 18-22,
                  2022, Proceedings, Part {VI}},
  series       = {Lecture Notes in Computer Science},
  volume       = {13436},
  pages        = {207--216},
  publisher    = {Springer},
  year         = {2022},
  url          = {https://drive.google.com/file/d/13Dw3RO1ZhF3vtLr9TyJGhJkF7wz8DrjC},
  doi          = {10.1007/978-3-031-16446-0\_20},
  timestamp    = {Tue, 13 Dec 2022 14:39:06 +0100},
  biburl       = {https://dblp.org/rec/conf/miccai/TianLEN22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {We propose LiftReg, a 2D/3D deformable registration approach. LiftReg is a deep registration framework which is trained using sets of digitally reconstructed radiographs (DRR) and computed tomography (CT) image pairs. By using simulated training data, LiftReg can use a high-quality CT-CT image similarity measure, which helps the network to learn a high-quality deformation space. To further improve registration quality and to address the inherent depth ambiguities of very limited angle acquisitions, we propose to use features extracted from the backprojected 2D images and a statistical deformation model. We test our approach on the DirLab lung registration dataset and show that it outperforms an existing learning-based pairwise registration approach.},
  keywords = {tomosynthesis,CT,2D/3D,registration,MICCAI,lung}
}

@inproceedings{DBLP:conf/nips/GrafZRNK22,
  author       = {Florian Graf and
                  Sebastian Zeng and
                  Bastian Rieck and
                  Marc Niethammer and
                  Roland Kwitt},
  title        = {On Measuring Excess Capacity in Neural Networks},
  booktitle    = {NeurIPS},
  year         = {2022},
  url          = {https://drive.google.com/file/d/1O9LlGse4ZDWBEjvBKBDxDfTFfFkRVmRo},
  timestamp    = {Thu, 11 May 2023 17:08:21 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/GrafZRNK22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {We study the excess capacity of deep networks in the context of supervised classification. That is, given a capacity measure of the underlying hypothesis class – in our case, empirical Rademacher complexity – to what extent can we (a priori) constrain this class while retaining an empirical error on a par with the unconstrained regime? To assess excess capacity in modern architectures (such as residual networks), we extend and unify prior Rademacher complexity bounds to accommodate function composition and addition, as well as the structure of convolutions. The capacitydriving terms in our bounds are the Lipschitz constants of the layers and an (2, 1) group norm distance to the initializations of the convolution weights. Experiments on benchmark datasets of varying task difficulty indicate that (1) there is a substantial amount of excess capacity per task, and (2) capacity can be kept at a surprisingly similar level across tasks. Overall, this suggests a notion of compressibility with respect to weight norms, complementary to classic compression via weight pruning. Source code is available at https://github.com/rkwitt/excess_capacity.},
  keywords={deep learning,capacity,generalization,NeurIPS}
}

@inproceedings{DBLP:conf/nips/XuNR22,
  author       = {Zhenlin Xu and
                  Marc Niethammer and
                  Colin Raffel},
  title        = {Compositional Generalization in Unsupervised Compositional Representation
                  Learning: {A} Study on Disentanglement and Emergent Language},
  booktitle    = {NeurIPS},
  year         = {2022},
  url          = {https://arxiv.org/abs/2210.00482},
  timestamp    = {Thu, 11 May 2023 17:08:21 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/XuNR22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Deep learning models struggle with compositional generalization, i.e. the ability to recognize or generate novel combinations of observed elementary concepts. In hopes of enabling compositional generalization, various unsupervised learning algorithms have been proposed with inductive biases that aim to induce compositional structure in learned representations (e.g. disentangled representation and emergent language learning). In this work, we evaluate these unsupervised learning algorithms in terms of how well they enable compositional generalization. Specifically, our evaluation protocol focuses on whether or not it is easy to train a simple model on top of the learned representation that generalizes to new combinations of compositional factors. We systematically study three unsupervised representation learning algorithms - β-VAE, β-TCVAE, and emergent language (EL) autoencoders - on two datasets that allow directly testing compositional generalization. We find that directly using the bottleneck representation with simple models and few labels may lead to worse generalization than using representations from layers before or after the learned representation itself. In addition, we find that the previously proposed metrics for evaluating the levels of compositionality are not correlated with actual compositional generalization in our framework. Surprisingly, we find that increasing pressure to produce a disentangled representation produces representations with worse generalization, while representations from EL models show strong compositional generalization. Taken together, our results shed new light on the compositional generalization behavior of different unsupervised learning algorithms with a new setting to rigorously test this behavior, and suggest the potential benefits of delevoping EL learning algorithms for more generalizable representations.},
  keywords = {deep learning,compositionality,NeurIPS}
}

@article{DBLP:journals/corr/abs-2206-05897,
  author       = {Lin Tian and
                  Hastings Greer and
                  Fran{\c{c}}ois{-}Xavier Vialard and
                  Roland Kwitt and
                  Ra{\'{u}}l San Jos{\'{e}} Est{\'{e}}par and
                  Marc Niethammer},
  title        = {GradICON: Approximate Diffeomorphisms via Gradient Inverse Consistency},
  journal      = {CVPR},
  volume       = {abs/2206.05897},
  year         = {2023},
  url          = {https://drive.google.com/file/d/1j8u5n50knQUxhnHp1OMGEwsl8CX-lODX},
  doi          = {10.48550/arXiv.2206.05897},
  eprinttype    = {arXiv},
  eprint       = {2206.05897},
  timestamp    = {Tue, 21 Mar 2023 21:04:57 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2206-05897.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {We present an approach to learning regular spatial transformations between image pairs in the context of medical image registration. Contrary to optimization-based registration techniques and many modern learning-based methods, we do not directly penalize transformation irregularities but instead promote transformation regularity via an inverse consistency penalty. We use a neural network to predict a map between a source and a target image as well as the map when swapping the source and target images. Different from existing approaches, we compose these two resulting maps and regularize deviations of the Jacobian of this composition from the identity matrix. This regularizer - GradICON - results in much better convergence when training registration models compared to promoting inverse consistency of the composition of maps directly while retaining the desirable implicit regularization effects of the latter. We achieve state-of-the-art registration performance on a variety of real-world medical image datasets using a single set of hyperparameters and a single non-dataset-specific training protocol. Code is available at https://github.com/uncbiag/ICON.},
  keywords = {CVPR,registration,gradient inverse consistency,lung,knee,brain}
}

@inproceedings{DBLP:conf/iccv/DingHLN21,
  author       = {Zhipeng Ding and
                  Xu Han and
                  Peirong Liu and
                  Marc Niethammer},
  title        = {Local Temperature Scaling for Probability Calibration},
  booktitle    = {2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
                  2021, Montreal, QC, Canada, October 10-17, 2021},
  pages        = {6869--6879},
  publisher    = {{IEEE}},
  year         = {2021},
  url          = {https://drive.google.com/file/d/1XDPwmr4iBZaY06OebVhKqwD_ZaARBL8X},
  doi          = {10.1109/ICCV48922.2021.00681},
  timestamp    = {Fri, 11 Mar 2022 10:01:59 +0100},
  biburl       = {https://dblp.org/rec/conf/iccv/DingHLN21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {For semantic segmentation, label probabilities are often uncalibrated as they are typically only the by-product of a segmentation task. Intersection over Union (IoU) and Dice score are often used as criteria for segmentation success, while metrics related to label probabilities are rarely explored. On the other hand, probability calibration approaches have been studied, which aim at matching probability outputs with experimentally observed errors, but they mainly focus on classification tasks, not on semantic segmentation. Thus, we propose a learning-based calibration method that focuses on multi-label semantic segmentation. Specifically, we adopt a tree-like convolution neural network to predict local temperature values for probability calibration. One advantage of our approach is that it does not change prediction accuracy, hence allowing for calibration as a post-processing step. Experiments on the COCO and LPBA40 datasets demonstrate improved calibration performance over different metrics. We also demonstrate the performance of our method for multi-atlas brain segmentation from magnetic resonance images.},
  keywords = {ICCV,probability calibration,segmentation}
}


@article{DBLP:journals/corr/abs-2210-11006,
  author       = {Qin Liu and
                  Zhenlin Xu and
                  Gedas Bertasius and
                  Marc Niethammer},
  title        = {SimpleClick: Interactive Image Segmentation with Simple Vision Transformers},
  journal      = {CoRR},
  volume       = {abs/2210.11006},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2210.11006},
  doi          = {10.48550/arXiv.2210.11006},
  eprinttype    = {arXiv},
  eprint       = {2210.11006},
  timestamp    = {Tue, 25 Oct 2022 14:25:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2210-11006.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Click-based interactive image segmentation aims at extracting objects with a limited user clicking. A hierarchical backbone is the de-facto architecture for current methods. Recently, the plain, non-hierarchical Vision Transformer (ViT) has emerged as a competitive backbone for dense prediction tasks. This design allows the original ViT to be a
foundation model that can be finetuned for downstream tasks without redesigning a hierarchical backbone for pretraining. Although this design is simple and has been proven effective, it has not yet been explored for interactive image segmentation. To fill this gap, we propose SimpleClick, the first interactive segmentation method that leverages a plain backbone. Based on the plain backbone, we introduce a symmetric patch embedding layer that encodes clicks into the backbone with minor modifications to the backbone itself. With the plain backbone pretrained as a masked autoencoder (MAE), SimpleClick achieves state-of-theart performance. Remarkably, our method achieves 4.15 NoC@90 on SBD, improving 21.8\% over the previous best result. Extensive evaluation on medical images demonstrates the generalizability of our method. We further develop an extremely tiny ViT backbone for SimpleClick and provide a detailed computational analysis, highlighting its suitability as a practical annotation tool.},
  keywords = {deep learning,segmentation,interactive}
}

@inproceedings{DBLP:conf/cvpr/LiuTZALN21,
  author       = {Peirong Liu and
                  Lin Tian and
                  Yubo Zhang and
                  Stephen R. Aylward and
                  Yueh Z. Lee and
                  Marc Niethammer},
  title        = {Discovering Hidden Physics Behind Transport Dynamics},
  booktitle    = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
                  2021, virtual, June 19-25, 2021},
  pages        = {10082--10092},
  publisher    = {Computer Vision Foundation / {IEEE}},
  year         = {2021},
  url          = {https://drive.google.com/file/d/1Egl7mcuvgwpE_Owbb8P5h1KrhdRHVYP7},
  doi          = {10.1109/CVPR46437.2021.00995},
  timestamp    = {Tue, 29 Nov 2022 14:53:03 +0100},
  biburl       = {https://dblp.org/rec/conf/cvpr/LiuTZALN21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  abstract = {Transport processes are ubiquitous. They are, for example, at the heart of optical flow approaches; or of perfusion imaging, where blood transport is assessed, most com-
monly by injecting a tracer. An advection-diffusion equation is widely used to describe these transport phenomena. Our goal is estimating the underlying physics of advection-diffusion equations, expressed as velocity and diffusion tensor fields. We propose a learning framework (YETI) building on an auto-encoder structure between 2D and 3D image time-series, which incorporates the advection-diffusion model. To help with identifiability, we develop an advection-diffusion simulator which allows pre-training of our model by supervised learning using the velocity and diffusion tensor fields. Instead of directly learning these velocity and diffusion tensor fields, we introduce representations that assure incompressible flow and symmetric positive semi-definite diffusion fields and demonstrate the additional benefits of these representations on improving estimation accuracy. We further use transfer learning to apply YETI on a public brain magnetic resonance (MR) perfusion dataset of stroke patients and show its ability to successfully distinguish stroke lesions from normal brain regions via the estimated velocity and diffusion tensor fields.},
  keywords = {perfusion,stroke,CVPR}

}

@inproceedings{DBLP:conf/icml/GrafHNK21,
  author    = {Florian Graf and
               Christoph D. Hofer and
               Marc Niethammer and
               Roland Kwitt},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {Dissecting Supervised Constrastive Learning},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {3821--3830},
  publisher = {{PMLR}},
  year      = {2021},
  url       = {http://proceedings.mlr.press/v139/graf21a.html},
  timestamp = {Wed, 14 Jul 2021 15:41:58 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/GrafHNK21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Minimizing cross-entropy over the softmax scores of a linear map composed with a high-capacity encoder is arguably the most popular choice for training neural networks on supervised learning tasks. However, recent works show that one can directly optimize the encoder instead, to obtain equally (or even more) discriminative representations via a supervised variant of a contrastive objective. In this work, we address the question whether there are fundamental differences in the sought-for representation geometry in the output space of the encoder at minimal loss. Specifically, we prove, under mild assumptions, that both losses attain their minimum once the representations of each class collapse to the vertices of a regular simplex, inscribed in a hypersphere. We provide empirical evidence that this configuration is attained in practice and that reaching a close-to-optimal state typically indicates good generalization performance. Yet, the two losses show remarkably different optimization behavior. The number of iterations required to perfectly fit to data scales superlinearly with the amount of randomly flipped labels for the supervised contrastive loss. This is in contrast to the approximately linear scaling previously reported for networks trained with cross-entropy.},
  keywords = {deep learning,contrastive learning,ICML}
}

@inproceedings{DBLP:conf/isbi/DingN21,
  author    = {Zhipeng Ding and
               Marc Niethammer},
  title     = {Votenet++: Registration Refinement For Multi-Atlas Segmentation},
  booktitle = {18th {IEEE} International Symposium on Biomedical Imaging, {ISBI}
               2021, Nice, France, April 13-16, 2021},
  pages     = {275--279},
  publisher = {{IEEE}},
  year      = {2021},
  url       = {https://drive.google.com/file/d/1MWCl3YhQR8qTt-CPmXKkqtg_aoWq33IZ},
  abstract = {Multi-atlas segmentation (MAS) is a popular image segmen- tation technique for medical images. In this work, we improve the performance of MAS by correcting registration errors be- fore label fusion. Specifically, we use a volumetric displace- ment field to refine registrations based on image anatomical appearance and predicted labels. We show the influence of the initial spatial alignment as well as the beneficial effect of using label information for MAS performance. Experiments demonstrate that the proposed refinement approach improves MAS performance on a 3D magnetic resonance dataset of the knee.},
  doi       = {10.1109/ISBI48211.2021.9434031},
  timestamp = {Mon, 31 May 2021 11:40:24 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/DingN21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  keywords = {segmentation,brain,ISBI}
}

@inproceedings{DBLP:conf/iclr/XuLYRN21,
  author    = {Zhenlin Xu and
               Deyi Liu and
               Junlin Yang and
               Colin Raffel and
               Marc Niethammer},
  title     = {Robust and Generalizable Visual Representation Learning via Random
               Convolutions},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=BVSM0x3EDK6},
  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/XuLYRN21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {While successful for various computer vision tasks, deep neural networks have shown to be vulnerable to texture style shifts and small perturbations to which humans are robust. In this work, we show that the robustness of neural networks can be greatly improved through the use of random convolutions as data augmentation. Random convolutions are approximately shape-preserving and may distort local textures. Intuitively, randomized convolutions create an infinite number of new domains with similar global shapes but random local texture. Therefore, we explore using outputs of multi-scale random convolutions as new images or mixing them with the original images during training. When applying a network trained with our approach to unseen domains, our method consistently improves the performance on domain generalization benchmarks and is scalable to ImageNet. In particular, in the challenging scenario of generalizing to the sketch domain in PACS and to ImageNet-Sketch, our method outperforms state-of-art methods by a large margin. More interestingly, our method can benefit downstream tasks by providing a more robust pretrained visual representation.},
   keywords = {deep learning,representation learning,robustness,domain generalization,neural networks,data augmentation,ICLR}
}

@inproceedings{DBLP:conf/aaai/ShiON20,
  author    = {Yifeng Shi and
               Junier Oliva and
               Marc Niethammer},
  title     = {Deep Message Passing on Sets},
  booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2020, The Thirty-Second Innovative Applications of Artificial Intelligence
               Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
               Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
               February 7-12, 2020},
  pages     = {5750--5757},
  publisher = {{AAAI} Press},
  year      = {2020},
  url       = {https://aaai.org/ojs/index.php/AAAI/article/view/6031},
  timestamp = {Thu, 04 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/aaai/ShiON20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Modern methods for learning over graph input data have shown the fruitfulness of accounting for relationships among elements in a collection. However, most methods that learn over set input data use only rudimentary approaches to exploit intra-collection relationships. In this work we introduce Deep Message Passing on Sets (DMPS), a novel method that incorporates relational learning for sets. DMPS not only connects learning on graphs with learning on sets via deep kernel learning, but it also bridges message passing on sets and traditional diffusion dynamics commonly used in denoising models. Based on these connections, we develop two new blocks for relational learning on sets: the set-denoising block and the set-residual block. The former is motivated by the connection between message passing on general graphs and diffusion-based denoising models, whereas the latter is inspired by the well-known residual network. In addition to demonstrating the interpretability of our model by learning the true underlying relational structure experimentally, we also show the effectiveness of our approach on both synthetic and real-world datasets by achieving results that are competitive with or outperform the state-of-the-art. For readers who are interested in the detailed derivations of serveral results that we present in this work, please see the supplementary material at: https://arxiv. org/abs/1909.09877.},
  keywords = {AAAI,deep learning}
}

@inproceedings{DBLP:conf/miccai/MooreMNGA20,
  author    = {Brad T. Moore and
               Sean Montgomery and
               Marc Niethammer and
               Hastings Greer and
               Stephen R. Aylward},
  editor    = {Yipeng Hu and
               Roxane Licandro and
               J. Alison Noble and
               Jana Hutter and
               Stephen R. Aylward and
               Andrew Melbourne and
               Esra Abaci Turk and
               Jordina Torrents{-}Barrena},
  title     = {Automatic Optic Nerve Sheath Measurement in Point-of-Care Ultrasound},
  booktitle = {Medical Ultrasound, and Preterm, Perinatal and Paediatric Image Analysis
               - First International Workshop, {ASMUS} 2020, and 5th International
               Workshop, {PIPPI} 2020, Held in Conjunction with {MICCAI} 2020, Lima,
               Peru, October 4-8, 2020, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {12437},
  pages     = {23--32},
  publisher = {Springer},
  year      = {2020},
  url       = {https://doi.org/10.1007/978-3-030-60334-2\_3},
  doi       = {10.1007/978-3-030-60334-2\_3},
  timestamp = {Wed, 07 Apr 2021 16:01:49 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/MooreMNGA20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Intracranial hypertension associated with traumatic brain injury is a life-threatening condition which requires immediate diagnosis and treatment. The measurement of optic nerve sheath diameter (ONSD), using ultrasonography, has been shown to be a promising, non-invasive predictor of intracranial pressure (ICP). Unfortunately, the reproducibility and accuracy of this measure depends on the expertise of the sonologist- a requirement that limits the broad application of ONSD. Previous work on ONSD measurement has focused on computer-automated annotation of expert-acquired ultrasound taken in a clinical setting. Here, we present a system using a handheld point-of-care ultrasound probe whereby the ONSD is automatically measured without requiring an expert sonographer to acquire the images. We report our results on videos from ocular phantoms with varying ONSDs. We show that our approach accurately measures the ONSD despite the lack of an observer keeping the ONSD in focus or in frame.},
  keywords = {ultrasound,MICCAI}
}

@inproceedings{DBLP:conf/miccai/HanSXBABDN20,
  author    = {Xu Han and
               Zhengyang Shen and
               Zhenlin Xu and
               Spyridon Bakas and
               Hamed Akbari and
               Michel Bilello and
               Christos Davatzikos and
               Marc Niethammer},
  editor    = {Mingxia Liu and
               Pingkun Yan and
               Chunfeng Lian and
               Xiaohuan Cao},
  title     = {A Deep Network for Joint Registration and Reconstruction of Images
               with Pathologies},
  booktitle = {Machine Learning in Medical Imaging - 11th International Workshop,
               {MLMI} 2020, Held in Conjunction with {MICCAI} 2020, Lima, Peru, October
               4, 2020, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {12436},
  pages     = {342--352},
  publisher = {Springer},
  year      = {2020},
  url       = {https://drive.google.com/file/d/1AaLx1KS3QvxAAHsh6qFrxBoMfV5IELUO},
  doi       = {10.1007/978-3-030-59861-7\_35},
  timestamp = {Tue, 06 Oct 2020 16:05:22 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/HanSXBABDN20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Registration of images with pathologies is challenging due to tissue appearance changes and missing correspondences caused by the pathologies. Moreover, mass effects as observed for brain tumors may displace tissue, creating larger deformations over time than what is observed in a healthy brain. Deep learning models have successfully been applied to image registration to offer dramatic speed up and to use surrogate information (e.g., segmentations) during training. However, existing approaches focus on learning registration models using images from healthy patients. They are therefore not designed for the registration of images with strong pathologies for example in the context of brain tumors, and traumatic brain injuries. In this work, we explore a deep learning approach to register images with brain tumors to an atlas. Our model learns an appearance mapping from images with tumors to the atlas, while simultaneously predicting the transformation to atlas space. Using separate decoders, the network disentangles the tumor mass effect from the reconstruction of quasi-normal images. Results on both synthetic and real brain tumor scans show that our approach outperforms cost function masking for registration to the atlas and that reconstructed quasi-normal images can be used for better longitudinal registrations.},
  keywords = {registration,brain,pathology,MICCAI}
}

@inproceedings{DBLP:conf/miccai/GerberN20,
  author    = {Samuel Gerber and
               Marc Niethammer},
  editor    = {Anne L. Martel and
               Purang Abolmaesumi and
               Danail Stoyanov and
               Diana Mateus and
               Maria A. Zuluaga and
               S. Kevin Zhou and
               Daniel Racoceanu and
               Leo Joskowicz},
  title     = {Spatial Component Analysis to Mitigate Multiple Testing in Voxel-Based
               Analysis},
  booktitle = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}
               2020 - 23rd International Conference, Lima, Peru, October 4-8, 2020,
               Proceedings, Part {VII}},
  series    = {Lecture Notes in Computer Science},
  volume    = {12267},
  pages     = {667--677},
  publisher = {Springer},
  year      = {2020},
  url       = {https://doi.org/10.1007/978-3-030-59728-3\_65},
  doi       = {10.1007/978-3-030-59728-3\_65},
  timestamp = {Mon, 26 Apr 2021 14:27:06 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/GerberN20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Voxel-based analysis provides a simple, easy to interpret approach to discover regions correlated with a variable of interest such as for example a pathology indicator. Voxel-based analysis methods perform a statistical test at each voxel and are prone to false positives due to multiple testing, or when corrected for multiple testing may miss regions of interest. Component based approaches, such as principal or independent component analysis provide an approach to mitigate multiple testing, by testing for correlations to projections of the data to the components. We propose a spatially regularized component analysis approach to find components for image data sets that are spatially localized and smooth. We show that the proposed approach leads to components that are easier to interpret and can improve predictive performance when used with linear regression models. We develop an efficient optimization approach using the Grassmannian projection kernel and a randomized SVD. The proposed optimization is capable to deal with data sets to large too fit all at once into memory. We demonstrate the approach with an application to study Alzheimer's disease using over 1200 images from the OASIS-3 data set.},
  keywords = 	 {MICCAI,statistics,brain},
}

@inproceedings{DBLP:conf/miccai/LiuLAN20,
  author    = {Peirong Liu and
               Yueh Z. Lee and
               Stephen R. Aylward and
               Marc Niethammer},
  editor    = {Anne L. Martel and
               Purang Abolmaesumi and
               Danail Stoyanov and
               Diana Mateus and
               Maria A. Zuluaga and
               S. Kevin Zhou and
               Daniel Racoceanu and
               Leo Joskowicz},
  title     = {{PIANO:} Perfusion Imaging via Advection-Diffusion},
  booktitle = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}
               2020 - 23rd International Conference, Lima, Peru, October 4-8, 2020,
               Proceedings, Part {VII}},
  series    = {Lecture Notes in Computer Science},
  volume    = {12267},
  pages     = {688--698},
  publisher = {Springer},
  year      = {2020},
  url       = {https://drive.google.com/file/d/1goRkNQ27N262Fg-arCzCZG_Cx4-pMqYV},
  doi       = {10.1007/978-3-030-59728-3\_67},
  timestamp = {Mon, 26 Apr 2021 14:27:06 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/LiuLAN20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Perfusion imaging (PI) is clinically used to assess strokes and brain tumors. Commonly used PI approaches based on magnetic resonance imaging (MRI) or computed tomography (CT) image the effect of a contrast agent moving through blood vessels and into tissue. Contrast-agent free approaches, for example, based on intravoxel incoherent motion, also exist, but are so far not routinely used clinically. MR or CT perfusion imaging based on contrast agents relies on the estimation of the arterial input function (AIF) to approximately model tissue perfusion, neglecting spatial dependencies. Reliably estimating the AIF is also non-trivial, leading to difficulties with standardizing perfusion measures. In this work we therefore propose a data-assimilation approach (PIANO) which estimates the velocity and diffusion fields of an advection-diffusion model best explaining the contrast dynamics. PIANO accounts for spatial dependencies and neither requires estimating the AIF nor relies on a particular contrast agent bolus shape. Specifically, we propose a convenient parameterization of the estimation problem, a numerical estimation approach, and extensively evaluate PIANO. We demonstrate that PIANO can successfully resolve velocity and diffusion field ambiguities and results in sensitive measures for the assessment of stroke, comparing favorably to conventional measures of perfusion.},
   keywords = {MICCAI,perfusion,brain}
}

@inproceedings{DBLP:conf/miccai/TianPLSALN20,
  author    = {Lin Tian and
               Connor Puett and
               Peirong Liu and
               Zhengyang Shen and
               Stephen R. Aylward and
               Yueh Z. Lee and
               Marc Niethammer},
  editor    = {Anne L. Martel and
               Purang Abolmaesumi and
               Danail Stoyanov and
               Diana Mateus and
               Maria A. Zuluaga and
               S. Kevin Zhou and
               Daniel Racoceanu and
               Leo Joskowicz},
  title     = {Fluid Registration Between Lung {CT} and Stationary Chest Tomosynthesis
               Images},
  booktitle = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}
               2020 - 23rd International Conference, Lima, Peru, October 4-8, 2020,
               Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {12263},
  pages     = {307--317},
  publisher = {Springer},
  year      = {2020},
  doi       = {10.1007/978-3-030-59716-0\_30},
  timestamp = {Mon, 05 Oct 2020 18:46:13 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/TianPLSALN20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  url = {https://drive.google.com/file/d/1-gORB0x9qa8hDpnpLSISXGmb9I6j9SG9},
  abstract = {Registration is widely used in image-guided therapy and image-guided surgery to estimate spatial correspondences between organs of interest between planning and treatment images. However, while high-quality computed tomography (CT) images are often available at planning time, limited angle acquisitions are frequently used during treatment because of radiation concerns or imaging time constraints. This requires algorithms to register CT images based on limited angle acquisitions. We, therefore, formulate a 3D/2D registration approach which infers a 3D deformation based on measured projections and digitally reconstructed radiographs of the CT. Most 3D/2D registration approaches use simple transformation models or require complex mathematical derivations to formulate the underlying optimization problem. Instead, our approach entirely relies on differentiable operations which can be combined with modern computational toolboxes supporting automatic differentiation. This then allows for rapid prototyping, integration with deep neural networks, and to support a variety of transformation models including fluid flow models. We demonstrate our approach for the registration between CT and stationary chest tomosynthesis (sDCT) images and show how it naturally leads to an iterative image reconstruction approach.},
  keywords = {MICCAI,registration,lung,LDDMM}
}

@inproceedings{DBLP:conf/miccai/ShenXON20,
  author    = {Zhengyang Shen and
               Zhenlin Xu and
               Sahin Olut and
               Marc Niethammer},
  editor    = {Anne L. Martel and
               Purang Abolmaesumi and
               Danail Stoyanov and
               Diana Mateus and
               Maria A. Zuluaga and
               S. Kevin Zhou and
               Daniel Racoceanu and
               Leo Joskowicz},
  title     = {Anatomical Data Augmentation via Fluid-Based Image Registration},
  booktitle = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}
               2020 - 23rd International Conference, Lima, Peru, October 4-8, 2020,
               Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {12263},
  pages     = {318--328},
  publisher = {Springer},
  year      = {2020},
  doi       = {10.1007/978-3-030-59716-0\_31},
  timestamp = {Mon, 05 Oct 2020 18:46:13 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/ShenXON20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  url = {https://drive.google.com/file/d/1WzuwW5Hk8LIGEUCfQOrTHle3B1A1LroY},
  abstract = {We introduce a fluid-based image augmentation method for medical image analysis. In contrast to existing methods, our framework generates anatomically meaningful images via interpolation from the geodesic subspace underlying given samples. Our approach consists of three steps: 1) given a source image and a set of target images, we construct a geodesic subspace using the Large Deformation Diffeomorphic Metric Mapping (LDDMM) model; 2) we sample transformations from the resulting geodesic subspace; 3) we obtain deformed images and segmentations via interpolation. Experiments on brain (LPBA) and knee (OAI) data illustrate the performance of our approach on two tasks: 1) data augmentation during training and testing for image segmentation; 2) one-shot learning for single atlas image segmentation. We demonstrate that our approach generates anatomically meaningful data and improves performance on these tasks over competing approaches.},
  keywords = {MICCAI,registration,segmentation,brain,knee,LDDMM}
}

@inproceedings{DBLP:conf/eccv/OlutSXGN20,
  author    = {Sahin Olut and
               Zhengyang Shen and
               Zhenlin Xu and
               Samuel Gerber and
               Marc Niethammer},
  editor    = {Andrea Vedaldi and
               Horst Bischof and
               Thomas Brox and
               Jan{-}Michael Frahm},
  title     = {Adversarial Data Augmentation via Deformation Statistics},
  booktitle = {Computer Vision - {ECCV} 2020 - 16th European Conference, Glasgow,
               UK, August 23-28, 2020, Proceedings, Part {XXIX}},
  series    = {Lecture Notes in Computer Science},
  volume    = {12374},
  pages     = {643--659},
  publisher = {Springer},
  year      = {2020},
  url       = {https://doi.org/10.1007/978-3-030-58526-6\_38},
  doi       = {10.1007/978-3-030-58526-6\_38},
  timestamp = {Wed, 07 Oct 2020 19:50:12 +0200},
  biburl    = {https://dblp.org/rec/conf/eccv/OlutSXGN20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Deep learning models have been successful in computer vision and medical image analysis. However, training these models frequently requires large labeled image sets whose creation is often very time and labor intensive, for example, in the context of 3D segmentations. Approaches capable of training deep segmentation networks with a limited number of labeled samples are therefore highly desirable. Data augmentation or semi-supervised approaches are commonly used to cope with limited labeled training data. However, the augmentation strategies for many existing approaches are either hand-engineered or require computationally demanding searches. To that end, we explore an augmentation strategy which builds statistical deformation models from unlabeled data via principal component analysis and uses the resulting statistical deformation space to augment the labeled training samples. Specifically, we obtain transformations via deep registration models. This allows for an intuitive control over plausible deformation magnitudes via the statistical model and, if combined with an appropriate deformation model, yields spatially regular transformations. To optimally augment a dataset we use an adversarial strategy integrated into our statistical deformation model. We demonstrate the effectiveness of our approach for the segmentation of knee cartilage from 3D magnetic resonance images. We show favorable performance to state-of-the-art augmentation approaches.},
    keywords = {ECCV,registration,segmentation,knee,statistics,deep learning}
}

@inproceedings{DBLP:conf/isbi/DingHN20,
  author    = {Zhipeng Ding and
               Xu Han and
               Marc Niethammer},
  title     = {Votenet+: An Improved Deep Learning Label Fusion Method for Multi-Atlas
               Segmentation},
  booktitle = {17th {IEEE} International Symposium on Biomedical Imaging, {ISBI}
               2020, Iowa City, IA, USA, April 3-7, 2020},
  pages     = {363--367},
  publisher = {{IEEE}},
  year      = {2020},
  url       = {https://drive.google.com/file/d/17wMnHNosMbFjYhu4TuNd8zmbXtCA2398},
  doi       = {10.1109/ISBI45749.2020.9098493},
  timestamp = {Sun, 07 Jun 2020 18:48:26 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/DingHN20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this work, we improve the performance of multi-atlas segmentation (MAS) by integrating the recently proposed VoteNet model with the joint label fusion (JLF) approach. Specifically, we first illustrate that using a deep convolutional neural network to predict atlas probabilities can better distinguish correct atlas labels from incorrect ones than relying on image intensity difference as is typical in JLF. Motivated by this finding, we propose VoteNet+, an improved deep network to locally predict the probability of an atlas label to differ from the label of the target image. Furthermore, we show that JLF is more suitable for the VoteNet framework as a label fusion method than plurality voting. Lastly, we use Platt scaling to calibrate the probabilities of our new model. Results on LPBA40 3D MR brain images show that our proposed method can achieve better performance than VoteNet.},
  keywords = {ISBI,deep learning,segmentation,registration,brain}
}

@inproceedings{DBLP:conf/icml/HoferGNK20,
  author    = {Christoph D. Hofer and
               Florian Graf and
               Marc Niethammer and
               Roland Kwitt},
  title     = {Topologically Densified Distributions},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning,
               {ICML} 2020, 13-18 July 2020, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {119},
  pages     = {4304--4313},
  publisher = {{PMLR}},
  year      = {2020},
  url       = {http://proceedings.mlr.press/v119/hofer20a.html},
  timestamp = {Tue, 15 Dec 2020 17:40:19 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/HoferGNK20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We study regularization in the context of small sample-size learning with over-parameterized neural networks. Specifically, we shift focus from architectural properties, such as norms on the network weights, to properties of the internal representations before a linear classifier. Specifically, we impose a topological constraint on samples drawn from the probability measure induced in that space. This provably leads to mass concentration effects around the representations of training instances, ie, a property beneficial for generalization. By leveraging previous work to impose topological constraints in a neural network setting, we provide empirical evidence (across various vision benchmarks) to support our claim for better generalization.},
  keywords={ICML,deep learning,topology}
}

@article{DBLP:journals/corr/abs-2006-04259,
  author    = {Yifeng Shi and
               Christopher M. Bender and
               Junier B. Oliva and
               Marc Niethammer},
  title     = {Deep Goal-Oriented Clustering},
  journal   = {CoRR},
  volume    = {abs/2006.04259},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.04259},
  archivePrefix = {arXiv},
  eprint    = {2006.04259},
  timestamp = {Fri, 12 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-04259.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Clustering and prediction are two primary tasks in the fields of unsupervised and supervised learning, respectively. Although much of the recent advances in machine learning have been centered around those two tasks, the interdependent, mutually beneficial relationship between them is rarely explored. One could reasonably expect appropriately clustering the data would aid the downstream prediction task and, conversely, a better prediction performance for the downstream task could potentially inform a more appropriate clustering strategy. In this work, we focus on the latter part of this mutually beneficial relationship. To this end, we introduce Deep Goal-Oriented Clustering (DGC), a probabilistic framework that clusters the data by jointly using supervision via side-information and unsupervised modeling of the inherent data structure in an end-to-end fashion. We show the effectiveness of our model on a range of datasets by achieving prediction accuracies comparable to the state-of-the-art, while, more importantly in our setting, simultaneously learning congruent clustering strategies.},
  keywords = {deep learning,clustering}
}

@inproceedings{DBLP:conf/nips/VialardKWN20,
  author    = {Fran{\c{c}}ois{-}Xavier Vialard and
               Roland Kwitt and
               Susan Wei and
               Marc Niethammer},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {A shooting formulation of deep learning},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/89562dccfeb1d0394b9ae7e09544dc70-Abstract.html},
  timestamp = {Tue, 19 Jan 2021 15:56:51 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/VialardKWN20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Continuous-depth neural networks can be viewed as deep limits of discrete neural networks whose dynamics resemble a discretization of an ordinary differential equation (ODE). Although important steps have been taken to realize the advantages of such continuous formulations, most current techniques are not truly continuous-depth as they assume identical layers. Indeed, existing works throw into relief the myriad difficulties presented by an infinite-dimensional parameter space in learning a continuous-depth neural ODE. To this end, we introduce a shooting formulation which shifts the perspective from parameterizing a network layer-by-layer to parameterizing over optimal networks described only by a set of initial conditions. For scalability, we propose a novel particle-ensemble parametrization which fully specifies the optimal weight trajectory of the continuous-depth neural network. Our experiments show that our particle-ensemble shooting formulation can achieve competitive performance, especially on long-range forecasting tasks. Finally, though the current work is inspired by continuous-depth neural networks, the particle-ensemble shooting formulation also applies to discrete-time networks and may lead to a new fertile area of research in deep learning parametrization.},
  keywords = {deep learning,NeurIPS}
}

@article{DBLP:journals/ans/StanleyBKNM19,
  author    = {Natalie Stanley and
               Thomas Bonacci and
               Roland Kwitt and
               Marc Niethammer and
               Peter J. Mucha},
  title     = {Stochastic block models with multiple continuous attributes},
  journal   = {Applied Network Science},
  volume    = {4},
  number    = {1},
  pages     = {54:1--54:22},
  year      = {2019},
  url       = {https://doi.org/10.1007/s41109-019-0170-z},
  doi       = {10.1007/s41109-019-0170-z},
  timestamp = {Tue, 20 Aug 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/ans/StanleyBKNM19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {The stochastic block model (SBM) is a probabilistic model for community structure in networks. Typically, only the adjacency matrix is used to perform SBM parameter inference. In this paper, we consider circumstances in which nodes have an associated vector of continuous attributes that are also used to learn the node-to-community assignments and corresponding SBM parameters. Our model assumes that the attributes associated with the nodes in a network’s community can be described by a common multivariate Gaussian model. In this augmented, attributed SBM, the objective is to simultaneously learn the SBM connectivity probabilities with the multivariate Gaussian parameters describing each community. While there are recent examples in the literature that combine connectivity and attribute information to inform community detection, our model is the first augmented stochastic block model to handle multiple continuous attributes. This provides the flexibility in biological data to, for example, augment connectivity information with continuous measurements from multiple experimental modalities. Because the lack of labeled network data often makes community detection results difficult to validate, we highlight the usefulness of our model for two network prediction tasks: link prediction and collaborative filtering. As a result of fitting this attributed stochastic block model, one can predict the attribute vector or connectivity patterns for a new node in the event of the complementary source of information (connectivity or attributes, respectively). We also highlight two biological examples where the attributed stochastic block model provides satisfactory performance in the link prediction and collaborative filtering tasks.},
  keywords = {SBM,network,Applied Network Science}
}

@article{DBLP:journals/jmlr/HoferKN19,
  author    = {Christoph D. Hofer and
               Roland Kwitt and
               Marc Niethammer},
  title     = {Learning Representations of Persistence Barcodes},
  journal   = {J. Mach. Learn. Res.},
  volume    = {20},
  pages     = {126:1--126:45},
  year      = {2019},
  url       = {http://jmlr.org/papers/v20/18-358.html},
  timestamp = {Thu, 18 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/jmlr/HoferKN19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We consider the problem of supervised learning with summary representations of topological features in data. In particular, we focus on persistent homology, the prevalent tool used in topological data analysis. As the summary representations, referred to as barcodes or persistence diagrams, come in the unusual format of multi sets, equipped with computationally expensive metrics, they can not readily be processed with conventional learning techniques. While different approaches to address this problem have been proposed, either in the context of kernel-based learning, or via carefully designed vectorization techniques, it remains an open problem how to leverage advances in representation learning via deep neural networks. Appropriately handling topological summaries as input to neural networks would address the disadvantage of previous strategies which handle this type of data in a task-agnostic manner. In particular, we propose an approach that is designed to learn a task-specific representation of barcodes. In other words, we aim to learn a representation that adapts to the learning problem while, at the same time, preserving theoretical properties (such as stability). This is done by projecting barcodes into a finite dimensional vector space using a collection of parametrized functionals, so called structure elements, for which we provide a generic construction scheme. A theoretical analysis of this approach reveals sufficient conditions to preserve stability, and also shows that different choices of structure elements lead to great differences with respect to their suitability for numerical optimization. When implemented as a neural network input layer, our approach demonstrates compelling performance on various types of problems, including graph classification and eigenvalue prediction, the classification of 2D/3D object shapes and recognizing activities from EEG signals.},
  keywords = {topology,deep learning,JMLR}
}

@article{DBLP:journals/mia/DingFYTKN19,
  author    = {Zhipeng Ding and
               Greg M. Fleishman and
               Xiao Yang and
               Paul Thompson and
               Roland Kwitt and
               Marc Niethammer},
  title     = {Fast predictive simple geodesic regression},
  journal   = {Medical Image Anal.},
  volume    = {56},
  pages     = {193--209},
  year      = {2019},
  url       = {https://drive.google.com/file/d/1D2RastKoyhEl9lwOYDD5wG_Fy4LwEFc5},
  doi       = {10.1016/j.media.2019.06.003},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/mia/DingFYTKN19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Deformable image registration and regression are important tasks in medical image analysis. However, they are computationally expensive, especially when analyzing large-scale datasets that contain thousands of images. Hence, cluster computing is typically used, making the approaches dependent on such computational infrastructure. Even larger computational resources are required as study sizes increase. This limits the use of deformable image registration and regression for clinical applications and as component algorithms for other image analysis approaches. We therefore propose using a fast predictive approach to perform image registrations. In particular, we employ these fast registration predictions to approximate a simplified geodesic regression model to capture longitudinal brain changes. The resulting method is orders of magnitude faster than the standard optimization-based regression model and hence facilitates large-scale analysis on a single graphics processing unit (GPU). We evaluate our results on 3D brain magnetic resonance images (MRI) from the ADNI datasets.},
  keywords = {registration,brain,regression,MEDIA}
}

@article{DBLP:journals/tbe/ChittajalluMGCG19,
  author    = {Deepak Roy Chittajallu and
               Matthew McCormick and
               Samuel Gerber and
               Tomasz J. Czernuszewicz and
               Ryan C. Gessner and
               Monte S. Willis and
               Marc Niethammer and
               Roland Kwitt and
               Stephen R. Aylward},
  title     = {Image-Based Methods for Phase Estimation, Gating, and Temporal Superresolution
               of Cardiac Ultrasound},
  journal   = {{IEEE} Trans. Biomed. Engineering},
  volume    = {66},
  number    = {1},
  pages     = {72--79},
  year      = {2019},
  url       = {https://doi.org/10.1109/TBME.2018.2823279},
  doi       = {10.1109/TBME.2018.2823279},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/tbe/ChittajalluMGCG19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Objective: Ultrasound is an effective tool for rapid noninvasive assessment of cardiac structure and function. Determining the cardiorespiratory phases of each frame in the ultrasound video and capturing the cardiac function at a much higher temporal resolution are essential in many applications. Fulfilling these requirements is particularly challenging in preclinical studies involving small animals with high cardiorespiratory rates, requiring cumbersome and expensive specialized hardware. Methods: We present a novel method for the retrospective estimation of cardiorespiratory phases directly from the ultrasound videos. It transforms the videos into a univariate time series preserving the evidence of periodic cardiorespiratory motion, decouples the signatures of cardiorespiratory motion with a trend extraction technique, and estimates the cardiorespiratory phases using a Hilbert transform approach. We also present a robust nonparametric regression technique for respiratory gating and a novel kernelregression model for reconstructing images at any cardiac phase facilitating temporal superresolution. Results: We validated our methods using two-dimensional echocardiography videos and electrocardiogram (ECG) recordings of six mice. Our cardiac phase estimation method provides accurate phase estimates with a mean-phase-error range of 3\%–6\% against ECG derived phase and outperforms three previously published methods in locating ECGs R-wave peak frames with a mean-frame-error range of 0.73–1.36. Our kernel-regression model accurately reconstructs images at any cardiac phase with a mean-normalizedcorrelation range of 0.81–0.85 over 50 leave-one-outcross-validation rounds. Conclusion and significance: Our methods can enable tracking of cardiorespiratory phases without additional hardware and reconstruction of respiration-free single cardiac-cycle videos at a much higher temporal resolution.},
  keywords = {heart,regression,TBME}
}

@inproceedings{DBLP:conf/cvpr/ShenHXN19,
  author    = {Zhengyang Shen and
               Xu Han and
               Zhenlin Xu and
               Marc Niethammer},
  title     = {Networks for Joint Affine and Non-Parametric Image Registration},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2019, Long Beach, CA, USA, June 16-20, 2019},
  pages     = {4224--4233},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2019},
  url       = {https://drive.google.com/file/d/1fybx_qI9PNW14w8C2gOmBN6GoYn3G_Mu},
  doi       = {10.1109/CVPR.2019.00435},
  timestamp = {Mon, 20 Jan 2020 15:36:04 +0100},
  biburl    = {https://dblp.org/rec/conf/cvpr/ShenHXN19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We introduce an end-to-end deep-learning framework for 3D medical image registration. In contrast to existing approaches, our framework combines two registration methods: an affine registration and a vector momentum-parameterized stationary velocity field (vSVF) model. Specifically, it consists of three stages. In the first stage, a multi-step affine network predicts affine transform parameters. In the second stage, we use a U-Net-like network to generate a momentum, from which a velocity field can be computed via smoothing. Finally, in the third stage, we employ a self-iterable map-based vSVF component to provide a non-parametric refinement based on the current estimate of the transformation map. Once the model is trained, a registration is completed in one forward pass. To evaluate the performance, we conducted longitudinal and cross-subject experiments on 3D magnetic resonance images (MRI) of the knee of the Osteoarthritis Initiative (OAI) dataset. Results show that our framework achieves comparable performance to state-of-the-art medical image registration approaches, but it is much faster, with a better control of transformation regularity including the ability to produce approximately symmetric transformations, and combining affine as well as non-parametric registration.},
  keywords = {registration,deep learning,knee,SVF,CVPR}
}

@inproceedings{DBLP:conf/cvpr/NiethammerKV19,
  author    = {Marc Niethammer and
               Roland Kwitt and
               Fran{\c{c}}ois{-}Xavier Vialard},
  title     = {Metric Learning for Image Registration},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2019, Long Beach, CA, USA, June 16-20, 2019},
  pages     = {8463--8472},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2019},
  url       = {http://openaccess.thecvf.com/content\_CVPR\_2019/html/Niethammer\_Metric\_Learning\_for\_Image\_Registration\_CVPR\_2019\_paper.html},
  doi       = {10.1109/CVPR.2019.00866},
  timestamp = {Mon, 20 Jan 2020 15:36:04 +0100},
  biburl    = {https://dblp.org/rec/conf/cvpr/NiethammerKV19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Image registration is a key technique in medical image analysis to estimate deformations between image pairs. A good deformation model is important for high-quality estimates. However, most existing approaches use ad-hoc deformation models chosen for mathematical convenience rather than to capture observed data variation. Recent deep learning approaches learn deformation models directly from data. However, they provide limited control over the spatial regularity of transformations. Instead of learning the entire registration approach, we learn a spatially-adaptive regularizer within a registration model. This allows controlling the desired level of regularity and preserving structural properties of a registration model. For example, diffeomorphic transformations can be attained. Our approach is a radical departure from existing deep learning approaches to image registration by embedding a deep learning model in an optimization-based registration algorithm to parameterize and data-adapt the registration model itself.},
  keywords = {registration,SVF,metric learning,brain,CVPR}
}

@inproceedings{DBLP:conf/icml/HoferKND19,
  author    = {Christoph D. Hofer and
               Roland Kwitt and
               Marc Niethammer and
               Mandar Dixit},
  editor    = {Kamalika Chaudhuri and
               Ruslan Salakhutdinov},
  title     = {Connectivity-Optimized Representation Learning via Persistent Homology},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning,
               {ICML} 2019, 9-15 June 2019, Long Beach, California, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {97},
  pages     = {2751--2760},
  publisher = {{PMLR}},
  year      = {2019},
  url       = {http://proceedings.mlr.press/v97/hofer19a.html},
  timestamp = {Fri, 14 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/HoferKND19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We study the problem of learning representations with controllable connectivity properties. This is beneficial in situations when the imposed structure can be leveraged upstream. In particular, we control the connectivity of an autoencoder’s latent space via a novel type of loss, operating on information from persistent homology. Under mild conditions, this loss is differentiable and we present a theoretical analysis of the properties induced by the loss. We choose one-class learning as our upstream task and demonstrate that the imposed structure enables informed parameter selection for modeling the in-class distribution via kernel density estimators. Evaluated on computer vision data, these one-class models exhibit competitive performance and, in a low sample size regime, outperform other methods by a large margin. Notably, our results indicate that a single autoencoder, trained on auxiliary (unlabeled) data, yields a mapping into latent space that can be reused across datasets for one-class learning.},
  keywords = {topology,deep learning,ICML}
}

@inproceedings{DBLP:conf/mibam/Pham0NPS19,
  author    = {Kevin Pham and
               Xiao Yang and
               Marc Niethammer and
               Juan{-}Carlos Prieto and
               Martin Styner},
  editor    = {Barjor Gimi and
               Andrzej Kr{\'{o}}l},
  title     = {Multiseg pipeline: automatic tissue segmentation of brain {MR} images
               with subject-specific atlases},
  booktitle = {Medical Imaging 2019: Biomedical Applications in Molecular, Structural,
               and Functional Imaging, San Diego, California, United States, 16-21
               February 2019},
  series    = {{SPIE} Proceedings},
  volume    = {10953},
  pages     = {109530K},
  publisher = {{SPIE}},
  year      = {2019},
  url       = {https://doi.org/10.1117/12.2513237},
  doi       = {10.1117/12.2513237},
  timestamp = {Sun, 02 Jun 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/mibam/Pham0NPS19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Automated segmentation and labeling of individual brain anatomical regions is challenging due to individual structural variability. Although, atlas-based segmentation has shown its potential for both tissue and structure segmentation, the inherent natural variability as well as disease-related changes in MR appearance is often inappropriately represented by a single atlas image. In order to have a more accurate representation, several atlases may be used for the segmentation task in a given neuroimaging study. In this paper, we present the MultisegPipeline, it uses multiple atlases that have been visually inspected and capture the expected variability in a neonatal population. The MultisegPipeline transfers the labeled regions from each atlas to the target image using deformable registration (ANTs or QuickSilver is available for this task). Additionally, the set of labels are merged using a label fusion technique that reduces the errors produced by the registration. The final output is a single label map that combines the results produced by all atlases into a consensus solution. In our study, the MultisegPipeline is used to segment brain MR images from 31 infants, a leave-one-out strategy was used to test our framework. The average dice score coefficient was 0.89.}
}

@inproceedings{DBLP:conf/miccai/DingHN19,
  author    = {Zhipeng Ding and
               Xu Han and
               Marc Niethammer},
  editor    = {Dinggang Shen and
               Tianming Liu and
               Terry M. Peters and
               Lawrence H. Staib and
               Caroline Essert and
               Sean Zhou and
               Pew{-}Thian Yap and
               Ali Khan},
  title     = {VoteNet: {A} Deep Learning Label Fusion Method for Multi-atlas Segmentation},
  booktitle = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}
               2019 - 22nd International Conference, Shenzhen, China, October 13-17,
               2019, Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {11766},
  pages     = {202--210},
  publisher = {Springer},
  year      = {2019},
  url       = {https://drive.google.com/file/d/1Qs5_Vd0AHjty2Dx6e2-mISKX8vcQE44x},
  doi       = {10.1007/978-3-030-32248-9\_23},
  timestamp = {Thu, 10 Oct 2019 13:42:59 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/DingHN19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Deep learning (DL) approaches are state-of-the-art for many medical image segmentation tasks. They offer a number of advantages: they can be trained for specific tasks, computations are fast at test time, and segmentation quality is typically high. In contrast, previously popular multi-atlas segmentation (MAS) methods are relatively slow (as they rely on costly registrations) and even though sophisticated label fusion strategies have been proposed, DL approaches generally outperform MAS. In this work, we propose a DL-based label fusion strategy (VoteNet) which locally selects a set of reliable atlases whose labels are then fused via plurality voting. Experiments on 3D brain MRI data show that by selecting a good initial atlas set MAS with VoteNet significantly outperforms a number of other label fusion strategies as well as a direct DL segmentation approach. We also provide an experimental analysis of the upper performance bound achievable by our method. While unlikely achievable in practice, this bound suggests room for further performance improvements. Lastly, to address the runtime disadvantage of standard MAS, all our results make use of a fast DL registration approach.},
  keywords = {segmentation,deep learning,multi atlas,MICCAI,brain}
}

@inproceedings{DBLP:conf/miccai/XuN19,
  author    = {Zhenlin Xu and
               Marc Niethammer},
  editor    = {Dinggang Shen and
               Tianming Liu and
               Terry M. Peters and
               Lawrence H. Staib and
               Caroline Essert and
               Sean Zhou and
               Pew{-}Thian Yap and
               Ali Khan},
  title     = {DeepAtlas: Joint Semi-supervised Learning of Image Registration and
               Segmentation},
  booktitle = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}
               2019 - 22nd International Conference, Shenzhen, China, October 13-17,
               2019, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {11765},
  pages     = {420--429},
  publisher = {Springer},
  year      = {2019},
  url       = {https://drive.google.com/file/d/10NhXJNETZ0-tqoiwBDaHUEj5yRkg__94},
  doi       = {10.1007/978-3-030-32245-8\_47},
  timestamp = {Thu, 10 Oct 2019 12:51:56 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/XuN19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Deep convolutional neural networks (CNNs) are state-of-theart for semantic image segmentation, but typically require many labeled training samples. Obtaining 3D segmentations of medical images for supervised training is difficult and labor intensive. Motivated by classical approaches for joint segmentation and registration we therefore propose a deep learning framework that jointly learns networks for image registration and image segmentation. In contrast to previous work on deep unsupervised image registration, which showed the benefit of weak supervision via image segmentations, our approach can use existing segmentations when available and computes them via the segmentation network otherwise, thereby providing the same registration benefit. Conversely, segmentation network training benefits from the registration, which essentially provides a realistic form of data augmentation. Experiments on knee and brain 3D magnetic resonance (MR) images show that our approach achieves large simultaneous improvements of segmentation and registration accuracy (over independently trained networks) and allows training high-quality models with very limited training data. Specifically, in a one-shot-scenario (with only one manually labeled image) our approach increases Dice scores (\%) over an unsupervised registration network by 2.7 and 1.8 on the knee and brain images respectively.},
  keywords = {knee,brain,registration,segmentation,deep learning,MICCAI}
}

@inproceedings{DBLP:conf/nips/ShenVN19,
  author    = {Zhengyang Shen and
               Fran{\c{c}}ois{-}Xavier Vialard and
               Marc Niethammer},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Region-specific Diffeomorphic Metric Mapping},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14
               December 2019, Vancouver, BC, Canada},
  pages     = {1096--1106},
  year      = {2019},
  url       = {https://drive.google.com/file/d/1kIuunw6FP2ek8ZsLw92zL6RJw02YU7Nx},
  timestamp = {Fri, 06 Mar 2020 16:59:09 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/ShenVN19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We introduce a region-specific diffeomorphic metric mapping (RDMM) registration approach. RDMM is non-parametric, estimating spatio-temporal velocity fields which parameterize the sought-for spatial transformation. Regularization of these velocity fields is necessary. In contrast to existing non-parametric registration approaches using a fixed spatially-invariant regularization, for example, the large displacement diffeomorphic metric mapping (LDDMM) model, our approach allows for spatially-varying regularization which is advected via the estimated spatio-temporal velocity field. Hence, not only can our model capture large displacements, it does so with a spatio-temporal regularizer that keeps track of how regions deform, which is a more natural mathematical formulation. We explore a family of RDMM registration approaches: 1) a registration model where regions with separate regularizations are pre-defined (e.g., in an atlas space or for distinct foreground and background regions), 2) a registration model where a general spatially-varying regularizer is estimated, and 3) a registration model where the spatially-varying regularizer is obtained via an end-to-end trained deep learning (DL) model. We provide a variational derivation of RDMM, showing that the model can assure diffeomorphic transformations in the continuum, and that LDDMM is a particular instance of RDMM. To evaluate RDMM performance we experiment 1) on synthetic 2D data and 2) on two 3D datasets: knee magnetic resonance images (MRIs) of the Osteoarthritis Initiative (OAI) and computed tomography images (CT) of the lung. Results show that our framework achieves comparable performance to state-of-the-art image registration approaches, while providing additional information via a learned spatio-temporal regularizer. Further, our deep learning approach allows for very fast RDMM and LDDMM estimations. Code is available at https://github.com/uncbiag/registration.},
  keywords = {LDDMM,RDMM,deep learning,knee,registration,NeurIPS}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/abs-1903-08811,
  author    = {Zhengyang Shen and
               Xu Han and
               Zhenlin Xu and
               Marc Niethammer},
  title     = {Networks for Joint Affine and Non-parametric Image Registration},
  journal   = {CoRR},
  volume    = {abs/1903.08811},
  year      = {2019},
  url       = {https://drive.google.com/file/d/1fybx_qI9PNW14w8C2gOmBN6GoYn3G_Mu},
  timestamp = {Mon, 01 Apr 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1903-08811.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We introduce an end-to-end deep-learning framework for 3D medical image registration. In contrast to existing approaches, our framework combines two registration methods: an affine registration and a vector momentum-parameterized stationary velocity field (vSVF) model. Specifically, it consists of three stages. In the first stage, a multi-step affine network predicts affine transform parameters. In the second stage, we use a U-Net-like network to generate a momentum, from which a velocity field can be computed via smoothing. Finally, in the third stage, we employ a self-iterable map-based vSVF component to provide a non-parametric refinement based on the current estimate of the transformation map. Once the model is trained, a registration is completed in one forward pass. To evaluate the performance, we conducted longitudinal and cross-subject experiments on 3D magnetic resonance images (MRI) of the knee of the Osteoarthritis Initiative (OAI) dataset. Results show that our framework achieves comparable performance to state-of-the-art medical image registration approaches, but it is much faster, with a better control of transformation regularity including the ability to produce approximately symmetric transformations, and combining affine as well as non-parametric registration.},
}

# commented out as already included as regular paper
article{DBLP:journals/corr/abs-1904-08465,
  author    = {Zhenlin Xu and
               Marc Niethammer},
  title     = {DeepAtlas: Joint Semi-Supervised Learning of Image Registration and
               Segmentation},
  journal   = {CoRR},
  volume    = {abs/1904.08465},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.08465},
  archivePrefix = {arXiv},
  eprint    = {1904.08465},
  timestamp = {Fri, 26 Apr 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-08465.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Deep convolutional neural networks (CNNs) are state-of-theart for semantic image segmentation, but typically require many labeled training samples. Obtaining 3D segmentations of medical images for supervised training is difficult and labor intensive. Motivated by classical approaches for joint segmentation and registration we therefore propose a deep learning framework that jointly learns networks for image registration and image segmentation. In contrast to previous work on deep unsupervised image registration, which showed the benefit of weak supervision via image segmentations, our approach can use existing segmentations when available and computes them via the segmentation network otherwise, thereby providing the same registration benefit. Conversely, segmentation network training benefits from the registration, which essentially provides a realistic form of data augmentation. Experiments on knee and brain 3D magnetic resonance (MR) images show that our approach achieves large simultaneous improvements of segmentation and registration accuracy (over independently trained networks) and allows training high-quality models with very limited training data. Specifically, in a one-shot-scenario (with only one manually labeled image) our approach increases Dice scores (\%) over an unsupervised registration network by 2.7 and 1.8 on the knee and brain images respectively.}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/abs-1904-08963,
  author    = {Zhipeng Ding and
               Xu Han and
               Marc Niethammer},
  title     = {VoteNet: {A} Deep Learning Label Fusion Method for Multi-Atlas Segmentation},
  journal   = {CoRR},
  volume    = {abs/1904.08963},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.08963},
  archivePrefix = {arXiv},
  eprint    = {1904.08963},
  timestamp = {Fri, 26 Apr 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-08963.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Deep learning (DL) approaches are state-of-the-art for many medical image segmentation tasks. They offer a number of advantages: they can be trained for specific tasks, computations are fast at test time, and segmentation quality is typically high. In contrast, previously popular multi-atlas segmentation (MAS) methods are relatively slow (as they rely on costly registrations) and even though sophisticated label fusion strategies have been proposed, DL approaches generally outperform MAS. In this work, we propose a DL-based label fusion strategy (VoteNet) which locally selects a set of reliable atlases whose labels are then fused via plurality voting. Experiments on 3D brain MRI data show that by selecting a good initial atlas set MAS with VoteNet significantly outperforms a number of other label fusion strategies as well as a direct DL segmentation approach. We also provide an experimental analysis of the upper performance bound achievable by our method. While unlikely achievable in practice, this bound suggests room for further performance improvements. Lastly, to address the runtime disadvantage of standard MAS, all our results make use of a fast DL registration approach.}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/abs-1904-09524,
  author    = {Marc Niethammer and
               Roland Kwitt and
               Fran{\c{c}}ois{-}Xavier Vialard},
  title     = {Metric Learning for Image Registration},
  journal   = {CoRR},
  volume    = {abs/1904.09524},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.09524},
  archivePrefix = {arXiv},
  eprint    = {1904.09524},
  timestamp = {Fri, 26 Apr 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1904-09524.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Image registration is a key technique in medical image analysis to estimate deformations between image pairs. A good deformation model is important for high-quality estimates. However, most existing approaches use ad-hoc deformation models chosen for mathematical convenience rather than to capture observed data variation. Recent deep learning approaches learn deformation models directly from data. However, they provide limited control over the spatial regularity of transformations. Instead of learning the entire registration approach, we learn a spatially-adaptive regularizer within a registration model. This allows controlling the desired level of regularity and preserving structural properties of a registration model. For example, diffeomorphic transformations can be attained. Our approach is a radical departure from existing deep learning approaches to image registration by embedding a deep learning model in an optimization-based registration algorithm to parameterize and data-adapt the registration model itself.}
}

@inproceedings{DBLP:conf/icml/HoferGRNK20,
  author    = {Christoph D. Hofer and
               Florian Graf and
               Bastian Rieck and
               Marc Niethammer and
               Roland Kwitt},
  title     = {Graph Filtration Learning},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning,
               {ICML} 2020, 13-18 July 2020, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {119},
  pages     = {4314--4323},
  publisher = {{PMLR}},
  year      = {2020},
  url       = {http://proceedings.mlr.press/v119/hofer20b.html},
  timestamp = {Tue, 15 Dec 2020 17:40:19 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/HoferGRNK20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We propose an approach to learning with graph-structured data in the problem domain of graph classification. In particular, we present a novel type of readout operation to aggregate node features into a graph-level representation. To this end, we leverage persistent homology computed via a real-valued, learnable, filter function. We establish the theoretical foundation for differentiating through the persistent homology computation. Empirically, we show that this type of readout operation compares favorably to previous techniques, especially when the graph connectivity structure is informative for the learning problem.},
  keywords = {ICML,deep learning,topology}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/abs-1906-00139,
  author    = {Zhengyang Shen and
               Fran{\c{c}}ois{-}Xavier Vialard and
               Marc Niethammer},
  title     = {Region-specific Diffeomorphic Metric Mapping},
  journal   = {CoRR},
  volume    = {abs/1906.00139},
  year      = {2019},
  url       = {https://drive.google.com/file/d/1kIuunw6FP2ek8ZsLw92zL6RJw02YU7Nx},
  timestamp = {Thu, 13 Jun 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-00139.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We introduce a region-specific diffeomorphic metric mapping (RDMM) registration approach. RDMM is non-parametric, estimating spatio-temporal velocity fields which parameterize the sought-for spatial transformation. Regularization of these velocity fields is necessary. In contrast to existing non-parametric registration approaches using a fixed spatially-invariant regularization, for example, the large displacement diffeomorphic metric mapping (LDDMM) model, our approach allows for spatially-varying regularization which is advected via the estimated spatio-temporal velocity field. Hence, not only can our model capture large displacements, it does so with a spatio-temporal regularizer that keeps track of how regions deform, which is a more natural mathematical formulation. We explore a family of RDMM registration approaches: 1) a registration model where regions with separate regularizations are pre-defined (e.g., in an atlas space or for distinct foreground and background regions), 2) a registration model where a general spatially-varying regularizer is estimated, and 3) a registration model where the spatially-varying regularizer is obtained via an end-to-end trained deep learning (DL) model. We provide a variational derivation of RDMM, showing that the model can assure diffeomorphic transformations in the continuum, and that LDDMM is a particular instance of RDMM. To evaluate RDMM performance we experiment 1) on synthetic 2D data and 2) on two 3D datasets: knee magnetic resonance images (MRIs) of the Osteoarthritis Initiative (OAI) and computed tomography images (CT) of the lung. Results show that our framework achieves comparable performance to state-of-the-art image registration approaches, while providing additional information via a learned spatio-temporal regularizer. Further, our deep learning approach allows for very fast RDMM and LDDMM estimations. Code is available at https://github.com/uncbiag/registration.}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/abs-1906-09003,
  author    = {Christoph D. Hofer and
               Roland Kwitt and
               Mandar Dixit and
               Marc Niethammer},
  title     = {Connectivity-Optimized Representation Learning via Persistent Homology},
  journal   = {CoRR},
  volume    = {abs/1906.09003},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.09003},
  archivePrefix = {arXiv},
  eprint    = {1906.09003},
  timestamp = {Fri, 14 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-09003.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We study the problem of learning representations with controllable connectivity properties. This is beneficial in situations when the imposed structure can be leveraged upstream. In particular, we control the connectivity of an autoencoder’s latent space via a novel type of loss, operating on information from persistent homology. Under mild conditions, this loss is differentiable and we present a theoretical analysis of the properties induced by the loss. We choose one-class learning as our upstream task and demonstrate that the imposed structure enables informed parameter selection for modeling the in-class distribution via kernel density estimators. Evaluated on computer vision data, these one-class models exhibit competitive performance and, in a low sample size regime, outperform other methods by a large margin. Notably, our results indicate that a single autoencoder, trained on auxiliary (unlabeled) data, yields a mapping into latent space that can be reused across datasets for one-class learning.}
}

@article{DBLP:journals/corr/abs-1907-07739,
  author    = {Heather D. Couture and
               Roland Kwitt and
               J. S. Marron and
               Melissa A. Troester and
               Charles M. Perou and
               Marc Niethammer},
  title     = {Deep Multi-View Learning via Task-Optimal {CCA}},
  journal   = {CoRR},
  volume    = {abs/1907.07739},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.07739},
  archivePrefix = {arXiv},
  eprint    = {1907.07739},
  timestamp = {Tue, 23 Jul 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-07739.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Canonical Correlation Analysis (CCA) is widely used for multimodal data analysis and, more recently, for discriminative tasks such as multi-view learning; however, it makes no use of class labels. Recent CCA methods have started to address this weakness but are limited in that they do not simultaneously optimize the CCA projection for discrimination and the CCA projection itself, or they are linear only. We address these deficiencies by simultaneously optimizing a CCA-based and a task objective in an end-to-end manner. Together, these two objectives learn a non-linear CCA projection to a shared latent space that is highly correlated and discriminative. Our method shows a significant improvement over previous state-of-the-art (including deep supervised approaches) for cross-view classification, regularization with a second view, and semi-supervised learning on real data.},
  keywords = {CCA,deep learning}
}

# already included
article{DBLP:journals/corr/abs-1909-09877,
  author    = {Yifeng Shi and
               Junier Oliva and
               Marc Niethammer},
  title     = {Deep Message Passing on Sets},
  journal   = {CoRR},
  volume    = {abs/1909.09877},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.09877},
  archivePrefix = {arXiv},
  eprint    = {1909.09877},
  timestamp = {Fri, 27 Sep 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-09877.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Modern methods for learning over graph input data have shown the fruitfulness of accounting for relationships among elements in a collection. However, most methods that learn over set input data use only rudimentary approaches to exploit intra-collection relationships. In this work we introduce Deep Message Passing on Sets (DMPS), a novel method that incorporates relational learning for sets. DMPS not only connects learning on graphs with learning on sets via deep kernel learning, but it also bridges message passing on sets and traditional diffusion dynamics commonly used in denoising models. Based on these connections, we develop two new blocks for relational learning on sets: the set-denoising block and the set-residual block. The former is motivated by the connection between message passing on general graphs and diffusion-based denoising models, whereas the latter is inspired by the well-known residual network. In addition to demonstrating the interpretability of our model by learning the true underlying relational structure experimentally, we also show the effectiveness of our approach on both synthetic and real-world datasets by achieving results that are competitive with or outperform the state-of-the-art. For readers who are interested in the detailed derivations of serveral results that we present in this work, please see the supplementary material at: https://arxiv. org/abs/1909.09877.},
  keywords = {AAAI,deep learning,sets}
}

@article{DBLP:journals/neuroimage/HanKABMAVHN18,
  author    = {Xu Han and
               Roland Kwitt and
               Stephen R. Aylward and
               Spyridon Bakas and
               Bjoern H. Menze and
               Alexander Asturias and
               Paul M. Vespa and
               John D. Van Horn and
               Marc Niethammer},
  title     = {Brain extraction from normal and pathological images: {A} joint PCA/Image-Reconstruction
               approach},
  journal   = {NeuroImage},
  volume    = {176},
  pages     = {431--445},
  year      = {2018},
  url       = {https://drive.google.com/file/d/1M0IRCxSnxCcn8Og7fZ-IwE-BaZiOW8bA},
  doi       = {10.1016/j.neuroimage.2018.04.073},
  timestamp = {Mon, 16 Sep 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/neuroimage/HanKABMAVHN18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Brain extraction from 3D medical images is a common pre-processing step. A variety of approaches exist, but they are frequently only designed to perform brain extraction from images without strong pathologies. Extracting the brain from images exhibiting strong pathologies, for example, the presence of a brain tumor or of a traumatic brain injury (TBI), is challenging. In such cases, tissue appearance may substantially deviate from normal tissue appearance and hence violates algorithmic assumptions for standard approaches to brain extraction; consequently, the brain may not be correctly extracted. This paper proposes a brain extraction approach which can explicitly account for pathologies by jointly modeling normal tissue appearance and pathologies. Specifically, our model uses a three-part image decomposition: (1) normal tissue appearance is captured by principal component analysis (PCA), (2) pathologies are captured via a total variation term, and (3) the skull and surrounding tissue is captured by a sparsity term. Due to its convexity, the resulting decomposition model allows for efficient optimization. Decomposition and image registration steps are alternated to allow statistical modeling of normal tissue appearance in a fixed atlas coordinate system. As a beneficial side effect, the decomposition model allows for the identification of potentially pathological areas and the reconstruction of a quasi-normal image in atlas space. We demonstrate the effectiveness of our approach on four datasets: the publicly available IBSR and LPBA40 datasets which show normal image appearance, the BRATS dataset containing images with brain tumors, and a dataset containing clinical TBI images. We compare the performance with other popular brain extraction models: ROBEX, BEaST, MASS, BET, BSE and a recently proposed deep learning approach. Our model performs better than these competing approaches on all four datasets. Specifically, our model achieves the best median (97.11) and mean (96.88) Dice scores over all datasets. The two best performing competitors, ROBEX and MASS, achieve scores of 96.23/95.62 and 96.67/94.25 respectively. Hence, our approach is an effective method for high quality brain extraction for a wide variety of images.}
  keywords = {brain,segmentation,registration,NeuroImage}
}

@inproceedings{DBLP:conf/icpr/ZhaoLZTNM18,
  author    = {Yu Zhao and
               Hongwei Li and
               Rong Zhou and
               Giles Tetteh and
               Marc Niethammer and
               Bjoern H. Menze},
  title     = {Automatic Multi-Atlas Segmentation for Abdominal Images Using Template
               Construction and Robust Principal Component Analysis},
  booktitle = {24th International Conference on Pattern Recognition, {ICPR} 2018,
               Beijing, China, August 20-24, 2018},
  pages     = {3880--3885},
  publisher = {{IEEE} Computer Society},
  year      = {2018},
  url       = {https://doi.org/10.1109/ICPR.2018.8546323},
  doi       = {10.1109/ICPR.2018.8546323},
  timestamp = {Wed, 15 Jan 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/conf/icpr/ZhaoLZTNM18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {The automatic and accurate segmentation of different organs is a critical step for computer-aided diagnosis, treatment planning and clinical decision support. However, for small organs such as the gallbladder, pancreas, and thyroid, accurate segmentation remains challenging due to their limited fraction in the image, high anatomical variability, and inhomogeneity. This paper presents a new fully automated multi-atlas segmentation approach to segment small organs using template construction, robust principal component analysis, and K-nearest neighbor classifier. Qualitative and quantitative evaluation has been evaluated on the VISCERAL challenge dataset. Experimental results show that the proposed system outperforms other multi-atlas based methods and forest-based methods in the segmentation of small organs.},
  keywords = {ICPR,multi atlas segmentation}
}

@inproceedings{DBLP:conf/isbi/GreerGNKMCSOCA18,
  author    = {Hastings Greer and
               Samuel Gerber and
               Marc Niethammer and
               Roland Kwitt and
               Matt McCormick and
               Deepak Roy Chittajallu and
               Neal Siekierski and
               Matthew Oetgen and
               Kevin Cleary and
               Stephen R. Aylward},
  title     = {Scoliosis screening and monitoring using self contained ultrasound
               and neural networks},
  booktitle = {15th {IEEE} International Symposium on Biomedical Imaging, {ISBI}
               2018, Washington, DC, USA, April 4-7, 2018},
  pages     = {1500--1503},
  publisher = {{IEEE}},
  year      = {2018},
  url       = {https://doi.org/10.1109/ISBI.2018.8363857},
  doi       = {10.1109/ISBI.2018.8363857},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/GreerGNKMCSOCA18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We aim to diagnose scoliosis using a self contained ultrasound device that does not require significant training to operate. The device knows its angle relative to vertical using an embedded inertial measurement unit, and it estimates its angle relative to a vertebrae using a neural network analysis of its ultrasound images. The composition of those angles defines the angle of a vertebrae from vertical. The maximum difference between vertebrae angles collected from a scan of a spine yields the Cobb angle measure that is used to quantify scoliosis severity.},
  keywords = {ISBI,deep learning,scoliosis}
}

@inproceedings{DBLP:conf/miccai/XuSN18,
  author    = {Zhenlin Xu and
               Zhengyang Shen and
               Marc Niethammer},
  editor    = {Danail Stoyanov and
               Zeike Taylor and
               Gustavo Carneiro and
               Tanveer F. Syeda{-}Mahmood and
               Anne L. Martel and
               Lena Maier{-}Hein and
               Jo{\~{a}}o Manuel R. S. Tavares and
               Andrew P. Bradley and
               Jo{\~{a}}o Paulo Papa and
               Vasileios Belagiannis and
               Jacinto C. Nascimento and
               Zhi Lu and
               Sailesh Conjeti and
               Mehdi Moradi and
               Hayit Greenspan and
               Anant Madabhushi},
  title     = {Contextual Additive Networks to Efficiently Boost 3D Image Segmentations},
  booktitle = {Deep Learning in Medical Image Analysis - and - Multimodal Learning
               for Clinical Decision Support - 4th International Workshop, {DLMIA}
               2018, and 8th International Workshop, {ML-CDS} 2018, Held in Conjunction
               with {MICCAI} 2018, Granada, Spain, September 20, 2018, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {11045},
  pages     = {92--100},
  publisher = {Springer},
  year      = {2018},
  url       = {https://drive.google.com/file/d/1NgY7umhgCURSSf6Emmib1N0G2oXI5ZSC},
  doi       = {10.1007/978-3-030-00889-5\_11},
  timestamp = {Tue, 14 May 2019 10:00:50 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/XuSN18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Semantic segmentation for 3D medical images is an important task for medical image analysis which would benefit from more efficient approaches. We propose a 3D segmentation framework of cascaded fully convolutional networks (FCNs) with contextual inputs and additive outputs. Compared to previous contextual cascaded networks the additive output forces each subsequent model to refine the output of previous models in the cascade. We use U-Nets of various complexity as elementary FCNs and demonstrate our method for cartilage segmentation on a large set of 3D magnetic resonance images (MRI) of the knee. We show that a cascade of simple U-Nets may for certain tasks be superior to a single deep and complex U-Net with almost two orders of magnitude more parameters. Our framework also allows greater flexibility in trading-off performance and efficiency during testing and training.},
  keywords = {segmentation,knee,MICCAI,deep learning}
}

@inproceedings{DBLP:conf/miccai/HanBKAABDN18,
  author    = {Xu Han and
               Spyridon Bakas and
               Roland Kwitt and
               Stephen R. Aylward and
               Hamed Akbari and
               Michel Bilello and
               Christos Davatzikos and
               Marc Niethammer},
  editor    = {Alessandro Crimi and
               Spyridon Bakas and
               Hugo J. Kuijf and
               Farahani Keyvan and
               Mauricio Reyes and
               Theo van Walsum},
  title     = {Patient-Specific Registration of Pre-operative and Post-recurrence
               Brain Tumor {MRI} Scans},
  booktitle = {Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain
               Injuries - 4th International Workshop, BrainLes 2018, Held in Conjunction
               with {MICCAI} 2018, Granada, Spain, September 16, 2018, Revised Selected
               Papers, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {11383},
  pages     = {105--114},
  publisher = {Springer},
  year      = {2018},
  url       = {https://drive.google.com/file/d/1UWIFHt8vvA5ugW_FTPKn1MNCPSjWR5nq},
  doi       = {10.1007/978-3-030-11723-8\_10},
  timestamp = {Mon, 15 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/HanBKAABDN18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Registering brain magnetic resonance imaging (MRI) scans containing pathologies is challenging primarily due to large deformations caused by the pathologies, leading to missing correspondences between scans. However, the registration task is important and directly related to personalized medicine, as registering between baseline pre-operative and post-recurrence scans may allow the evaluation of tumor infiltration and recurrence. While many registration methods exist, most of them do not specifically account for pathologies. Here, we propose a framework for the registration of longitudinal image-pairs of individual patients diagnosed with glioblastoma. Specifically, we present a combined image registration/reconstruction approach, which makes use of a patient-specific principal component analysis (PCA) model of image appearance to register baseline pre-operative and post-recurrence brain tumor scans. Our approach uses the postrecurrence scan to construct a patient-specific model, which then guides the registration of the preoperative scan. Quantitative and qualitative evaluations of our framework on 10 patient imagepairs indicate that it provides excellent registration performance without requiring (1) any human intervention or (2) prior knowledge of tumor location, growth or appearance.},
  keywords = {registration,MICCAI,brain,cancer}
}

@inproceedings{DBLP:conf/miccai/CoutureMPTN18,
  author    = {Heather D. Couture and
               J. S. Marron and
               Charles M. Perou and
               Melissa A. Troester and
               Marc Niethammer},
  editor    = {Alejandro F. Frangi and
               Julia A. Schnabel and
               Christos Davatzikos and
               Carlos Alberola{-}L{\'{o}}pez and
               Gabor Fichtinger},
  title     = {Multiple Instance Learning for Heterogeneous Images: Training a {CNN}
               for Histopathology},
  booktitle = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}
               2018 - 21st International Conference, Granada, Spain, September 16-20,
               2018, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {11071},
  pages     = {254--262},
  publisher = {Springer},
  year      = {2018},
  url       = {https://doi.org/10.1007/978-3-030-00934-2\_29},
  doi       = {10.1007/978-3-030-00934-2\_29},
  timestamp = {Tue, 14 May 2019 10:00:50 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/CoutureMPTN18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Multiple instance (MI) learning with a convolutional neural network enables end-to-end training in the presence of weak image-level labels. We propose a new method for aggregating predictions from smaller regions of the image into an image-level classification by using the quantile function. The quantile function provides a more complete description of the heterogeneity within each image, improving image-level classification. We also adapt image augmentation to the MI framework by randomly selecting cropped regions on which to apply MI aggregation during each epoch of training. This provides a mechanism to study the importance of MI learning. We validate our method on five different classification tasks for breast tumor histology and provide a visualization method for interpreting local image classifications that could lead to future insights into tumor heterogeneity.},
  keywords = {cancer,MICCAI,histology}
}

@inproceedings{DBLP:conf/miccai/GerberNSA18,
  author    = {Samuel Gerber and
               Marc Niethammer and
               Martin Styner and
               Stephen R. Aylward},
  editor    = {Alejandro F. Frangi and
               Julia A. Schnabel and
               Christos Davatzikos and
               Carlos Alberola{-}L{\'{o}}pez and
               Gabor Fichtinger},
  title     = {Exploratory Population Analysis with Unbalanced Optimal Transport},
  booktitle = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}
               2018 - 21st International Conference, Granada, Spain, September 16-20,
               2018, Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {11072},
  pages     = {464--472},
  publisher = {Springer},
  year      = {2018},
  url       = {https://doi.org/10.1007/978-3-030-00931-1\_53},
  doi       = {10.1007/978-3-030-00931-1\_53},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/GerberNSA18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {The plethora of data from neuroimaging studies provide a rich opportunity to discover effects and generate hypotheses through exploratory data analysis. Brain pathologies often manifest in changes in shape along with deterioration and alteration of brain matter, i.e., changes in mass. We propose a morphometry approach using unbalanced optimal transport that detects and localizes changes in mass and separates them from changes due to the location of mass. The approach generates images of mass allocation and mass transport cost for each subject in the population. Voxelwise correlations with clinical variables highlight regions of mass allocation or mass transfer related to the variables. We demonstrate the method on the white and gray matter segmentations from the OASIS brain MRI data set. The separation of white and gray matter ensures that optimal transport does not transfer mass between different tissues types and separates gray and white matter related changes. The OASIS data set includes subjects ranging from healthy to mild and moderate dementia, and the results corroborate known pathology changes related to dementia that are not discovered with traditional voxel-based morphometry. The transport-based morphometry increases the explanatory power of regression on clinical variables compared to traditional voxelbased morphometry, indicating that transport cost and mass allocation images capture a larger portion of pathology induced changes.},
  keywords = {MICCAI,brain,registration}
}

@article{DBLP:journals/ans/StanleyBKNM19,
  author    = {Natalie Stanley and
               Thomas Bonacci and
               Roland Kwitt and
               Marc Niethammer and
               Peter J. Mucha},
  title     = {Stochastic block models with multiple continuous attributes},
  journal   = {Appl. Netw. Sci.},
  volume    = {4},
  number    = {1},
  pages     = {54:1--54:22},
  year      = {2019},
  url       = {https://doi.org/10.1007/s41109-019-0170-z},
  doi       = {10.1007/s41109-019-0170-z},
  timestamp = {Fri, 18 Sep 2020 11:14:59 +0200},
  biburl    = {https://dblp.org/rec/journals/ans/StanleyBKNM19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {The stochastic block model (SBM) is a probabilistic model for community structure in networks. Typically, only the adjacency matrix is used to perform SBM parameter inference. In this paper, we consider circumstances in which nodes have an associated vector of continuous attributes that are also used to learn the node-to-community assignments and corresponding SBM parameters. Our model assumes that the attributes associated with the nodes in a network’s community can be described by a common multivariate Gaussian model. In this augmented, attributed SBM, the objective is to simultaneously learn the SBM connectivity probabilities with the multivariate Gaussian parameters describing each community. While there are recent examples in the literature that combine connectivity and attribute information to inform community detection, our model is the first augmented stochastic block model to handle multiple continuous attributes. This provides the flexibility in biological data to, for example, augment connectivity information with continuous measurements from multiple experimental modalities. Because the lack of labeled network data often makes community detection results difficult to validate, we highlight the usefulness of our model for two network prediction tasks: link prediction and collaborative filtering. As a result of fitting this attributed stochastic block model, one can predict the attribute vector or connectivity patterns for a new node in the event of the complementary source of information (connectivity or attributes, respectively). We also highlight two biological examples where the attributed stochastic block model provides satisfactory performance in the link prediction and collaborative filtering tasks.},
  keywords = {SBM,network}
}

@article{DBLP:journals/corr/abs-1805-07375,
  author    = {Natalie Stanley and
               Marc Niethammer and
               Peter J. Mucha},
  title     = {Testing Alignment of Node Attributes with Network Structure Through
               Label Propagation},
  journal   = {CoRR},
  volume    = {abs/1805.07375},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.07375},
  archivePrefix = {arXiv},
  eprint    = {1805.07375},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-07375.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Attributed network data is becoming increasingly common across fields, as we are often equipped with information about nodes in addition to their pairwise connectivity patterns. This extra information can manifest as a classification, or as a multidimensional vector of features. Recently developed methods that seek to extend community detection approaches to attributed networks have explored how to most effectively combine connectivity and attribute information to identify quality communities. These methods often rely on some assumption of the dependency relationships between attributes and connectivity. In this work, we seek to develop a statistical test to assess whether node attributes align with network connectivity. The objective is to quantitatively evaluate whether nodes with similar connectivity patterns also have similar attributes. To address this problem, we use a node sampling and label propagation approach. We apply our method to several synthetic examples that explore how network structure and attribute characteristics affect the empirical p-value computed by our method. Finally, we apply the test to a network generated from a single cell mass cytometry (CyTOF) dataset and show that our test can identify markers associated with distinct sub populations of single cells.},
  keywords = {SBM,network}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/abs-1806-05083,
  author    = {Heather D. Couture and
               J. S. Marron and
               Charles M. Perou and
               Melissa A. Troester and
               Marc Niethammer},
  title     = {Multiple Instance Learning for Heterogeneous Images: Training a {CNN}
               for Histopathology},
  journal   = {CoRR},
  volume    = {abs/1806.05083},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.05083},
  archivePrefix = {arXiv},
  eprint    = {1806.05083},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-05083.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Multiple instance (MI) learning with a convolutional neural network enables end-to-end training in the presence of weak image-level labels. We propose a new method for aggregating predictions from smaller regions of the image into an image-level classification by using the quantile function. The quantile function provides a more complete description of the heterogeneity within each image, improving image-level classification. We also adapt image augmentation to the MI framework by randomly selecting cropped regions on which to apply MI aggregation during each epoch of training. This provides a mechanism to study the importance of MI learning. We validate our method on five different classification tasks for breast tumor histology and provide a visualization method for interpreting local image classifications that could lead to future insights into tumor heterogeneity.}
}

@article{DBLP:journals/neuroimage/YangKSN17,
  author    = {Xiao Yang and
               Roland Kwitt and
               Martin Styner and
               Marc Niethammer},
  title     = {Quicksilver: Fast predictive image registration - {A} deep learning
               approach},
  journal   = {NeuroImage},
  volume    = {158},
  pages     = {378--396},
  year      = {2017},
  url       = {https://drive.google.com/file/d/18XO7SZtFzVHnKs3Q8BnEclbvgTPsCVbh},
  doi       = {10.1016/j.neuroimage.2017.07.008},
  timestamp = {Wed, 14 Nov 2018 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/neuroimage/YangKSN17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper introduces Quicksilver, a fast deformable image registration method. Quicksilver registration for image-pairs works by patch-wise prediction of a deformation model based directly on image appearance. A deep encoder-decoder network is used as the prediction model. While the prediction strategy is general, we focus on predictions for the Large Deformation Diffeomorphic Metric Mapping (LDDMM) model. Specifically, we predict the momentum-parameterization of LDDMM, which facilitates a patch-wise prediction strategy while maintaining the theoretical properties of LDDMM, such as guaranteed diffeomorphic mappings for sufficiently strong regularization. We also provide a probabilistic version of our prediction network which can be sampled during the testing time to calculate uncertainties in the predicted deformations. Finally, we introduce a new correction network which greatly increases the prediction accuracy of an already existing prediction network. We show experimental results for uni-modal atlas-to-image as well as uni-/multimodal image-to-image registrations. These experiments demonstrate that our method accurately predicts registrations obtained by numerical optimization, is very fast, achieves state-of-the-art registration results on four standard validation datasets, and can jointly learn an image similarity measure. Quicksilver is freely available as an open-source software.},
  keywords = {registration,deep learning,brain,NeuroImage}
}

@article{DBLP:journals/siamis/NiethammerPJW17,
  author    = {Marc Niethammer and
               Kilian M. Pohl and
               Firdaus Janoos and
               William M. Wells III},
  title     = {Active Mean Fields for Probabilistic Image Segmentation: Connections
               with Chan-Vese and Rudin-Osher-Fatemi Models},
  journal   = {{SIAM} J. Imaging Sciences},
  volume    = {10},
  number    = {3},
  pages     = {1069--1103},
  year      = {2017},
  url       = {https://doi.org/10.1137/16M1058601},
  doi       = {10.1137/16M1058601},
  timestamp = {Wed, 14 Nov 2018 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/siamis/NiethammerPJW17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Segmentation is a fundamental task for extracting semantically meaningful regions from an image. The goal of segmentation algorithms is to accurately assign object labels to each image location. However, image-noise, shortcomings of algorithms, and image ambiguities cause uncertainty in label assignment. Estimating the uncertainty in label assignment is important in multiple application domains, such as segmenting tumors from medical images for radiation treatment planning. One way to estimate these uncertainties is through the computation of posteriors of Bayesian models, which is computationally prohibitive for many practical applications. On the other hand, most computationally efficient methods fail to estimate label uncertainty. We therefore propose in this paper the Active Mean Fields (AMF) approach, a technique based on Bayesian modeling that uses a mean-field approximation to efficiently compute a segmentation and its corresponding uncertainty. Based on a variational formulation, the resulting convex model combines any label-likelihood measure with a prior on the length of the segmentation boundary. A specific implementation of that model is the Chan–Vese segmentation model (CV), in which the binary segmentation task is defined by a Gaussian likelihood and a prior regularizing the length of the segmentation boundary. Furthermore, the Euler–Lagrange equations derived from the AMF model are equivalent to those of the popular Rudin-Osher-Fatemi (ROF) model for image denoising. Solutions to the AMF model can thus be implemented by directly utilizing highlyefficient ROF solvers on log-likelihood ratio fields. We qualitatively assess the approach on synthetic data as well as on real natural and medical images. For a quantitative evaluation, we apply our approach to the icgbench dataset.},
  keywords = {segmentation,JIS,variational}
}

@inproceedings{DBLP:conf/aistats/HongYKSN17,
  author    = {Yi Hong and
               Xiao Yang and
               Roland Kwitt and
               Martin Styner and
               Marc Niethammer},
  editor    = {Aarti Singh and
               Xiaojin (Jerry) Zhu},
  title     = {Regression Uncertainty on the Grassmannian},
  booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence
               and Statistics, {AISTATS} 2017, 20-22 April 2017, Fort Lauderdale,
               FL, {USA}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {54},
  pages     = {785--793},
  publisher = {{PMLR}},
  year      = {2017},
  url       = {https://drive.google.com/file/d/1LkB5J8vqsXhLIRnr21EBYNZR5vtIubqM},
  timestamp = {Wed, 29 May 2019 08:41:44 +0200},
  biburl    = {https://dblp.org/rec/conf/aistats/HongYKSN17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Trends in longitudinal or cross-sectional studies over time are often captured through regression models. In their simplest manifestation, these regression models are formulated in . However, in the context of imaging studies, the objects of interest which are to be regressed are frequently best modeled as elements of a Riemannian manifold. Regression on such spaces can be accomplished through geodesic regression. This paper develops an approach to compute confidence intervals for geodesic regression models. The approach is general, but illustrated and specifically developed for the Grassmann manifold, which allows us, eg, to regress shapes or linear dynamical systems. Extensions to other manifolds can be obtained in a similar manner. We demonstrate our approach for regression with 2D/3D shapes using synthetic and real data.},
  keywords = {AISTATS,regression}
}

@inproceedings{DBLP:conf/cvpr/DixitKNV17,
  author    = {Mandar Dixit and
               Roland Kwitt and
               Marc Niethammer and
               Nuno Vasconcelos},
  title     = {{AGA:} Attribute-Guided Augmentation},
  booktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2017, Honolulu, HI, USA, July 21-26, 2017},
  pages     = {3328--3336},
  publisher = {{IEEE} Computer Society},
  year      = {2017},
  url       = {https://drive.google.com/file/d/1imiDFsm-CDQ40bat_xjP2f-wBGshOXln},
  doi       = {10.1109/CVPR.2017.355},
  timestamp = {Mon, 15 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/DixitKNV17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We consider the problem of data augmentation, ie, generating artificial samples to extend a given corpus of training data. Specifically, we propose attributed-guided augmentation (AGA) which learns a mapping that allows to synthesize data such that an attribute of a synthesized sample is at a desired value or strength. This is particularly interesting in situations where little data with no attribute annotation is available for learning, but we have access to a large external corpus of heavily annotated samples. While prior works primarily augment in the space of images, we propose to perform augmentation in feature space instead. We implement our approach as a deep encoder-decoder architecture that learns the synthesis function in an end-to-end manner. We demonstrate the utility of our approach on the problems of (1) one-shot object recognition in a transfer-learning setting where we have no prior knowledge of the new classes, as well as (2) object-based one-shot scene recognition. As external data, we leverage 3D depth and pose information from the SUN RGB-D dataset. Our experiments show that attribute-guided augmentation of high-level CNN features considerably improves one-shot recognition performance on both problems.},
  keywords = {CVPR,augmentation}
}

@inproceedings{DBLP:conf/ipmi/HoferKNHTU17,
  author    = {Christoph D. Hofer and
               Roland Kwitt and
               Marc Niethammer and
               Yvonne H{\"{o}}ller and
               Eugen Trinka and
               Andreas Uhl},
  editor    = {Marc Niethammer and
               Martin Styner and
               Stephen R. Aylward and
               Hongtu Zhu and
               Ipek Oguz and
               Pew{-}Thian Yap and
               Dinggang Shen},
  title     = {Constructing Shape Spaces from a Topological Perspective},
  booktitle = {Information Processing in Medical Imaging - 25th International Conference,
               {IPMI} 2017, Boone, NC, USA, June 25-30, 2017, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {10265},
  pages     = {106--118},
  publisher = {Springer},
  year      = {2017},
  url       = {https://drive.google.com/file/d/1Lu5vikOSRAK_2iz7TvaqMUII6PZADTlF},
  doi       = {10.1007/978-3-319-59050-9\_9},
  timestamp = {Fri, 14 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/conf/ipmi/HoferKNHTU17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We consider the task of constructing (metric) shape space(s) from a topological perspective. In particular, we present a generic construction scheme and demonstrate how to apply this scheme when shape is interpreted as the differences that remain after factoring out translation, scaling and rotation. This is achieved by leveraging a recently proposed injective functional transform of 2D/3D (binary) objects, based on persistent homology. The resulting shape space is then equipped with a similarity measure that is (1) by design robust to noise and (2) fulfills all metric axioms. From a practical point of view, analyses of object shape can then be carried out directly on segmented objects obtained from some imaging modality without any preprocessing, such as alignment, smoothing, or landmark selection. We demonstrate the utility of the approach on the problem of distinguishing segmented hippocampi from normal controls vs. patients with Alzheimer’s disease in a challenging setup where volume changes are no longer discriminative.},
  keywords = {IPMI,topology}
}

@inproceedings{DBLP:conf/ipmi/ZhaoPANR17,
  author    = {Qingyu Zhao and
               Stephen M. Pizer and
               Ron Alterovitz and
               Marc Niethammer and
               Julian G. Rosenman},
  editor    = {Marc Niethammer and
               Martin Styner and
               Stephen R. Aylward and
               Hongtu Zhu and
               Ipek Oguz and
               Pew{-}Thian Yap and
               Dinggang Shen},
  title     = {Orthotropic Thin Shell Elasticity Estimation for Surface Registration},
  booktitle = {Information Processing in Medical Imaging - 25th International Conference,
               {IPMI} 2017, Boone, NC, USA, June 25-30, 2017, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {10265},
  pages     = {493--504},
  publisher = {Springer},
  year      = {2017},
  url       = {https://drive.google.com/file/d/1JUQ_CewTSDMbYavrqs_mVuR7XpjHPv90},
  doi       = {10.1007/978-3-319-59050-9\_39},
  timestamp = {Tue, 14 May 2019 10:00:52 +0200},
  biburl    = {https://dblp.org/rec/conf/ipmi/ZhaoPANR17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Elastic physical models have been widely used to regularize deformations in different medical object registration tasks. Traditional approaches usually assume uniform isotropic tissue elasticity (a constant regularization weight) across the whole domain, which contradicts human tissue elasticity being not only inhomogeneous but also anisotropic. We focus on producing more physically realistic deformations for the task of surface registration. We model the surface as an orthotropic elastic thin shell, and we propose a novel statistical framework to estimate inhomogeneous and anisotropic shell elasticity parameters only from a group of known surface deformations. With this framework we show that a joint estimation of within-patient surface deformations and the shell elasticity parameters can improve groupwise registration accuracy. The method is tested in the context of endoscopic reconstruction-surface registration.},
  keywords = {IPMI,registration,endoscopy}
}

@inproceedings{DBLP:conf/isbi/HanYAKN17,
  author    = {Xu Han and
               Xiao Yang and
               Stephen R. Aylward and
               Roland Kwitt and
               Marc Niethammer},
  title     = {Efficient registration of pathological images: {A} joint PCA/image-reconstruction
               approach},
  booktitle = {14th {IEEE} International Symposium on Biomedical Imaging, {ISBI}
               2017, Melbourne, Australia, April 18-21, 2017},
  pages     = {10--14},
  publisher = {{IEEE}},
  year      = {2017},
  url       = {https://drive.google.com/file/d/11hSJN3FK3U2a38GaBZDe7w-fXXqDGP5M},
  doi       = {10.1109/ISBI.2017.7950456},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/HanYAKN17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Registration involving one or more images containing pathologies is challenging, as standard image similarity measures and spatial transforms cannot account for common changes due to pathologies. Low-rank/Sparse (LRS) decomposition removes pathologies prior to registration; however, LRS is memory-demanding and slow, which limits its use on larger data sets. Additionally, LRS blurs normal tissue regions, which may degrade registration performance. This paper proposes an efficient alternative to LRS: (1) normal tissue appearance is captured by principal component analysis (PCA) and (2) blurring is avoided by an integrated model for pathology removal and image reconstruction. Results on synthetic and BRATS 2015 data demonstrate its utility.},
  keywords = {ISBI,registration,brain}
}

@inproceedings{DBLP:conf/isbi/YangKSN17,
  author    = {Xiao Yang and
               Roland Kwitt and
               Martin Styner and
               Marc Niethammer},
  title     = {Fast predictive multimodal image registration},
  booktitle = {14th {IEEE} International Symposium on Biomedical Imaging, {ISBI}
               2017, Melbourne, Australia, April 18-21, 2017},
  pages     = {858--862},
  publisher = {{IEEE}},
  year      = {2017},
  url       = {https://drive.google.com/file/d/1upWddxmHodmYu62eDXtUzS4dqJjFlw0J},
  doi       = {10.1109/ISBI.2017.7950652},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/YangKSN17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We introduce a deep encoder-decoder architecture for image deformation prediction from multimodal images. Specifically, we design an image-patch-based deep network that jointly (i) learns an image similarity measure and (ii) the relationship between image patches and deformation parameters. While our method can be applied to general image registration formulations, we focus on the Large Deformation Diffeomorphic Metric Mapping (LDDMM) registration model. By predicting the initial momentum of the shooting formulation of LDDMM, we preserve its mathematical properties and drastically reduce the computation time, compared to optimizationbased approaches. Furthermore, we create a Bayesian probabilistic version of the network that allows evaluation of registration uncertainty via sampling of the network at test time. We evaluate our method on a 3D brain MRI dataset using both T1- and T2-weighted images. Our experiments show that our method generates accurate predictions and that learning the similarity measure leads to more consistent registrations than relying on generic multimodal image similarity measures, such as mutual information. Our approach is an order of magnitude faster than optimization-based LDDMM.},
  keywords = {registration,brain,ISBI,deep learning}
}

@inproceedings{DBLP:conf/miccai/DingFYTKN17,
  author    = {Zhipeng Ding and
               Greg M. Fleishman and
               Xiao Yang and
               Paul Thompson and
               Roland Kwitt and
               Marc Niethammer},
  editor    = {M. Jorge Cardoso and
               Tal Arbel and
               Gustavo Carneiro and
               Tanveer F. Syeda{-}Mahmood and
               Jo{\~{a}}o Manuel R. S. Tavares and
               Mehdi Moradi and
               Andrew P. Bradley and
               Hayit Greenspan and
               Jo{\~{a}}o Paulo Papa and
               Anant Madabhushi and
               Jacinto C. Nascimento and
               Jaime S. Cardoso and
               Vasileios Belagiannis and
               Zhi Lu},
  title     = {Fast Predictive Simple Geodesic Regression},
  booktitle = {Deep Learning in Medical Image Analysis and Multimodal Learning for
               Clinical Decision Support - Third International Workshop, {DLMIA}
               2017, and 7th International Workshop, {ML-CDS} 2017, Held in Conjunction
               with {MICCAI} 2017, Qu{\'{e}}bec City, QC, Canada, September 14, 2017,
               Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {10553},
  pages     = {267--275},
  publisher = {Springer},
  year      = {2017},
  url       = {https://drive.google.com/file/d/1iUjKQl5MIhxs-gsZ2SM8rscZUzWq5f7S},
  doi       = {10.1007/978-3-319-67558-9\_31},
  timestamp = {Tue, 14 May 2019 10:00:49 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/DingFYTKN17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Analyzing large-scale imaging studies with thousands of images is computationally expensive. To assess localized morphological differences, deformable image registration is a key tool. However, as registrations are costly to compute, large-scale studies frequently require large compute clusters. This paper explores a fast predictive approximation to image registration. In particular, it uses these fast registrations to approximate a simplified geodesic regression model to capture longitudinal brain changes. The resulting approach is orders of magnitude faster than the optimization-based regression approach and hence facilitates large-scale analysis on a single graphics processing unit. We show results on 2D and 3D brain magnetic resonance images from OASIS and ADNI.},
  keywords = {regression,deep learning, registration,brain,MICCAI}
}

@inproceedings{DBLP:conf/nips/HoferKNU17,
  author    = {Christoph D. Hofer and
               Roland Kwitt and
               Marc Niethammer and
               Andreas Uhl},
  editor    = {Isabelle Guyon and
               Ulrike von Luxburg and
               Samy Bengio and
               Hanna M. Wallach and
               Rob Fergus and
               S. V. N. Vishwanathan and
               Roman Garnett},
  title     = {Deep Learning with Topological Signatures},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference
               on Neural Information Processing Systems 2017, 4-9 December 2017,
               Long Beach, CA, {USA}},
  pages     = {1634--1644},
  year      = {2017},
  url       = {http://papers.nips.cc/paper/6761-deep-learning-with-topological-signatures},
  timestamp = {Fri, 06 Mar 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/HoferKNU17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Inferring topological and geometrical information from data can offer an alternative perspective in machine learning problems. Methods from topological data analysis, eg, persistent homology, enable us to obtain such information, typically in the form of summary representations of topological features. However, such topological signatures often come with an unusual structure (eg, multisets of intervals) that is highly impractical for most machine learning techniques. While many strategies have been proposed to map these topological signatures into machine learning compatible representations, they suffer from being agnostic to the target learning task. In contrast, we propose a technique that enables us to input topological signatures to deep neural networks and learn a task-optimal representation during training. Our approach is realized as a novel input layer with favorable theoretical properties. Classification experiments on 2D object shapes and social network graphs demonstrate the versatility of the approach and, in case of the latter, we even outperform the state-of-the-art by a large margin.},
  keywords = {NeurIPS,deep learning,topology}
}

@proceedings{DBLP:conf/ipmi/2017,
  editor    = {Marc Niethammer and
               Martin Styner and
               Stephen R. Aylward and
               Hongtu Zhu and
               Ipek Oguz and
               Pew{-}Thian Yap and
               Dinggang Shen},
  title     = {Information Processing in Medical Imaging - 25th International Conference,
               {IPMI} 2017, Boone, NC, USA, June 25-30, 2017, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {10265},
  publisher = {Springer},
  year      = {2017},
  url       = {https://doi.org/10.1007/978-3-319-59050-9},
  doi       = {10.1007/978-3-319-59050-9},
  isbn      = {978-3-319-59049-3},
  timestamp = {Tue, 14 May 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/ipmi/2017.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This book constitutes the proceedings of the 25th International Conference on Information Processing in Medical Imaging, IPMI 2017, held at the Appalachian State University, Boon, NC, USA, in June 2017. The 53 full papers presented in this volume were carefully reviewed and selected from 147 submissions. They were organized in topical sections named: analysis on manifolds; shape analysis; disease diagnosis/progression; brain networks an connectivity; diffusion imaging; quantitative imaging; imaging genomics; image registration; segmentation; general image analysis.},
  keywords = {IPMI}
}

@article{DBLP:journals/corr/WassermannTNW17,
  author    = {Demian Wassermann and
               Matthew Toews and
               Marc Niethammer and
               William M. Wells III},
  title     = {Probabilistic Diffeomorphic Registration: Representing Uncertainty},
  journal   = {CoRR},
  volume    = {abs/1701.03266},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.03266},
  archivePrefix = {arXiv},
  eprint    = {1701.03266},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/WassermannTNW17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper presents a novel mathematical framework for representing uncertainty in large deformation diffeomorphic image registration. The Bayesian posterior distribution over the deformations aligning a moving and a fixed image is approximated via a variational formulation. A stochastic differential equation (SDE) modeling the deformations as the evolution of a time-varying velocity field leads to a prior density over deformations in the form of a Gaussian process. This permits estimating the full posterior distribution in order to represent uncertainty, in contrast to methods in which the posterior is approximated via Monte Carlo sampling or maximized in maximum a-posteriori (MAP) estimation. The framework is demonstrated in the case of landmark-based image registration, including simulated data and annotated pre and intra-operative 3D images.},
  keywords = {registration,uncertainty,brain}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/YangKSN17,
  author    = {Xiao Yang and
               Roland Kwitt and
               Martin Styner and
               Marc Niethammer},
  title     = {Fast Predictive Multimodal Image Registration},
  journal   = {CoRR},
  volume    = {abs/1703.10902},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.10902},
  archivePrefix = {arXiv},
  eprint    = {1703.10902},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/YangKSN17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We introduce a deep encoder-decoder architecture for image deformation prediction from multimodal images. Specifically, we design an image-patch-based deep network that jointly (i) learns an image similarity measure and (ii) the relationship between image patches and deformation parameters. While our method can be applied to general image registration formulations, we focus on the Large Deformation Diffeomorphic Metric Mapping (LDDMM) registration model. By predicting the initial momentum of the shooting formulation of LDDMM, we preserve its mathematical properties and drastically reduce the computation time, compared to optimizationbased approaches. Furthermore, we create a Bayesian probabilistic version of the network that allows evaluation of registration uncertainty via sampling of the network at test time. We evaluate our method on a 3D brain MRI dataset using both T1- and T2-weighted images. Our experiments show that our method generates accurate predictions and that learning the similarity measure leads to more consistent registrations than relying on generic multimodal image similarity measures, such as mutual information. Our approach is an order of magnitude faster than optimization-based LDDMM.}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/YangKN17,
  author    = {Xiao Yang and
               Roland Kwitt and
               Marc Niethammer},
  title     = {Quicksilver: Fast Predictive Image Registration - a Deep Learning
               Approach},
  journal   = {CoRR},
  volume    = {abs/1703.10908},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.10908},
  archivePrefix = {arXiv},
  eprint    = {1703.10908},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/YangKN17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper introduces Quicksilver, a fast deformable image registration method. Quicksilver registration for image-pairs works by patch-wise prediction of a deformation model based directly on image appearance. A deep encoder-decoder network is used as the prediction model. While the prediction strategy is general, we focus on predictions for the Large Deformation Diffeomorphic Metric Mapping (LDDMM) model. Specifically, we predict the momentum-parameterization of LDDMM, which facilitates a patch-wise prediction strategy while maintaining the theoretical properties of LDDMM, such as guaranteed diffeomorphic mappings for sufficiently strong regularization. We also provide a probabilistic version of our prediction network which can be sampled during the testing time to calculate uncertainties in the predicted deformations. Finally, we introduce a new correction network which greatly increases the prediction accuracy of an already existing prediction network. We show experimental results for uni-modal atlas-to-image as well as uni-/multimodal image-to-image registrations. These experiments demonstrate that our method accurately predicts registrations obtained by numerical optimization, is very fast, achieves state-of-the-art registration results on four standard validation datasets, and can jointly learn an image similarity measure. Quicksilver is freely available as an open-source software.}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/HanYAKN17,
  author    = {Xu Han and
               Xiao Yang and
               Stephen R. Aylward and
               Roland Kwitt and
               Marc Niethammer},
  title     = {Efficient Registration of Pathological Images: {A} Joint PCA/Image-Reconstruction
               Approach},
  journal   = {CoRR},
  volume    = {abs/1704.00036},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.00036},
  archivePrefix = {arXiv},
  eprint    = {1704.00036},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HanYAKN17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Registration involving one or more images containing pathologies is challenging, as standard image similarity measures and spatial transforms cannot account for common changes due to pathologies. Low-rank/Sparse (LRS) decomposition removes pathologies prior to registration; however, LRS is memory-demanding and slow, which limits its use on larger data sets. Additionally, LRS blurs normal tissue regions, which may degrade registration performance. This paper proposes an efficient alternative to LRS: (1) normal tissue appearance is captured by principal component analysis (PCA) and (2) blurring is avoided by an integrated model for pathology removal and image reconstruction. Results on synthetic and BRATS 2015 data demonstrate its utility.}
}

@article{DBLP:journals/corr/StanleyKNM17,
  author    = {Natalie Stanley and
               Roland Kwitt and
               Marc Niethammer and
               Peter J. Mucha},
  title     = {Compressing networks with super nodes},
  journal   = {CoRR},
  volume    = {abs/1706.04110},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.04110},
  archivePrefix = {arXiv},
  eprint    = {1706.04110},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/StanleyKNM17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Community detection is a commonly used technique for identifying groups in a network based on similarities in connectivity patterns. To facilitate community detection in large networks, we recast the network as a smaller network of ‘super nodes’, where each super node comprises one or more nodes of the original network. We can then use this super node representation as the input into standard community detection algorithms. To define the seeds, or centers, of our super nodes, we apply the ‘CoreHD’ ranking, a technique applied in network dismantling and decycling problems. We test our approach through the analysis of two common methods for community detection: modularity maximization with the Louvain algorithm and maximum likelihood optimization for fitting a stochastic block model. Our results highlight that applying community detection to the compressed network of super nodes is significantly faster while successfully producing partitions that are more aligned with the local network connectivity and more stable across multiple (stochastic) runs within and between community detection algorithms, yet still overlap well with the results obtained using the full network.},
  keywords = {SBM,network}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/HoferKNU17,
  author    = {Christoph D. Hofer and
               Roland Kwitt and
               Marc Niethammer and
               Andreas Uhl},
  title     = {Deep Learning with Topological Signatures},
  journal   = {CoRR},
  volume    = {abs/1707.04041},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.04041},
  archivePrefix = {arXiv},
  eprint    = {1707.04041},
  timestamp = {Fri, 14 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/HoferKNU17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Inferring topological and geometrical information from data can offer an alternative perspective in machine learning problems. Methods from topological data analysis, eg, persistent homology, enable us to obtain such information, typically in the form of summary representations of topological features. However, such topological signatures often come with an unusual structure (eg, multisets of intervals) that is highly impractical for most machine learning techniques. While many strategies have been proposed to map these topological signatures into machine learning compatible representations, they suffer from being agnostic to the target learning task. In contrast, we propose a technique that enables us to input topological signatures to deep neural networks and learn a task-optimal representation during training. Our approach is realized as a novel input layer with favorable theoretical properties. Classification experiments on 2D object shapes and social network graphs demonstrate the versatility of the approach and, in case of the latter, we even outperform the state-of-the-art by a large margin.}
}

# commented out, already included
article{DBLP:journals/corr/GerardinCCCDKND17,
  author    = {Emilie Gerardin and
               Ga{\"{e}}l Ch{\'{e}}telat and
               Marie Chupin and
               R{\'{e}}mi Cuingnet and
               B{\'{e}}atrice Desgranges and
               Hosung Kim and
               Marc Niethammer and
               Bruno Dubois and
               St{\'{e}}phane Leh{\'{e}}ricy and
               Line Garnero and
               Francis Eustache and
               Olivier Colliot},
  title     = {Multidimensional classification of hippocampal shape features discriminates
               Alzheimer's disease and mild cognitive impairment from normal aging},
  journal   = {CoRR},
  volume    = {abs/1707.05961},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.05961},
  archivePrefix = {arXiv},
  eprint    = {1707.05961},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/GerardinCCCDKND17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We describe a new method to automatically discriminate between patients with Alzheimer's disease (AD) or mild cognitive impairment (MCI) and elderly controls, based on multidimensional classification of hippocampal shape features. This approach uses spherical harmonics (SPHARM) coefficients to model the shape of the hippocampi, which are segmented from magnetic resonance images (MRI) using a fully automatic method that we previously developed. SPHARM coefficients are used as features in a classification procedure based on support vector machines (SVM). The most relevant features for classification are selected using a bagging strategy. We evaluate the accuracy of our method in a group of 23 patients with AD (10 males, 13 females, age ±standard-deviation (SD)=73±6 years, mini-mental score (MMS)=24.4±2.8), 23 patients with amnestic MCI (10 males, 13 females, age±SD=74±8 years, MMS=27.3±1.4) and 25 elderly healthy controls (13 males,12 females, age±SD=64±8 years), using leave-one-out cross-validation. For AD vs controls, we obtain a correct classification rate of 94\%, a sensitivity of 96\%, and a specificity of 92\%. For MCI vs controls, we obtain a classification rate of 83\%, a sensitivity of 83\%, and a specificity of 84\%. This accuracy is superior to that of hippocampal volumetry and is comparable to recently published SVM-based whole-brain classification methods, which relied on a different strategy. This new method may become a useful tool to assist in the diagnosis of
Alzheimer's disease.}
}

# already included
article{DBLP:journals/corr/abs-1711-05702,
  author    = {Xu Han and
               Roland Kwitt and
               Stephen R. Aylward and
               Bjoern H. Menze and
               Alexander Asturias and
               Paul M. Vespa and
               John D. Van Horn and
               Marc Niethammer},
  title     = {Brain Extraction from Normal and Pathological Images: {A} Joint PCA/Image-Reconstruction
               Approach},
  journal   = {CoRR},
  volume    = {abs/1711.05702},
  year      = {2017},
  url       = {https://drive.google.com/file/d/1M0IRCxSnxCcn8Og7fZ-IwE-BaZiOW8bA},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-05702.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Brain extraction from 3D medical images is a common pre-processing step. A variety of approaches exist, but they are frequently only designed to perform brain extraction from images without strong pathologies. Extracting the brain from images exhibiting strong pathologies, for example, the presence of a brain tumor or of a traumatic brain injury (TBI), is challenging. In such cases, tissue appearance may substantially deviate from normal tissue appearance and hence violates algorithmic assumptions for standard approaches to brain extraction; consequently, the brain may not be correctly extracted. This paper proposes a brain extraction approach which can explicitly account for pathologies by jointly modeling normal tissue appearance and pathologies. Specifically, our model uses a threepart image decomposition: (1) normal tissue appearance is captured by principal component analysis (PCA), (2) pathologies are captured via a total variation term, and (3) the skull and surrounding tissue is captured by a sparsity term. Due to its convexity, the resulting decomposition model allows for efficient optimization. Decomposition and image registration steps are alternated to allow statistical modeling of normal tissue appearance in a fixed atlas coordinate system. As a beneficial side effect, the decomposition model allows for the identification of potentially pathological areas and the reconstruction of a quasi-normal image in atlas space. We demonstrate the effectiveness of our approach on four datasets: the publicly available IBSR and LPBA40 datasets which show normal image appearance, the BRATS dataset containing images with brain tumors, and a dataset containing clinical TBI images. We compare the performance with other popular brain extraction models: ROBEX, BEaST, MASS, BET, BSE and a recently proposed deep learning approach. Our model performs better than these competing approaches on all four datasets. Specifically, our model achieves the best median (97.11) and mean (96.88) Dice scores over all datasets. The two best performing competitors, ROBEX and MASS, achieve scores of 96.23/95.62 and 96.67/94.25 respectively. Hence, our approach is an effective method for high quality brain extraction for a wide variety of images.}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/abs-1711-05766,
  author    = {Zhipeng Ding and
               Greg M. Fleishman and
               Xiao Yang and
               Paul Thompson and
               Roland Kwitt and
               Marc Niethammer},
  title     = {Fast Predictive Simple Geodesic Regression},
  journal   = {CoRR},
  volume    = {abs/1711.05766},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.05766},
  archivePrefix = {arXiv},
  eprint    = {1711.05766},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1711-05766.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Deformable image registration and regression are important tasks in medical image analysis. However, they are computationally expensive, especially when analyzing large-scale datasets that contain thousands of images. Hence, cluster computing is typically used, making the approaches dependent on such computational infrastructure. Even larger computational resources are required as study sizes increase. This limits the use of deformable image registration and regression for clinical applications and as component algorithms for other image analysis approaches. We therefore propose using a fast predictive approach to perform image registrations. In particular, we employ these fast registration predictions to approximate a simplified geodesic regression model to capture longitudinal brain changes. The resulting method is orders of magnitude faster than the standard optimization-based regression model and hence facilitates large-scale analysis on a single graphics processing unit (GPU). We evaluate our results on 3D brain magnetic resonance images (MRI) from the ADNI datasets.}
}

@article{DBLP:journals/pami/HongKSVN16,
  author    = {Yi Hong and
               Roland Kwitt and
               Nikhil Singh and
               Nuno Vasconcelos and
               Marc Niethammer},
  title     = {Parametric Regression on the Grassmannian},
  journal   = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume    = {38},
  number    = {11},
  pages     = {2284--2297},
  year      = {2016},
  url       = {https://drive.google.com/file/d/1GgflrMg1_p0GZHmeb2owDU7SRMmTiNZp},
  doi       = {10.1109/TPAMI.2016.2516533},
  timestamp = {Mon, 15 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/pami/HongKSVN16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We address the problem of fitting parametric curves on the Grassmann manifold for the purpose of intrinsic parametric regression. As customary in the literature, we start from the energy minimization formulation of linear least-squares in Euclidean spaces and generalize this concept to general nonflat Riemannian manifolds, following an optimal-control point of view. We then specialize this idea to the Grassmann manifold and demonstrate that it yields a simple, extensible and easy-to-implement solution to the parametric regression problem. In fact, it allows us to extend the basic geodesic model to (1) a “time-warped” variant and (2) cubic splines. We demonstrate the utility of the proposed solution on different vision problems, such as shape regression as a function of age, trafficspeed estimation and crowd-counting from surveillance video clips. Most notably, these problems can be conveniently solved within the same framework without any specifically-tailored steps along the processing pipeline.},
  keywords = {regression,TPAMI}
}

@inproceedings{DBLP:conf/cvpr/KwittHN16,
  author    = {Roland Kwitt and
               Sebastian Hegenbart and
               Marc Niethammer},
  title     = {One-Shot Learning of Scene Locations via Feature Trajectory Transfer},
  booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016},
  pages     = {78--86},
  publisher = {{IEEE} Computer Society},
  year      = {2016},
  url       = {https://drive.google.com/file/d/1TEU-88C1YpA6m_vCpQdTFQ75ziQjNkZf},
  doi       = {10.1109/CVPR.2016.16},
  timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/KwittHN16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {The appearance of (outdoor) scenes changes considerably with the strength of certain transient attributes, such as" rainy"," dark" or" sunny". Obviously, this also affects the representation of an image in feature space, eg, as activations at a certain CNN layer, and consequently impacts scene recognition performance. In this work, we investigate the variability in these transient attributes as a rich source of information for studying how image representations change as a function of attribute strength. In particular, we leverage a recently introduced dataset with fine-grain annotations to estimate feature trajectories for a collection of transient attributes and then show how these trajectories can be transferred to new image representations. This enables us to synthesize new data along the transferred trajectories with respect to the dimensions of the space spanned by the transient attributes. Applicability of this concept is demonstrated on the problem of one-shot recognition of scene locations. We show that data synthesized via feature trajectory transfer considerably boosts recognition performance,(1) with respect to baselines and (2) in combination with state-of-the-art approaches in one-shot learning.},
  keywords = {CVPR}
}

@inproceedings{DBLP:conf/cvpr/CsapoSSSN16,
  author    = {Istvan Csapo and
               Yundi Shi and
               Mar Sanchez and
               Martin Styner and
               Marc Niethammer},
  title     = {Registration of Developmental Image Sequences with Missing Data},
  booktitle = {2016 {IEEE} Conference on Computer Vision and Pattern Recognition
               Workshops, {CVPR} Workshops 2016, Las Vegas, NV, USA, June 26 - July
               1, 2016},
  pages     = {558--565},
  publisher = {{IEEE} Computer Society},
  year      = {2016},
  url       = {https://drive.google.com/file/d/1LsLMMhbYfR5KRbbhuNLa1bipjBMCZxuy},
  doi       = {10.1109/CVPRW.2016.76},
  timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/CsapoSSSN16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Longitudinal image registration is commonly used to establish spatial correspondence between images when investigating temporal changes in brain morphology. Most image registration methods have been developed to align images that are similar in appearance or structure. If such similarity is not given (eg, in the case of neurodevelopmental studies, which is the target application of this paper),(i) local similarity measures,(ii) metamorphosis approaches, or (iii) methods modeling longitudinal intensity change can be used. Methods modeling longitudinal intensity change have the advantage of not treating images as independent static samples. However, missing or incomplete data can lead to poor model estimation and, in turn, poor registration. Therefore, incomplete longitudinal data sets are often excluded from analysis. Here, we propose a method to build a longitudinal atlas of intensity change and incorporate it as a prior into an existing model-based registration method. We show that using the prior can guide the deformable registration of longitudinal images of brain development with missing data and produce comparable registration results to complete data sets.},
  keywords = {CVPR,registration,brain}
}

@inproceedings{DBLP:conf/isbi/AylwardMKRKN16,
  author    = {Stephen R. Aylward and
               Matthew McCormick and
               H. J. Kang and
               Sharif Razzaque and
               Roland Kwitt and
               Marc Niethammer},
  title     = {Ultrasound spectroscopy},
  booktitle = {13th {IEEE} International Symposium on Biomedical Imaging, {ISBI}
               2016, Prague, Czech Republic, April 13-16, 2016},
  pages     = {1013--1016},
  publisher = {{IEEE}},
  year      = {2016},
  url       = {https://drive.google.com/file/d/1kyJ-K73Lv0QsssAZW0vqT5qTUvkVm3Gr},
  doi       = {10.1109/ISBI.2016.7493437},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/AylwardMKRKN16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We introduce the concept of “Ultrasound Spectroscopy”. The premise of ultrasound spectroscopy is that by acquiring ultrasound RF data at multiple power and frequency settings, a rich set of features can be extracted from that RF data and used to characterize the underlying tissues. This is beneficial for a variety of problems, such as accurate tissue classification, application-specific image generation, and numerous other quantitative tasks. These capabilities are particularly relevant to point-of-care ultrasound (POCUS) applications, where operator experience with ultrasound may be limited. Instead of displaying B-mode images, a POCUS application using ultrasound spectroscopy can, for example, automatically detect internal abdominal bleeding. In this paper, we present ex vivo tissue phantom studies to demonstrate the accuracy of ultrasound spectroscopy over previous approaches. Our studies suggest that ultrasound spectroscopy provides exceptional accuracy and informative features for classifying blood versus other tissues across image locations and body habitus.},
  keywords = {ISBI}
}

@inproceedings{DBLP:conf/miccai/PolzinNHHM16,
  author    = {Thomas Polzin and
               Marc Niethammer and
               Mattias P. Heinrich and
               Heinz Handels and
               Jan Modersitzki},
  editor    = {S{\'{e}}bastien Ourselin and
               Leo Joskowicz and
               Mert R. Sabuncu and
               G{\"{o}}zde B. {\"{U}}nal and
               William Wells},
  title     = {Memory Efficient {LDDMM} for Lung {CT}},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2016 - 19th International Conference, Athens, Greece, October 17-21,
               2016, Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {9902},
  pages     = {28--36},
  year      = {2016},
  url       = {https://drive.google.com/file/d/1yk-ZvR7xWskPpUaUc9HMCz1IxKtBDg7a},
  doi       = {10.1007/978-3-319-46726-9\_4},
  timestamp = {Tue, 14 May 2019 10:00:50 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/PolzinNHHM16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper a novel Large Deformation Diffeomorphic Metric Mapping (LDDMM) scheme is presented which has significantly lower computational and memory demands than standard LDDMM but achieves the same accuracy. We exploit the smoothness of velocities and transformations by using a coarser discretization compared to the image resolution. This reduces required memory and accelerates numerical optimization as well as solution of transport equations. Accuracy is essentially unchanged as the mismatch of transformed moving and fixed image is incorporated into the model at high resolution. Reductions in memory consumption and runtime are demonstrated for registration of lung CT images. State-of-the-art accuracy is shown for the challenging DIR-Lab chronic obstructive pulmonary disease (COPD) lung CT data sets obtaining a mean landmark distance after registration of 1.03 mm and the best average results so far.},
   keywords = {MICCAI,LDDMM,lung}
}

@inproceedings{DBLP:conf/miccai/YangKN16,
  author    = {Xiao Yang and
               Roland Kwitt and
               Marc Niethammer},
  editor    = {Gustavo Carneiro and
               Diana Mateus and
               Lo{\"{\i}}c Peter and
               Andrew P. Bradley and
               Jo{\~{a}}o Manuel R. S. Tavares and
               Vasileios Belagiannis and
               Jo{\~{a}}o Paulo Papa and
               Jacinto C. Nascimento and
               Marco Loog and
               Zhi Lu and
               Jaime S. Cardoso and
               Julien Cornebise},
  title     = {Fast Predictive Image Registration},
  booktitle = {Deep Learning and Data Labeling for Medical Applications - First International
               Workshop, {LABELS} 2016, and Second International Workshop, {DLMIA}
               2016, Held in Conjunction with {MICCAI} 2016, Athens, Greece, October
               21, 2016, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {10008},
  pages     = {48--57},
  year      = {2016},
  url       = {https://drive.google.com/file/d/11QwMifHkk_NwumSWdtTWCENJVF6I8LsA},
  doi       = {10.1007/978-3-319-46976-8\_6},
  timestamp = {Tue, 14 May 2019 10:00:50 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/YangKN16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We present a method to predict image deformations based on patch-wise image appearance. Specifically, we design a patch-based deep encoder-decoder network which learns the pixel/voxel-wise mapping between image appearance and registration parameters. Our approach can predict general deformation parameterizations, however, we focus on the large deformation diffeomorphic metric mapping (LDDMM) registration model. By predicting the LDDMM momentum-parameterization we retain the desirable theoretical properties of LDDMM, while reducing computation time by orders of magnitude: combined with patch pruning, we achieve a 1500 x/66 x speed up compared to GPU-based optimization for 2D/3D image registration. Our approach has better prediction accuracy than predicting deformation or velocity fields and results in diffeomorphic transformations. Additionally, we create a Bayesian probabilistic version of our network, which allows evaluation of deformation field uncertainty through Monte Carlo sampling using dropout at test time. We show that deformation uncertainty highlights areas of ambiguous deformations. We test our method on the OASIS brain image dataset in 2D and 3D.},
   keywords = {MICCAI,registration,deep learning,brain}
}

@inproceedings{DBLP:conf/miccai/YangHPAKN16,
  author    = {Xiao Yang and
               Xu Han and
               Eunbyung Park and
               Stephen R. Aylward and
               Roland Kwitt and
               Marc Niethammer},
  editor    = {Sotirios A. Tsaftaris and
               Ali Gooya and
               Alejandro F. Frangi and
               Jerry L. Prince},
  title     = {Registration of Pathological Images},
  booktitle = {Simulation and Synthesis in Medical Imaging - First International
               Workshop, {SASHIMI} 2016, Held in Conjunction with {MICCAI} 2016,
               Athens, Greece, October 21, 2016, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {9968},
  pages     = {97--107},
  year      = {2016},
  url       = {https://drive.google.com/file/d/1Va_n8o-k6t6ga_UAO0J-KhiQE_wqHU4O},
  doi       = {10.1007/978-3-319-46630-9\_10},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/YangHPAKN16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper proposes an approach to improve atlas-to-image registration accuracy with large pathologies. Instead of directly registering an atlas to a pathological image, the method learns a mapping from the pathological image to a quasi-normal image, for which more accurate registration is possible. Specifically, the method uses a deep variational convolutional encoder-decoder network to learn the mapping. Furthermore, the method estimates local mapping uncertainty through network inference statistics and uses those estimates to down-weight the image registration similarity measure in areas of high uncertainty. The performance of the method is quantified using synthetic brain tumor images and images from the brain tumor segmentation challenge (BRATS 2015).},
  keywords = {MICCAI,registration,brain,cancer}
}

@inproceedings{DBLP:conf/miccai/ZhaoPPNAR16,
  author    = {Qingyu Zhao and
               True Price and
               Stephen M. Pizer and
               Marc Niethammer and
               Ron Alterovitz and
               Julian G. Rosenman},
  editor    = {S{\'{e}}bastien Ourselin and
               Leo Joskowicz and
               Mert R. Sabuncu and
               G{\"{o}}zde B. {\"{U}}nal and
               William Wells},
  title     = {The Endoscopogram: {A} 3D Model Reconstructed from Endoscopic Video
               Frames},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2016 - 19th International Conference, Athens, Greece, October 17-21,
               2016, Proceedings, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {9900},
  pages     = {439--447},
  year      = {2016},
  url       = {https://drive.google.com/file/d/1K1fcQ5Kr9egmU2rxrSNaYEiXEPs797qg},
  doi       = {10.1007/978-3-319-46720-7\_51},
  timestamp = {Tue, 14 May 2019 10:00:49 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/ZhaoPPNAR16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Endoscopy enables high resolution visualization of tissue texture and is a critical step in many clinical workflows, including diagnosis and treatment planning for cancers in the nasopharynx. However, an endoscopic video does not provide 3D spatial information, making it difficult to use in tumor localization, and it is inefficient to review. We introduce a pipeline for automatically reconstructing a textured 3D surface model, which we call an endoscopogram, from multiple 2D endoscopic video frames. Our pipeline first reconstructs a partial 3D surface model for each input individual 2D frame. In the next step (which is the focus of this paper), we generate a single high-quality 3D surface model using a groupwise registration approach that fuses multiple, partially overlapping, incomplete and deformed surface models together. We generate endoscopograms from synthetic, phantom, and patient data and show that our registration approach can account for tissue deformations and reconstruction inconsistency across endoscopic video frames.},
  keywords = {endoscopy,MICCAI}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/YangKN16,
  author    = {Xiao Yang and
               Roland Kwitt and
               Marc Niethammer},
  title     = {Fast Predictive Image Registration},
  journal   = {CoRR},
  volume    = {abs/1607.02504},
  year      = {2016},
  url       = {http://arxiv.org/abs/1607.02504},
  archivePrefix = {arXiv},
  eprint    = {1607.02504},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/YangKN16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We present a method to predict image deformations based on patch-wise image appearance. Specifically, we design a patch-based deep encoder-decoder network which learns the pixel/voxel-wise mapping between image appearance and registration parameters. Our approach can predict general deformation parameterizations, however, we focus on the large deformation diffeomorphic metric mapping (LDDMM) registration model. By predicting the LDDMM momentum-parameterization we retain the desirable theoretical properties of LDDMM, while reducing computation time by orders of magnitude: combined with patch pruning, we achieve a 1500x/66x speed up compared to GPU-based optimization for 2D/3D image registration. Our approach has better prediction accuracy than predicting deformation or velocity fields and results in diffeomorphic transformations. Additionally, we create a Bayesian probabilistic version of our network, which allows evaluation of deformation field uncertainty through Monte Carlo sampling using dropout at test time. We show that deformation uncertainty highlights areas of ambiguous deformations. We test our method on the OASIS brain image dataset in 2D and 3D.}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/DixitKNV16,
  author    = {Mandar Dixit and
               Roland Kwitt and
               Marc Niethammer and
               Nuno Vasconcelos},
  title     = {{AGA:} Attribute Guided Augmentation},
  journal   = {CoRR},
  volume    = {abs/1612.02559},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.02559},
  archivePrefix = {arXiv},
  eprint    = {1612.02559},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/DixitKNV16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We consider the problem of data augmentation, i.e., generating artificial samples to extend a given corpus of training data. Specifically, we propose attributed-guided augmentation (AGA) which learns a mapping that allows to synthesize data such that an attribute of a synthesized sample is at a desired value or strength. This is particularly interesting in situations where little data with no attribute annotation is available for learning, but we have access to a large external corpus of heavily annotated samples. While prior works primarily augment in the space of images, we propose to perform augmentation in feature space instead. We implement our approach as a deep encoder-decoder architecture that learns the synthesis function in an end-to-end manner. We demonstrate the utility of our approach on the problems of (1) one-shot object recognition in a transfer-learning setting where we have no prior knowledge of the new classes, as well as (2) object-based one-shot scene recognition. As external data, we leverage 3D depth and pose information from the SUN RGB-D dataset. Our experiments show that attribute-guided augmentation of high-level CNN features considerably improves one-shot recognition performance on both problems.}
}

@article{DBLP:journals/cmig/VicoryCTBMWN15,
  author    = {Jared Vicory and
               Heather D. Couture and
               Nancy E. Thomas and
               David Borland and
               J. S. Marron and
               John T. Woosley and
               Marc Niethammer},
  title     = {Appearance normalization of histology slides},
  journal   = {Comput. Medical Imaging Graph.},
  volume    = {43},
  pages     = {89--98},
  year      = {2015},
  url       = {https://drive.google.com/file/d/1TdvNKBiYnndlTnEFZiBr6WTgyTHk_YCk},
  doi       = {10.1016/j.compmedimag.2015.03.005},
  timestamp = {Mon, 15 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/cmig/VicoryCTBMWN15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper presents a method for automatic color and intensity normalization of digitized histology slides stained with two different agents. In comparison to previous approaches, prior information on the stain vectors is used in the plane estimation process, resulting in improved stability of the estimates. Due to the prevalence of hematoxylin and eosin staining for histology slides, the proposed method has significant practical utility. In particular, it can be used as a first step to standardize appearance across slides and is effective at countering effects due to differing stain amounts and protocols and counteracting slide fading. The approach is validated against non-prior plane-fitting using synthetic experiments and 13 real datasets. Results of application of the method to adjustment of faded slides are given, and the effectiveness of the method in aiding statistical classification is shown.},
  keywords = {CMIG,histology}
}

@article{DBLP:journals/ijcv/TigheNL15,
  author    = {Joseph Tighe and
               Marc Niethammer and
               Svetlana Lazebnik},
  title     = {Scene Parsing with Object Instance Inference Using Regions and Per-exemplar
               Detectors},
  journal   = {Int. J. Comput. Vis.},
  volume    = {112},
  number    = {2},
  pages     = {150--171},
  year      = {2015},
  url       = {https://drive.google.com/file/d/1-upIJCKdAtTZrIH1MaRt5NK0qtgnGqMq},
  doi       = {10.1007/s11263-014-0778-5},
  timestamp = {Fri, 13 Mar 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/ijcv/TigheNL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper describes a system for interpreting a scene by assigning a semantic label at every pixel and inferring the spatial extent of individual object instances together with their occlusion relationships. First we present a method for labeling each pixel aimed at achieving broad coverage across hundreds of object categories, many of them sparsely sampled. This method combines region-level features with per-exemplar sliding window detectors. Unlike traditional bounding box detectors, per-exemplar detectors perform well on classes with little training data and high intra-class variation, and they allow object masks to be transferred into the test image for pixel-level segmentation. Next, we use per-exemplar detections to generate a set of candidate object masks for a given test image. We then select a subset of objects that explain the image well and have valid overlap relationships and occlusion ordering. This is done by minimizing an integer quadratic program either using a greedy method or a standard solver. We alternate between using the object predictions to refine the pixel labels and using the pixel labels to improve the object predictions. The proposed system obtains promising results on two challenging subsets of the LabelMe dataset, the largest of which contains 45,676 images and 232 classes.},
  keywords = {IJCV}
}

@article{DBLP:journals/mia/HongGNB15,
  author    = {Yi Hong and
               Yi Gao and
               Marc Niethammer and
               Sylvain Bouix},
  title     = {Shape analysis based on depth-ordering},
  journal   = {Medical Image Anal.},
  volume    = {25},
  number    = {1},
  pages     = {2--10},
  year      = {2015},
  url       = {https://drive.google.com/file/d/1vyphsC5iO5VIx1tS6yPweFhvVpPSHtZT},
  doi       = {10.1016/j.media.2015.04.004},
  timestamp = {Mon, 24 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/mia/HongGNB15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper we propose a new method for shape analysis based on the ordering of shapes using band-depth. We use this band-depth to non-parametrically define a global depth for a shape with respect to a reference population, typically consisting of normal control subjects. This allows us to globally quantify differences with respect to “normality”. Using the depth-ordering of shapes also allows the detection of localized shape differences by using α-central values of shapes. We propose permutation tests to statistically assess global and local shape differences. We further determine the directionality of shape differences (local inflation versus deflation). The method is evaluated on a synthetically generated striatum dataset, and applied to detect shape differences in the hippocampus between subjects with first-episode schizophrenia and normal controls.},
  keywords = {MEDIA,shape,brain}
}

@article{DBLP:journals/mia/SinghVN15,
  author    = {Nikhil Singh and
               Fran{\c{c}}ois{-}Xavier Vialard and
               Marc Niethammer},
  title     = {Splines for diffeomorphisms},
  journal   = {Medical Image Anal.},
  volume    = {25},
  number    = {1},
  pages     = {56--71},
  year      = {2015},
  url       = {https://drive.google.com/file/d/1eWE0vGemtD5a-eIp48qNGwT33Sal_t-2},
  doi       = {10.1016/j.media.2015.04.012},
  timestamp = {Mon, 24 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/mia/SinghVN15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper develops a method for higher order parametric regression on diffeomorphisms for image regression. We present a principled way to define curves with nonzero acceleration and nonzero jerk. This work extends methods based on geodesics which have been developed during the last decade for computational anatomy in the large deformation diffeomorphic image analysis framework. In contrast to previously proposed methods to capture image changes over time, such as geodesic regression, the proposed method can capture more complex spatio-temporal deformations. We take a variational approach that is governed by an underlying energy formulation, which respects the nonflat geometry of diffeomorphisms. Such an approach of minimal energy curve estimation also provides a physical analogy to particle motion under a varying force field. This gives rise to the notion of the quadratic, the cubic and the piecewise cubic splines on the manifold of diffeomorphisms. The variational formulation of splines also allows for the use of temporal control points to control spline behavior. This necessitates the development of a shooting formulation for splines. The initial conditions of our proposed shooting polynomial paths in diffeomorphisms are analogous to the Euclidean polynomial coefficients. We experimentally demonstrate the effectiveness of using the parametric curves both for synthesizing polynomial paths and for regression of imaging data. The performance of the method is compared to geodesic regression.},
  keywords = {registration,brain,MEDIA}
}

@article{DBLP:journals/tmi/HuangSCWNZ15,
  author    = {Chao Huang and
               Liang Shan and
               Cecil Charles and
               Wolfgang Wirth and
               Marc Niethammer and
               Hongtu Zhu},
  title     = {Diseased Region Detection of Longitudinal Knee Magnetic Resonance
               Imaging Data},
  journal   = {{IEEE} Trans. Medical Imaging},
  volume    = {34},
  number    = {9},
  pages     = {1914--1927},
  year      = {2015},
  url       = {https://drive.google.com/file/d/1Ein6gq0VDoLqcr00Xr2Py7gZRj-mvC7r},
  doi       = {10.1109/TMI.2015.2415675},
  timestamp = {Thu, 18 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/tmi/HuangSCWNZ15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Magnetic resonance imaging (MRI) has become an important imaging technique for quantifying the spatial location and magnitude/direction of longitudinal cartilage morphology changes in patients with osteoarthritis (OA). Although several analytical methods, such as subregion-based analysis, have been developed to refine and improve quantitative cartilage analyses, they can be suboptimal due to two major issues: the lack of spatial correspondence across subjects and time and the spatial heterogeneity of cartilage progression across subjects. The aim of this paper is to present a statistical method for longitudinal cartilage quantification in OA patients, while addressing these two issues. The 3D knee image data is preprocessed to establish spatial correspondence across subjects and/or time. Then, a Gaussian hidden Markov model (GHMM) is proposed to deal with the spatial heterogeneity of cartilage progression across both time and OA subjects. To estimate unknown parameters in GHMM, we employ a pseudo-likelihood function and optimize it by using an expectation-maximization (EM) algorithm. The proposed model can effectively detect diseased regions in each OA subject and present a localized analysis of longitudinal cartilage thickness within each latent subpopulation. Our GHMM integrates the strengths of two standard statistical methods including the local subregion-based analysis and the ordered value approach. We use simulation studies and the Pfizer longitudinal knee MRI dataset to evaluate the finite sample performance of GHMM in the quantification of longitudinal cartilage morphology changes. Our results indicate that GHMM significantly outperforms several standard analytical methods.},
  keywords = {statistics,knee,TMI}
}

@inproceedings{DBLP:conf/ipmi/HongSKN15,
  author    = {Yi Hong and
               Nikhil Singh and
               Roland Kwitt and
               Marc Niethammer},
  editor    = {S{\'{e}}bastien Ourselin and
               Daniel C. Alexander and
               Carl{-}Fredrik Westin and
               Manuel Jorge Cardoso},
  title     = {Group Testing for Longitudinal Data},
  booktitle = {Information Processing in Medical Imaging - 24th International Conference,
               {IPMI} 2015, Sabhal Mor Ostaig, Isle of Skye, UK, June 28 - July 3,
               2015, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {9123},
  pages     = {139--151},
  publisher = {Springer},
  year      = {2015},
  url       = {https://drive.google.com/file/d/1kGMq1fxPEyqd757LLBQvluNBp0iGx3Bm},
  doi       = {10.1007/978-3-319-19992-4\_11},
  timestamp = {Tue, 14 May 2019 10:00:52 +0200},
  biburl    = {https://dblp.org/rec/conf/ipmi/HongSKN15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We consider how to test for group differences of shapes given longitudinal data. In particular, we are interested in differences of longitudinal models of each group’s subjects. We introduce a generalization of principal geodesic analysis to the tangent bundle of a shape space. This allows the estimation of the variance and principal directions of the distribution of trajectories that summarize shape variations within the longitudinal data. Each trajectory is parameterized as a point in the tangent bundle. To study statistical differences in two distributions of trajectories, we generalize the Bhattacharyya distance in Euclidean space to the tangent bundle. This not only allows to take second-order statistics into account, but also serves as our test-statistic during permutation testing. Our method is validated on both synthetic and real data, and the experimental results indicate improved statistical power in identifying group differences. In fact, our study sheds new light on group differences in longitudinal corpus callosum shapes of subjects with dementia versus normal controls.},
  keywords = {IPMI,statistics,shape,brain}
}

@inproceedings{DBLP:conf/isbi/CaoSJN15,
  author    = {Tian Cao and
               Nikhil Singh and
               Vladimir Jojic and
               Marc Niethammer},
  title     = {Semi-coupled dictionary learning for deformation prediction},
  booktitle = {12th {IEEE} International Symposium on Biomedical Imaging, {ISBI}
               2015, Brooklyn, NY, USA, April 16-19, 2015},
  pages     = {691--694},
  publisher = {{IEEE}},
  year      = {2015},
  url       = {https://drive.google.com/file/d/1y6QnGk1uy3z2jWRv5lRVxP2RZb7Z0Fcf},
  doi       = {10.1109/ISBI.2015.7163967},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/CaoSJN15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We propose a coupled dictionary learning method to predict deformation fields based on image appearance. Rather than estimating deformations by standard image registration methods, we investigate how to obtain a basis of the space of deformations. In particular, we explore how image appearance differences with respect to a common atlas image can be used to predict deformations represented by such a basis. We use a coupled dictionary learning method to jointly learn a basis for image appearance differences and their related deformations. Our proposed method is based on local image patches. We evaluate our method on synthetically generated datasets as well as on a structural magnetic resonance brain imaging (MRI) dataset. Our method results in an improved prediction accuracy while reducing the search space compared to nearest neighbor search and demonstrates that learning a deformation basis is feasible.},
  keywords = {registration,ISBI}
}

@inproceedings{DBLP:conf/isbi/CoutureMTPN15,
  author    = {Heather D. Couture and
               J. S. Marron and
               Nancy E. Thomas and
               Charles M. Perou and
               Marc Niethammer},
  title     = {Hierarchical task-driven feature learning for tumor histology},
  booktitle = {12th {IEEE} International Symposium on Biomedical Imaging, {ISBI}
               2015, Brooklyn, NY, USA, April 16-19, 2015},
  pages     = {999--1003},
  publisher = {{IEEE}},
  year      = {2015},
  url       = {https://drive.google.com/file/d/12yBl1GD3E7s2tyHUEQ1ShMaMj1VaRPwd},
  doi       = {10.1109/ISBI.2015.7164039},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/CoutureMTPN15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Through learning small and large-scale image features, we can capture the local and architectural structure of tumor tissue from histology images. This is done by learning a hierarchy of dictionaries using sparse coding, where each level captures progressively larger scale and more abstract properties. By optimizing the dictionaries further using class labels, discriminating properties of classes that are not easily visually distinguishable to pathologists are captured. We explore this hierarchical and task-driven model in classifying malignant melanoma and the genetic subtype of breast tumors from histology images. We also show how interpreting our model through visualizations can provide insight to pathologists.},
  keywords = {cancer,ISBI,histology}
}

@inproceedings{DBLP:conf/miccai/YangN15,
  author    = {Xiao Yang and
               Marc Niethammer},
  editor    = {Nassir Navab and
               Joachim Hornegger and
               William M. Wells III and
               Alejandro F. Frangi},
  title     = {Uncertainty Quantification for {LDDMM} Using a Low-Rank Hessian Approximation},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2015 - 18th International Conference Munich, Germany, October 5-9,
               2015, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {9350},
  pages     = {289--296},
  publisher = {Springer},
  year      = {2015},
  url       = {https://drive.google.com/file/d/17f379uvZrqjlgaAKSg_NrlzMAYS-KIvL},
  doi       = {10.1007/978-3-319-24571-3\_35},
  timestamp = {Tue, 14 May 2019 10:00:50 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/YangN15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper presents an approach to estimate the uncertainty of registration parameters for the large displacement diffeomorphic metric mapping (LDDMM) registration framework. Assuming a local multivariate Gaussian distribution as an approximation for the registration energy at the optimal registration parameters, we propose a method to approximate the covariance matrix as the inverse of the Hessian of the registration energy to quantify registration uncertainty. In particular, we make use of a low-rank approximation to the Hessian to accurately and efficiently estimate the covariance matrix using few eigenvalues and eigenvectors. We evaluate the uncertainty of the LDDMM registration results for both synthetic and real imaging data.},
  keywords = {LDDMM,MICCAI,uncertainty,brain}
}

@inproceedings{DBLP:conf/miccai/HongKN15,
  author    = {Yi Hong and
               Roland Kwitt and
               Marc Niethammer},
  editor    = {Nassir Navab and
               Joachim Hornegger and
               William M. Wells III and
               Alejandro F. Frangi},
  title     = {Model Criticism for Regression on the Grassmannian},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2015 - 18th International Conference Munich, Germany, October 5 -
               9, 2015, Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {9351},
  pages     = {727--734},
  publisher = {Springer},
  year      = {2015},
  url       = {https://drive.google.com/file/d/1kEdNNaW4Tgt38hEzqHU539Bo5HRYnMhY},
  doi       = {10.1007/978-3-319-24574-4\_87},
  timestamp = {Sun, 02 Jun 2019 21:24:41 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/HongKN15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Reliable estimation of model parameters from data requires a suitable model. In this work, we investigate and extend a recent model criticism approach to evaluate regression models on the Grassmann manifold. Model criticism allows us to check if a model fits and if the underlying model assumptions are justified by the observed data. This is a critical step to check model validity which is often neglected in practice. Using synthetic data we demonstrate that the proposed model criticism approach can indeed reject models that are improper for observed data and that the approach can guide the model selection process. We study two real applications: degeneration of corpus callosum shapes during aging and developmental shape changes in the rat calvarium. Our experimental results suggest that the three tested regression models on the Grassmannian (equivalent to linear, time-warped, and cubic-spline regression in Rn , respectively) can all capture changes of the corpus callosum, but only the cubic-spline model is appropriate for shape changes of the rat calvarium. While our approach is developed for the Grassmannian, the principles are applicable to smooth manifolds in general.},
  keywords = {regression,statistics,MICCAI,brain}
}

@inproceedings{DBLP:conf/miua/ZhaoPPNAR15,
  author    = {Qingyu Zhao and
               James Price and
               Stephen M. Pizer and
               Marc Niethammer and
               Ron Alterovitz and
               Julian G. Rosenman},
  editor    = {Tryphon Lambrou and
               Xujiong Ye},
  title     = {Surface Registration in the Presence of Missing Patches and Topology
               Change},
  booktitle = {Medical Image Understanding and Analysis - {MIUA} 2015. 19th Annual
               Conference, University of Lincoln, Lincoln, UK, July 15-17, 2015},
  pages     = {8--13},
  publisher = {{BMVA}},
  year      = {2015},
  url = {https://drive.google.com/file/d/1ODF45LpwsgstuVo50ruJ-bBjXftKx7QG},
  timestamp = {Thu, 12 Mar 2020 11:30:50 +0100},
  biburl    = {https://dblp.org/rec/conf/miua/ZhaoPPNAR15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {The fusion between an endoscopic movie and a CT poses a special surface registration problem. The surface extracted from CT is complete and accurate, whereas the surface extracted from endoscopy suffers from serious missing patches and topology change. We propose a surface registration method, Thin Shell Demons, that is robust under these two situations. Motivated by Thirion’s Demons idea, the partial surface can provide virtual forces to attract the complete surface, which is equipped with a novel physics-based deformation energy. This energy can help preserve the correct surface topology while producing realistic deformation for the regions that don’t have any attracting counterpart regions. The attraction direction assures the deformation is not affected by the surface completeness. Moreover, we propose to use geometric feature matching for computing virtual forces to handle inaccurate 3D point positions and large deformations. We test our method for CT/endoscope fusion and show its potential to achieve successful registration.},
  keywords = {MIUA,registration,endoscopy}
}

@inproceedings{DBLP:conf/nips/KwittHNLB15,
  author    = {Roland Kwitt and
               Stefan Huber and
               Marc Niethammer and
               Weili Lin and
               Ulrich Bauer},
  editor    = {Corinna Cortes and
               Neil D. Lawrence and
               Daniel D. Lee and
               Masashi Sugiyama and
               Roman Garnett},
  title     = {Statistical Topological Data Analysis - {A} Kernel Perspective},
  booktitle = {Advances in Neural Information Processing Systems 28: Annual Conference
               on Neural Information Processing Systems 2015, December 7-12, 2015,
               Montreal, Quebec, Canada},
  pages     = {3070--3078},
  year      = {2015},
  url       = {https://drive.google.com/file/d/11aN0VcGricPkzHHvio47uv35qc8KKj8F},
  timestamp = {Fri, 06 Mar 2020 16:56:52 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/KwittHNLB15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We consider the problem of statistical computations with persistence diagrams, a summary representation of topological features in data. These diagrams encode persistent homology, a widely used invariant in topological data analysis. While several avenues towards a statistical treatment of the diagrams have been explored recently, we follow an alternative route that is motivated by the success of methods based on the embedding of probability measures into reproducing kernel Hilbert spaces. In fact, a positive definite kernel on persistence diagrams has recently been proposed, connecting persistent homology to popular kernel-based learning techniques such as support vector machines. However, important properties of that kernel which would enable a principled use in the context of probability measure embeddings remain to be explored. Our contribution is to close this gap by proving universality of a variant of the original kernel, and to demonstrate its effective use in two-sample hypothesis testing on synthetic as well as real-world data.},
  keywords = {NeurIPS,topology}
}

@proceedings{DBLP:conf/miccai/2014stia,
  editor    = {Stanley Durrleman and
               Tom Fletcher and
               Guido Gerig and
               Marc Niethammer and
               Xavier Pennec},
  title     = {Spatio-temporal Image Analysis for Longitudinal and Time-Series Image
               Data - Third International Workshop, {STIA} 2014, Held in Conjunction
               with {MICCAI} 2014, Boston, MA, USA, September 18, 2014, Revised Selected
               Papers},
  series    = {Lecture Notes in Computer Science},
  volume    = {8682},
  publisher = {Springer},
  year      = {2015},
  url       = {https://doi.org/10.1007/978-3-319-14905-9},
  doi       = {10.1007/978-3-319-14905-9},
  isbn      = {978-3-319-14904-2},
  timestamp = {Tue, 14 May 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/2014stia.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This book constitutes the thoroughly refereed post-conference proceedings of the Third International Workshop on Spatio-temporal Image Analysis for Longitudinal and Time-Series Image Data, STIA 2014, held in conjunction with MICCAI 2014 in Boston, MA, USA, in September 2014. The 7 papers presented in this volume were carefully reviewed and selected from 15 submissions. They are organized in topical sections named: longitudinal registration and shape modeling, longitudinal modeling, reconstruction from longitudinal data, and 4D image processing.},
  keywords = {MICCAI}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/NiethammerPJW15,
  author    = {Marc Niethammer and
               Kilian M. Pohl and
               Firdaus Janoos and
               William M. Wells III},
  title     = {Active Mean Fields for Probabilistic Image Segmentation: Connections
               with Chan-Vese and Rudin-Osher-Fatemi Models},
  journal   = {CoRR},
  volume    = {abs/1501.05680},
  year      = {2015},
  url       = {https://drive.google.com/file/d/1XmG1d80oZRORqwCuMd1Zivy8g2R-WDiu},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/NiethammerPJW15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Segmentation is a fundamental task for extracting semantically meaningful regions from an image. The goal of segmentation algorithms is to accurately assign object labels to each image location. However, image-noise, shortcomings of algorithms, and image ambiguities cause uncertainty in label assignment. Estimating the uncertainty in label assignment is important in multiple application domains, such as segmenting tumors from medical images for radiation treatment planning. One way to estimate these uncertainties is through the computation of posteriors of Bayesian models, which is computationally prohibitive for many practical applications. On the other hand, most computationally efficient methods fail to estimate label uncertainty. We therefore propose in this paper the Active Mean Fields (AMF) approach, a technique based on Bayesian modeling that uses a mean-field approximation to efficiently compute a segmentation and its corresponding uncertainty. Based on a variational formulation, the resulting convex model combines any label-likelihood measure with a prior on the length of the segmentation boundary. A specific implementation of that model is the Chan–Vese segmentation model (CV), in which the binary segmentation task is defined by a Gaussian likelihood and a prior regularizing the length of the segmentation boundary. Furthermore, the Euler–Lagrange equations derived from the AMF model are equivalent to those of the popular Rudin-Osher-Fatemi (ROF) model for image denoising. Solutions to the AMF model can thus be implemented by directly utilizing highlyefficient ROF solvers on log-likelihood ratio fields. We qualitatively assess the approach on synthetic data as well as on real natural and medical images. For a quantitative evaluation, we apply our approach to the icgbench dataset.}
}

# commented out as already included as regular paper
article{DBLP:journals/corr/HongSKVN15,
  author    = {Yi Hong and
               Nikhil Singh and
               Roland Kwitt and
               Nuno Vasconcelos and
               Marc Niethammer},
  title     = {Parametric Regression on the Grassmannian},
  journal   = {CoRR},
  volume    = {abs/1505.03832},
  year      = {2015},
  url       = {http://arxiv.org/abs/1505.03832},
  archivePrefix = {arXiv},
  eprint    = {1505.03832},
  timestamp = {Mon, 13 Aug 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HongSKVN15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We address the problem of fitting parametric curves on the Grassmann manifold for the purpose of intrinsic parametric regression. As customary in the literature, we start from the energy minimization formulation of linear least-squares in Euclidean spaces and generalize this concept to general nonflat Riemannian manifolds, following an optimal-control point of view. We then specialize this idea to the Grassmann manifold and demonstrate that it yields a simple, extensible and easy-to-implement solution to the parametric regression problem. In fact, it allows us to extend the basic geodesic model to (1) a “time-warped” variant and (2) cubic splines. We demonstrate the utility of the proposed solution on different vision problems, such as shape regression as a function of age, trafficspeed estimation and crowd-counting from surveillance video clips. Most notably, these problems can be conveniently solved within the same framework without any specifically-tailored steps along the processing pipeline.}}
}

@article{DBLP:journals/mia/HongDMKSKPSDZN14,
  author    = {Yi Hong and
               Brad Davis and
               J. S. Marron and
               Roland Kwitt and
               Nikhil Singh and
               Julia S. Kimbell and
               Elizabeth Pitkin and
               Richard Superfine and
               Stephanie Davis and
               Carlton J. Zdanski and
               Marc Niethammer},
  title     = {Statistical atlas construction via weighted functional boxplots},
  journal   = {Medical Image Anal.},
  volume    = {18},
  number    = {4},
  pages     = {684--698},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1Fpw2HBq8Hq0fRl4G_tU6QTjxhm5PLJt6},
  doi       = {10.1016/j.media.2014.03.001},
  timestamp = {Mon, 24 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/mia/HongDMKSKPSDZN14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Atlas-building from population data is widely used in medical imaging. However, the emphasis of atlas-building approaches is typically to estimate a spatial alignment to compute a mean / median shape or image based on population data. In this work, we focus on the statistical characterization of the population data, once spatial alignment has been achieved. We introduce and propose the use of the weighted functional boxplot. This allows the generalization of concepts such as the median, percentiles, or outliers to spaces where the data objects are functions, shapes, or images, and allows spatio-temporal atlas-building based on kernel regression. In our experiments, we demonstrate the utility of the approach to construct statistical atlases for pediatric upper airways and corpora callosa revealing their growth patterns. We also define a score system based on the pediatric airway atlas to quantitatively measure the severity of subglottic stenosis (SGS) in the airway. This scoring allows the classification of pre- and post-surgery SGS subjects and radiographically normal controls. Experimental results show the utility of atlas information to assess the effect of airway surgery in children.},
  keywords = {shape,statistics,MEDIA,airway}
}

@article{DBLP:journals/mia/CaoZMPCN14,
  author    = {Tian Cao and
               Christopher Zach and
               Shannon Modla and
               Debbie Powell and
               Kirk Czymmek and
               Marc Niethammer},
  title     = {Multi-modal registration for correlative microscopy using image analogies},
  journal   = {Medical Image Anal.},
  volume    = {18},
  number    = {6},
  pages     = {914--926},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1S8bDBmZaWI7PfAKF26sBb9WYdeKdyzGu},
  doi       = {10.1016/j.media.2013.12.005},
  timestamp = {Mon, 24 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/mia/CaoZMPCN14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Correlative microscopy is a methodology combining the functionality of light microscopy with the high resolution of electron microscopy and other microscopy technologies for the same biological specimen. In this paper, we propose an image registration method for correlative microscopy, which is challenging due to the distinct appearance of biological structures when imaged with different modalities. Our method is based on image analogies and allows to transform images of a given modality into the appearance-space of another modality. Hence, the registration between two different types of microscopy images can be transformed to a mono-modality image registration. We use a sparse representation model to obtain image analogies. The method makes use of corresponding image training patches of two different imaging modalities to learn a dictionary capturing appearance relations. We test our approach on backscattered electron (BSE) scanning electron microscopy (SEM)/confocal and transmission electron microscopy (TEM)/ confocal images. We perform rigid, affine, and deformable registration via B-splines and show improvements over direct registration using both mutual information and sum of squared differences similarity measures to account for differences in image appearance.},
  keywords = {MEDIA,registration,microscopy}
}

@article{DBLP:journals/mia/ShanZCN14,
  author    = {Liang Shan and
               Christopher Zach and
               Cecil Charles and
               Marc Niethammer},
  title     = {Automatic atlas-based three-label cartilage segmentation from {MR}
               knee images},
  journal   = {Medical Image Anal.},
  volume    = {18},
  number    = {7},
  pages     = {1233--1246},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1ObKIWJ881A_-fgEpVnAu5Yc2M6OsHh9H},
  doi       = {10.1016/j.media.2014.05.008},
  timestamp = {Mon, 24 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/mia/ShanZCN14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Osteoarthritis (OA) is the most common form of joint disease and often characterized by cartilage changes. Accurate quantitative methods are needed to rapidly screen large image databases to assess changes in cartilage morphology. We therefore propose a new automatic atlas-based cartilage segmentation method for future automatic OA studies. Atlas-based segmentation methods have been demonstrated to be robust and accurate in brain imaging and therefore also hold high promise to allow for reliable and high-quality segmentations of cartilage. Nevertheless, atlas-based methods have not been well explored for cartilage segmentation. A particular challenge is the thinness of cartilage, its relatively small volume in comparison to surrounding tissue and the difficulty to locate cartilage interfaces – for example the interface between femoral and tibial cartilage. This paper focuses on the segmentation of femoral and tibial cartilage, proposing a multi-atlas segmentation strategy with non-local patch-based label fusion which can robustly identify candidate regions of cartilage. This method is combined with a novel three-label segmentation method which guarantees the spatial separation of femoral and tibial cartilage, and ensures spatial regularity while preserving the thin cartilage shape through anisotropic regularization. Our segmentation energy is convex and therefore guarantees globally optimal solutions. We perform an extensive validation of the proposed method on 706 images of the Pfizer Longitudinal Study. Our validation includes comparisons of different atlas segmentation strategies, different local classifiers, and different types of regularizers. To compare to other cartilage segmentation approaches we validate based on the 50 images of the SKI10 dataset.},
  keywords = {MEDIA,atlas,knee,segmentation}
}

@article{DBLP:journals/mia/ZhangNSY14,
  author    = {Pei Zhang and
               Marc Niethammer and
               Dinggang Shen and
               Pew{-}Thian Yap},
  title     = {Large deformation diffeomorphic registration of diffusion-weighted
               imaging data},
  journal   = {Medical Image Anal.},
  volume    = {18},
  number    = {8},
  pages     = {1290--1298},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1HEehA-fEACphT4OgYd6L_H9uEGDKap_d},
  doi       = {10.1016/j.media.2014.06.012},
  timestamp = {Mon, 24 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/mia/ZhangNSY14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We seek to compute a diffeomorphic map between a pair of diffusion-weighted images under large deformation. Unlike existing techniques, our method allows any diffusion model to be fitted after registration for subsequent multifaceted analysis. This is achieved by directly aligning the diffusion-weighted images using a large deformation diffeomorphic registration framework formulated from an optimal control perspective. Our algorithm seeks the optimal coordinate mapping by simultaneously considering structural alignment, local fiber reorientation, and deformation regularization. Our algorithm also incorporates a multi-kernel strategy to concurrently register anatomical structures of different scales. We demonstrate the efficacy of our approach using in vivo data and report on detailed qualitative and quantitative results in comparison with several different registration strategies.},
  keywords = {LDDMM,brain,MEDIA}
}

@article{DBLP:journals/tmi/KwonNABDP14,
  author    = {Dongjin Kwon and
               Marc Niethammer and
               Hamed Akbari and
               Michel Bilello and
               Christos Davatzikos and
               Kilian M. Pohl},
  title     = {{PORTR:} Pre-Operative and Post-Recurrence Brain Tumor Registration},
  journal   = {{IEEE} Trans. Medical Imaging},
  volume    = {33},
  number    = {3},
  pages     = {651--667},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1QpPdXd4emgVQldvthrZ3njHJvQnETfhv},
  doi       = {10.1109/TMI.2013.2293478},
  timestamp = {Thu, 18 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/tmi/KwonNABDP14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We propose a new method for deformable registration of pre-operative and post-recurrence brain MR scans of glioma patients. Performing this type of intra-subject registration is challenging as tumor, resection, recurrence, and edema cause large deformations, missing correspondences, and inconsistent intensity profiles between the scans. To address this challenging task, our method, called PORTR, explicitly accounts for pathological information. It segments tumor, resection cavity, and recurrence based on models specific to each scan. PORTR then uses the resulting maps to exclude pathological regions from the image-based correspondence term while simultaneously measuring the overlap between the aligned tumor and resection cavity. Embedded into a symmetric registration framework, we determine the optimal solution by taking advantage of both discrete and continuous search methods. We apply our method to scans of 24 glioma patients. Both quantitative and qualitative analysis of the results clearly show that our method is superior to other state-of-the-art approaches.},
  keywords = {cancer,brain,TMI}
}

@inproceedings{DBLP:conf/cvpr/TigheNL14,
  author    = {Joseph Tighe and
               Marc Niethammer and
               Svetlana Lazebnik},
  title     = {Scene Parsing with Object Instances and Occlusion Ordering},
  booktitle = {2014 {IEEE} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2014, Columbus, OH, USA, June 23-28, 2014},
  pages     = {3748--3755},
  publisher = {{IEEE} Computer Society},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1g7seimbTRymr-ebNJ6rvhBSAFolL7Tep},
  doi       = {10.1109/CVPR.2014.479},
  timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/TigheNL14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This work proposes a method to interpret a scene by assigning a semantic label at every pixel and inferring the spatial extent of individual object instances together with their occlusion relationships. Starting with an initial pixel labeling and a set of candidate object masks for a given test image, we select a subset of objects that explain the image well and have valid overlap relationships and occlusion ordering. This is done by minimizing an integer quadratic program either using a greedy method or a standard solver. Then we alternate between using the object predictions to refine the pixel labels and vice versa. The proposed system obtains promising results on two challenging subsets of the LabelMe and SUN datasets, the largest of which contains 45,676 images and 232 classes.},
  keywords = {CVPR}
}

@inproceedings{DBLP:conf/eccv/HongKSDVN14,
  author    = {Yi Hong and
               Roland Kwitt and
               Nikhil Singh and
               Brad Davis and
               Nuno Vasconcelos and
               Marc Niethammer},
  editor    = {David J. Fleet and
               Tom{\'{a}}s Pajdla and
               Bernt Schiele and
               Tinne Tuytelaars},
  title     = {Geodesic Regression on the Grassmannian},
  booktitle = {Computer Vision - {ECCV} 2014 - 13th European Conference, Zurich,
               Switzerland, September 6-12, 2014, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8690},
  pages     = {632--646},
  publisher = {Springer},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1OCYe4ekxKt01Qcys2Fk5WsfzHqZP1SZ7},
  doi       = {10.1007/978-3-319-10605-2\_41},
  timestamp = {Mon, 15 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/eccv/HongKSDVN14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper considers the problem of regressing data points on the Grassmann manifold over a scalar-valued variable. The Grassmannian has recently gained considerable attention in the vision community with applications in domain adaptation, face recognition, shape analysis, or the classification of linear dynamical systems. Motivated by the success of these approaches, we introduce a principled formulation for regression tasks on that manifold. We propose an intrinsic geodesic regression model generalizing classical linear least-squares regression. Since geodesics are parametrized by a starting point and a velocity vector, the model enables the synthesis of new observations on the manifold. To exemplify our approach, we demonstrate its applicability on three vision problems where data objects can be represented as points on the Grassmannian: the prediction of traffic speed and crowd counts from dynamical system models of surveillance videos and the modeling of aging trends in human brain structures using an affine-invariant shape representation.},
  keywords = {ECCV,regression}
}

@inproceedings{DBLP:conf/miccai/HongGNB14,
  author    = {Yi Hong and
               Yi Gao and
               Marc Niethammer and
               Sylvain Bouix},
  editor    = {Polina Golland and
               Nobuhiko Hata and
               Christian Barillot and
               Joachim Hornegger and
               Robert D. Howe},
  title     = {Depth-Based Shape-Analysis},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2014 - 17th International Conference, Boston, MA, USA, September 14-18,
               2014, Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8675},
  pages     = {17--24},
  publisher = {Springer},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1JABdv78b4Tw0vDsrvfKEONQE6uBm8FA-},
  doi       = {10.1007/978-3-319-10443-0\_3},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/HongGNB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper we propose a new method for shape analysis based on the depth-ordering of shapes. We use this depth-ordering to non-parametrically define depth with respect to a normal control population. This allows us to quantify differences with respect to “normality”. We combine this approach with a permutation test allowing it to test for localized shape differences. The method is evaluated on a synthetically generated striatum dataset as well as on a real caudate dataset.},
  keywords = {MICCAI,statistics,shape,brain}
}

@inproceedings{DBLP:conf/miccai/LiuNKMA14,
  author    = {Xiaoxiao Liu and
               Marc Niethammer and
               Roland Kwitt and
               Matthew McCormick and
               Stephen R. Aylward},
  editor    = {Polina Golland and
               Nobuhiko Hata and
               Christian Barillot and
               Joachim Hornegger and
               Robert D. Howe},
  title     = {Low-Rank to the Rescue - Atlas-Based Analyses in the Presence of Pathologies},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2014 - 17th International Conference, Boston, MA, USA, September 14-18,
               2014, Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8675},
  pages     = {97--104},
  publisher = {Springer},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1oR8cxmC_wMXZPjQgYw4aCZOOzDoLekTB},
  doi       = {10.1007/978-3-319-10443-0\_13},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/LiuNKMA14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Low-rank image decomposition has the potential to address a broad range of challenges that routinely occur in clinical practice. Its novelty and utility in the context of atlas-based analysis stems from its ability to handle images containing large pathologies and large deformations. Potential applications include atlas-based tissue segmentation and unbiased atlas building from data containing pathologies. In this paper we present atlas-based tissue segmentation of MRI from patients with large pathologies. Specifically, a healthy brain atlas is registered with the low-rank components from the input MRIs, the low-rank components are then re-computed based on those registrations, and the process is then iteratively repeated. Preliminary evaluations are conducted using the brain tumor segmentation challenge data (BRATS ’12).},
  keywords = {MICCAI,cancer,registration,brain}
}

@inproceedings{DBLP:conf/miccai/HongSKN14,
  author    = {Yi Hong and
               Nikhil Singh and
               Roland Kwitt and
               Marc Niethammer},
  editor    = {Polina Golland and
               Nobuhiko Hata and
               Christian Barillot and
               Joachim Hornegger and
               Robert D. Howe},
  title     = {Time-Warped Geodesic Regression},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2014 - 17th International Conference, Boston, MA, USA, September 14-18,
               2014, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8674},
  pages     = {105--112},
  publisher = {Springer},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1w9D7cI2RRlXk0eJkAysEBPDdur321qZw},
  doi       = {10.1007/978-3-319-10470-6\_14},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/HongSKN14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We consider geodesic regression with parametric time-warps. This allows, for example, to capture saturation effects as typically observed during brain development or degeneration. While highly-flexible models to analyze time-varying image and shape data based on generalizations of splines and polynomials have been proposed recently, they come at the cost of substantially more complex inference. Our focus in this paper is therefore to keep the model and its inference as simple as possible while allowing to capture expected biological variation. We demonstrate that by augmenting geodesic regression with parametric time-warp functions, we can achieve comparable flexibility to more complex models while retaining model simplicity. In addition, the time-warp parameters provide useful information of underlying anatomical changes as demonstrated for the analysis of corpora callosa and rat calvariae. We exemplify our strategy for shape regression on the Grassmann manifold, but note that the method is generally applicable for time-warped geodesic regression.},
  keywords = {MICCAI,regression,shape,brain}
}

@inproceedings{DBLP:conf/miccai/SinghN14,
  author    = {Nikhil Singh and
               Marc Niethammer},
  editor    = {Polina Golland and
               Nobuhiko Hata and
               Christian Barillot and
               Joachim Hornegger and
               Robert D. Howe},
  title     = {Splines for Diffeomorphic Image Regression},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2014 - 17th International Conference, Boston, MA, USA, September 14-18,
               2014, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8674},
  pages     = {121--129},
  publisher = {Springer},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1On3_bNVI7SPAWwQXQqahS2fW43pHd6mj},
  doi       = {10.1007/978-3-319-10470-6\_16},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/SinghN14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper develops a method for splines on diffeomorphisms for image regression. In contrast to previously proposed methods to capture image changes over time, such as geodesic regression, the method can capture more complex spatio-temporal deformations. In particular, it is a first step towards capturing periodic motions for example of the heart or the lung. Starting from a variational formulation of splines the proposed approach allows for the use of temporal control points to control spline behavior. This necessitates the development of a shooting formulation for splines. Experimental results are shown for synthetic and real data. The performance of the method is compared to geodesic regression.},
  keywords = {MICCAI,regression}
}

@inproceedings{DBLP:conf/miccai/SinghCMPN14,
  author    = {Nikhil Singh and
               Heather D. Couture and
               J. S. Marron and
               Charles M. Perou and
               Marc Niethammer},
  editor    = {Guorong Wu and
               Daoqiang Zhang and
               Luping Zhou},
  title     = {Topological Descriptors of Histology Images},
  booktitle = {Machine Learning in Medical Imaging - 5th International Workshop,
               {MLMI} 2014, Held in Conjunction with {MICCAI} 2014, Boston, MA, USA,
               September 14, 2014. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {8679},
  pages     = {231--239},
  publisher = {Springer},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1xtbqJ8BWvJIc5RNP-VCzPqYDqZpQoK47},
  doi       = {10.1007/978-3-319-10581-9\_29},
  timestamp = {Sun, 02 Jun 2019 21:24:45 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/SinghCMPN14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {The purpose of this study is to investigate architectural characteristics of cell arrangements in breast cancer histology images. We propose the use of topological data analysis to summarize the geometric information inherent in tumor cell arrangements. Our goal is to use this information as signatures that encode robust summaries of cell arrangements in tumor tissue as captured through histology images. In particular, using ideas from algebraic topology we construct topological descriptors based on cell nucleus segmentations such as persistency charts and Betti sequences. We assess their performance on the task of discriminating the breast cancer subtypes Basal, Luminal A, Luminal B and HER2. We demonstrate that the topological features contain useful complementary information to image-appearance based features that can improve discriminatory performance of classifiers.},
  keywords = {MICCAI,topology,histology}
}

@inproceedings{DBLP:conf/miccai/ZhaoPNR14,
  author    = {Qingyu Zhao and
               Stephen M. Pizer and
               Marc Niethammer and
               Julian G. Rosenman},
  editor    = {Polina Golland and
               Nobuhiko Hata and
               Christian Barillot and
               Joachim Hornegger and
               Robert D. Howe},
  title     = {Geometric-Feature-Based Spectral Graph Matching in Pharyngeal Surface
               Registration},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2014 - 17th International Conference, Boston, MA, USA, September 14-18,
               2014, Proceedings, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8673},
  pages     = {259--266},
  publisher = {Springer},
  year      = {2014},
  url       = {https://drive.google.com/file/d/1STCSpC6hQNgF7VBDRDVJ-gdyJsfV8ewU},
  doi       = {10.1007/978-3-319-10404-1\_33},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/ZhaoPNR14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Fusion between an endoscopic movie and a CT can aid specifying the tumor target volume for radiotherapy. That requires a deformable pharyngeal surface registration between a 3D endoscope reconstruction and a CT segmentation. In this paper, we propose to use local geometric features for deriving a set of initial correspondences between two surfaces, with which an association graph can be constructed for registration by spectral graph matching. We also define a new similarity measurement to provide a meaningful way for computing inter-surface affinities in the association graph. Our registration method can deal with large non-rigid anatomical deformation, as well as missing data and topology change. We tested the robustness of our method with synthetic deformations and showed registration results on real data.},
  keywords = {MICCAI,registration,endoscopy}
}

@inproceedings{DBLP:conf/wbir/WassermannTNW14,
  author    = {Demian Wassermann and
               Matthew Toews and
               Marc Niethammer and
               William M. Wells III},
  editor    = {S{\'{e}}bastien Ourselin and
               Marc Modat},
  title     = {Probabilistic Diffeomorphic Registration: Representing Uncertainty},
  booktitle = {Biomedical Image Registration - 6th International Workshop, {WBIR}
               2014, London, UK, July 7-8, 2014. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {8545},
  pages     = {72--82},
  publisher = {Springer},
  year      = {2014},
  url       = {https://doi.org/10.1007/978-3-319-08554-8\_8},
  doi       = {10.1007/978-3-319-08554-8\_8},
  timestamp = {Tue, 14 May 2019 10:00:49 +0200},
  biburl    = {https://dblp.org/rec/conf/wbir/WassermannTNW14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper presents a novel mathematical framework for representing uncertainty in large deformation diffeomorphic image registration. The Bayesian posterior distribution over the deformations aligning a moving and a fixed image is approximated via a variational formulation. A stochastic differential equation (SDE) modeling the deformations as the evolution of a time-varying velocity field leads to a prior density over deformations in the form of a Gaussian process. This permits estimating the full posterior distribution in order to represent uncertainty, in contrast to methods in which the posterior is approximated via Monte Carlo sampling or maximized in maximum a-posteriori (MAP) estimation. The framework is demonstrated in the case of landmark-based image registration, including simulated data and annotated pre and intra-operative 3D images.},
  keywords = {WBIR,registration,uncertainty}
}

@article{DBLP:journals/mia/NiethammerZ13,
  author    = {Marc Niethammer and
               Christopher Zach},
  title     = {Segmentation with area constraints},
  journal   = {Medical Image Anal.},
  volume    = {17},
  number    = {1},
  pages     = {101--112},
  year      = {2013},
  url       = {https://drive.google.com/file/d/1N-nVAKHX1cj6DzZYTupzah1VGIksJUHS},
  doi       = {10.1016/j.media.2012.09.002},
  timestamp = {Mon, 24 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/mia/NiethammerZ13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Image segmentation approaches typically incorporate weak regularity conditions such as boundary length or curvature terms, or use shape information. High-level information such as a desired area or volume, or a particular topology are only implicitly specified. In this paper we develop a segmentation method with explicit bounds on the segmented area. Area constraints allow for the soft selection of meaningful solutions, and can counteract the shrinking bias of length-based regularization. We analyze the intrinsic problems of convex relaxations proposed in the literature for segmentation with size constraints. Hence, we formulate the area-constrained segmentation task as a mixed integer program, propose a branch and bound method for exact minimization, and use convex relaxations to obtain the required lower energy bounds on candidate solutions. We also provide a numerical scheme to solve the convex subproblems. We demonstrate the method for segmentations of vesicles from electron tomography images.},
  keywords = {MEDIA,segmentation}
}

@article{DBLP:journals/tmi/CsapoDSSSN13,
  author    = {Istvan Csapo and
               Brad Davis and
               Yundi Shi and
               Mar Sanchez and
               Martin Styner and
               Marc Niethammer},
  title     = {Longitudinal Image Registration With Temporally-Dependent Image Similarity
               Measure},
  journal   = {{IEEE} Trans. Medical Imaging},
  volume    = {32},
  number    = {10},
  pages     = {1939--1951},
  year      = {2013},
  url       = {https://drive.google.com/file/d/1Tz0Ozp-u15o_CTyeC23LKd-A1440Vu5S},
  doi       = {10.1109/TMI.2013.2269814},
  timestamp = {Thu, 18 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/tmi/CsapoDSSSN13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Longitudinal imaging studies are frequently used to investigate temporal changes in brain morphology and often require spatial correspondence between images achieved through image registration. Beside morphological changes, image intensity may also change over time, for example when studying brain maturation. However, such intensity changes are not accounted for in image similarity measures for standard image registration methods. Hence, (i) local similarity measures, (ii) methods estimating intensity transformations between images, and (iii) metamorphosis approaches have been developed to either achieve robustness with respect to intensity changes or to simultaneously capture spatial and intensity changes. For these methods, longitudinal intensity changes are not explicitly modeled and images are treated as independent static samples. Here, we propose a model-based image similarity measure for longitudinal image registration that estimates a temporal model of intensity change using all available images simultaneously.},
  keywords = {registration,brain,TMI}
}

@article{DBLP:journals/tmi/PaceAN13,
  author    = {Danielle F. Pace and
               Stephen R. Aylward and
               Marc Niethammer},
  title     = {A Locally Adaptive Regularization Based on Anisotropic Diffusion for
               Deformable Image Registration of Sliding Organs},
  journal   = {{IEEE} Trans. Medical Imaging},
  volume    = {32},
  number    = {11},
  pages     = {2114--2126},
  year      = {2013},
  url       = {https://drive.google.com/file/d/11B0hArBC2q4VZrSUK_DPovEhS_tRNnGG},
  doi       = {10.1109/TMI.2013.2274777},
  timestamp = {Thu, 18 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/tmi/PaceAN13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We propose a deformable image registration algorithm that uses anisotropic smoothing for regularization to find correspondences between images of sliding organs. In particular, we apply the method for respiratory motion estimation in longitudinal thoracic and abdominal computed tomography scans. The algorithm uses locally adaptive diffusion tensors to determine the direction and magnitude with which to smooth the components of the displacement field that are normal and tangential to an expected sliding boundary. Validation was performed using synthetic, phantom, and 14 clinical datasets, including the publicly available DIR-Lab dataset. We show that motion discontinuities caused by sliding can be effectively recovered, unlike conventional regularizations that enforce globally smooth motion. In the clinical datasets, target registration error showed improved accuracy for lung landmarks compared to the diffusive regularization. We also present a generalization of our algorithm to other sliding geometries, including sliding tubes (e.g., needles sliding through tissue, or contrast agent flowing through a vessel). Potential clinical applications of this method include longitudinal change detection and radiotherapy for lung or abdominal tumours, especially those near the chest or abdominal wall.},
  keywords = {TMI,lung,registration}
}

@inproceedings{DBLP:conf/ipmi/LyuKSYESSNS13,
  author    = {Ilwoo Lyu and
               Sun Hyung Kim and
               Joon{-}Kyung Seong and
               Sang Wook Yoo and
               Alan C. Evans and
               Yundi Shi and
               Mar Sanchez and
               Marc Niethammer and
               Martin Andreas Styner},
  editor    = {James C. Gee and
               Sarang C. Joshi and
               Kilian M. Pohl and
               William M. Wells III and
               Lilla Z{\"{o}}llei},
  title     = {Group-Wise Cortical Correspondence via Sulcal Curve-Constrained Entropy
               Minimization},
  booktitle = {Information Processing in Medical Imaging - 23rd International Conference,
               {IPMI} 2013, Asilomar, CA, USA, June 28-July 3, 2013. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {7917},
  pages     = {364--375},
  publisher = {Springer},
  year      = {2013},
  url       = {https://drive.google.com/file/d/12ZBayr_zNgY4YGuCrK1u6LtNSJTPOab7},
  doi       = {10.1007/978-3-642-38868-2\_31},
  timestamp = {Tue, 14 May 2019 10:00:52 +0200},
  biburl    = {https://dblp.org/rec/conf/ipmi/LyuKSYESSNS13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We present a novel cortical correspondence method employing group-wise registration in a spherical parametrization space for the use in local cortical thickness analysis in human and nonhuman primate neuroimaging studies. The proposed method is unbiased registration that estimates a continuous smooth deformation field into an unbiased average space via sulcal curveconstrained entropy minimization using spherical harmonic decomposition of the spherical deformation field. We initialize a correspondence by our pair-wise method that establishes a surface correspondence with a prior template. Since this pair-wise correspondence is biased to the choice of a template, we further improve the correspondence by employing unbiased ensemble entropy minimization across all surfaces, which yields a deformation field onto the iteratively updated unbiased average. The specific entropy metric incorporates two terms: the first focused on optimizing the correspondence of automatically extracted sulcal landmarks and the second on that of sulcal depth maps. We also propose an encoding scheme for spherical deformation via spherical harmonics as well as a novel method to choose an optimal spherical polar coordinate system for the most efficient deformation field estimation. The experimental results show evidence that the proposed method improves the correspondence quality in non-human primate and human subjects as compared to the pair-wise method.},
  keywords = {registration,brain,IPMI}
}

@inproceedings{DBLP:conf/ipmi/HuangSCNZ13,
  author    = {Chao Huang and
               Liang Shan and
               Cecil Charles and
               Marc Niethammer and
               Hongtu Zhu},
  editor    = {James C. Gee and
               Sarang C. Joshi and
               Kilian M. Pohl and
               William M. Wells III and
               Lilla Z{\"{o}}llei},
  title     = {Diseased Region Detection of Longitudinal Knee {MRI} Data},
  booktitle = {Information Processing in Medical Imaging - 23rd International Conference,
               {IPMI} 2013, Asilomar, CA, USA, June 28-July 3, 2013. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {7917},
  pages     = {632--643},
  publisher = {Springer},
  year      = {2013},
  url       = {https://doi.org/10.1007/978-3-642-38868-2\_53},
  doi       = {10.1007/978-3-642-38868-2\_53},
  timestamp = {Tue, 21 Jan 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/conf/ipmi/HuangSCNZ13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Statistical analysis of longitudinal cartilage changes in osteoarthritis (OA) is of great importance and still a challenge in knee MRI data analysis. A major challenge is to establish a reliable correspondence across subjects within the same latent subpopulations. We develop a novel Gaussian hidden Markov model (GHMM) to establish spatial correspondence of cartilage thinning across both time and subjects within the same latent subpopulations and make statistical inference on the detection of diseased regions in each OA patient. A hidden Markov random filed (HMRF) is proposed to extract such latent subpopulation structure. The EM algorithm and pseudolikelihood method are both considered in making statistical inference. The proposed model can effectively detect diseased regions and present a localized analysis of longitudinal cartilage thickness within each latent subpopulation. Simulation studies and diseased regions detection of 2D thickness map extracted from full 3D longitudinal knee MRI Data for Pfizer Longitudinal Dataset are performed, which shows that our proposed model outperforms standard voxel-based analysis.},
  keywords = {knee,statistics,IPMI}
}

@inproceedings{DBLP:conf/isbi/HongNAKPSDZD13,
  author    = {Yi Hong and
               Marc Niethammer and
               Johan Andruejol and
               Julia S. Kimbell and
               Elizabeth Pitkin and
               Richard Superfine and
               Stephanie Davis and
               Carlton J. Zdanski and
               Brad Davis},
  title     = {A pediatric airway atlas and its application in subglottic stenosis},
  booktitle = {10th {IEEE} International Symposium on Biomedical Imaging: From Nano
               to Macro, {ISBI} 2013, 7-11 April, 2013, San Francisco, CA, USA, Proceedings},
  pages     = {1206--1209},
  publisher = {{IEEE}},
  year      = {2013},
  url       = {https://drive.google.com/file/d/1AXmuZy3wzIFqbUZG-qsFn1gr-AKWyrvh},
  doi       = {10.1109/ISBI.2013.6556697},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/HongNAKPSDZD13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Young children with upper airway problems are at risk for hypoxia, respiratory insufficiency and long term morbidity. Computational models and quantitative analysis would reveal airway growth patterns and benefit clinical care. To capture expected growth patterns we propose a method to build a pediatric airway atlas as a function of age. The atlas is based on a simplified airway model in combination with kernel regression. We show experimental results on children with subglottic stenosis to demonstrate that our method is able to track and measure the stenosis in pediatric airways.},
  keywords = {ISBI,airway,shape}
}

@inproceedings{DBLP:conf/isbi/ShanCN13,
  author    = {Liang Shan and
               Cecil Charles and
               Marc Niethammer},
  title     = {Longitudinal three-label segmentation of knee cartilage},
  booktitle = {10th {IEEE} International Symposium on Biomedical Imaging: From Nano
               to Macro, {ISBI} 2013, 7-11 April, 2013, San Francisco, CA, USA, Proceedings},
  pages     = {1376--1379},
  publisher = {{IEEE}},
  year      = {2013},
  url       = {https://drive.google.com/file/d/1G2BccJBvZWuo8XY__oD6gctaiCIfkqJj},
  doi       = {10.1109/ISBI.2013.6556789},
  timestamp = {Tue, 21 Jan 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/conf/isbi/ShanCN13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Automatic accurate segmentation methods are needed to assess longitudinal cartilage changes in osteoarthritis (OA). We propose a novel general spatio-temporal three-label segmentation method to encourage segmentation consistency across time in longitudinal image data. The segmentation is formulated as a convex optimization problem which allows for the computation of globally optimal solutions. The longitudinal segmentation is applied within an automatic knee cartilage segmentation pipeline. Experimental results demonstrate that the longitudinal segmentation improves the segmentation consistency in comparison to the temporally-independent segmentation.},
  keywords = {knee,segmentation,ISBI}
}

@inproceedings{DBLP:conf/miccai/ZhangNSY13,
  author    = {Pei Zhang and
               Marc Niethammer and
               Dinggang Shen and
               Pew{-}Thian Yap},
  editor    = {Kensaku Mori and
               Ichiro Sakuma and
               Yoshinobu Sato and
               Christian Barillot and
               Nassir Navab},
  title     = {Large Deformation Diffeomorphic Registration of Diffusion-Weighted Images with Explicit Orientation Optimization},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2013 - 16th International Conference, Nagoya, Japan, September 22-26,
               2013, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8150},
  pages     = {27--34},
  publisher = {Springer},
  year      = {2013},
  url       = {https://drive.google.com/file/d/1Td4nnv-Py4p-7Akvik5ODRHGv-NXKfzP},
  doi       = {10.1007/978-3-642-40763-5\_4},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/ZhangNSY13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We seek to compute a diffeomorphic map between a pair of diffusion-weighted images under large deformation. Unlike existing techniques, our method allows any diffusion model to be fitted after registration for subsequent multifaceted analysis. This is achieved by directly aligning the diffusion-weighted images using a large deformation diffeomorphic registration framework formulated from an optimal control perspective. Our algorithm seeks the optimal coordinate mapping by simultaneously considering structural alignment, local fiber reorientation, and deformation regularization. Our algorithm also incorporates a multi-kernel strategy to concurrently register anatomical structures of different scales. We demonstrate the efficacy of our approach using in vivo data and report on detailed qualitative and quantitative results in comparison with several different registration strategies.},
  keywords = {LDDMM,MICCAI,registration,brain}
}

@inproceedings{DBLP:conf/miccai/RathiNLSMGW13,
  author    = {Yogesh Rathi and
               Marc Niethammer and
               Frederik B. Laun and
               Kawin Setsompop and
               Oleg V. Michailovich and
               P. Ellen Grant and
               Carl{-}Fredrik Westin},
  editor    = {Thomas Schultz and
               Gemma L. Nedjati{-}Gilani and
               Archana Venkataraman and
               Lauren O'Donnell and
               Eleftheria Panagiotaki},
  title     = {Diffusion Propagator Estimation Using Radial Basis Functions},
  booktitle = {Computational Diffusion {MRI} and Brain Connectivity, {MICCAI} Workshops
               CDMRI/MMBC, Nagoya, Japan, September 22nd, 2013},
  pages     = {57--66},
  publisher = {Springer},
  year      = {2013},
  url       = {https://drive.google.com/file/d/1y8214ctViyaE6ekI5xxc7YKgiyKgm2Ja},
  doi       = {10.1007/978-3-319-02475-2\_6},
  timestamp = {Fri, 02 Nov 2018 09:47:24 +0100},
  biburl    = {https://dblp.org/rec/conf/miccai/RathiNLSMGW13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {The average diffusion propagator (ADP) obtained from diffusion MRI (dMRI) data encapsulates important structural properties of the underlying tissue. Measures derived from the ADP can be potentially used as markers of tissue integrity in characterizing several mental disorders. Thus, accurate estimation of the ADP is imperative for its use in neuroimaging studies. In this work, we propose a simple method for estimating the ADP by representing the acquired diffusion signal in the entire q-space using radial basis functions (RBF). We demonstrate our technique using two different RBF’s (generalized inverse multiquadric and Gaussian) and derive analytical expressions for the corresponding ADP’s. We also derive expressions for computing the solid angle orientation distribution function (ODF) for each of the RBF’s. Estimation of the weights of the RBF’s is done by enforcing positivity constraint on the estimated ADP or ODF. Finally, we validate our method on data obtained from a physical phantom with known fiber crossing of 45 degrees and also show comparison with the solid spherical harmonics method of [7].We also demonstrate our method on in-vivo human brain data.},
  keywords = {diffusion,brain,MICCAI}
}

@inproceedings{DBLP:conf/miccai/CaoJMPCN13,
  author    = {Tian Cao and
               Vladimir Jojic and
               Shannon Modla and
               Debbie Powell and
               Kirk Czymmek and
               Marc Niethammer},
  editor    = {Kensaku Mori and
               Ichiro Sakuma and
               Yoshinobu Sato and
               Christian Barillot and
               Nassir Navab},
  title     = {Robust Multimodal Dictionary Learning},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2013 - 16th International Conference, Nagoya, Japan, September 22-26,
               2013, Proceedings, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8149},
  pages     = {259--266},
  publisher = {Springer},
  year      = {2013},
  url       = {https://drive.google.com/file/d/1jZejfym69TW_FRnLUtIh0lvdiF-ifuFP},
  doi       = {10.1007/978-3-642-40811-3\_33},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/CaoJMPCN13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We propose a robust multimodal dictionary learning method for multimodal images. Joint dictionary learning for both modalities may be impaired by lack of correspondence between image modalities in training data, for example due to areas of low quality in one of the modalities. Dictionaries learned with such non-corresponding data will induce uncertainty about image representation. In this paper, we propose a probabilistic model that accounts for image areas that are poorly corresponding between the image modalities. We cast the problem of learning a dictionary in presence of problematic image patches as a likelihood maximization problem and solve it with a variant of the EM algorithm. Our algorithm iterates identification of poorly corresponding patches and refinements of the dictionary. We tested our method on synthetic and real data. We show improvements in image prediction quality and alignment accuracy when using the method for multimodal image registration.},
  keywords = {registration,MICCAI}
}

@inproceedings{DBLP:conf/miccai/ZhangWNSY13,
  author    = {Pei Zhang and
               Chong{-}Yaw Wee and
               Marc Niethammer and
               Dinggang Shen and
               Pew{-}Thian Yap},
  editor    = {Kensaku Mori and
               Ichiro Sakuma and
               Yoshinobu Sato and
               Christian Barillot and
               Nassir Navab},
  title     = {Large Deformation Image Classification Using Generalized Locality-Constrained
               Linear Coding},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2013 - 16th International Conference, Nagoya, Japan, September 22-26,
               2013, Proceedings, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8149},
  pages     = {292--299},
  publisher = {Springer},
  year      = {2013},
  url       = {https://drive.google.com/file/d/1wCBTs920taky3KotuD5oxo5u6PQ0squQ},
  doi       = {10.1007/978-3-642-40811-3\_37},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/ZhangWNSY13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Magnetic resonance (MR) imaging has been demonstrated to be very useful for clinical diagnosis of Alzheimer’s disease (AD). A common approach to using MR images for AD detection is to spatially normalize the images by non-rigid image registration, and then perform statistical analysis on the resulting deformation fields. Due to the high nonlinearity of the deformation field, recent studies suggest to use initial momentum instead as it lies in a linear space and fully encodes the deformation field. In this paper we explore the use of initial momentum for image classification by focusing on the problem of AD detection. Experiments on the public ADNI dataset show that the initial momentum, together with a simple sparse coding technique—locality-constrained linear coding (LLC)—can achieve a classification accuracy that is comparable to or even better than the state of the art. We also show that the performance of LLC can be greatly improved by introducing proper weights to the codebook.},
  keywords = {MICCAI,brain}
}

@inproceedings{DBLP:conf/miccai/LorenziMNAP13,
  author    = {Marco Lorenzi and
               Bjoern H. Menze and
               Marc Niethammer and
               Nicholas Ayache and
               Xavier Pennec},
  editor    = {Kensaku Mori and
               Ichiro Sakuma and
               Yoshinobu Sato and
               Christian Barillot and
               Nassir Navab},
  title     = {Sparse Scale-Space Decomposition of Volume Changes in Deformations
               Fields},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2013 - 16th International Conference, Nagoya, Japan, September 22-26,
               2013, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8150},
  pages     = {328--335},
  publisher = {Springer},
  year      = {2013},
  url       = {https://drive.google.com/file/d/1xgDv74_wdUiH48g-p3FrJuk3SeW2sby4},
  doi       = {10.1007/978-3-642-40763-5\_41},
  timestamp = {Mon, 16 Sep 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/LorenziMNAP13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Anatomical changes like brain atrophy or growth are usually not homogeneous in space and across spatial scales, since they map differently depending on the anatomical structures. Thus, the accurate analysis of volume changes from medical images requires to reliably localize and distinguish the spatial changes occurring at different scales, from voxel to regional level. We propose here a framework for the sparse probabilistic scale-space analysis of volume changes encoded by deformations. Our framework is based on the Helmoltz decomposition of vector fields. By scale-space analysis of the scalar pressure map associated to the irrotational component of the deformation, we robustly identify the areas of maximal volume changes, and we define a consistent sparse decomposition of the irrotational component. We show the effectiveness of our framework in the challenging problem of detecting the progression of tumor growth, and in the group-wise analysis of the longitudinal atrophy in Alzheimer’s disease.},
  keywords = {registration,MICCAI,brain}
}

@inproceedings{DBLP:conf/miccai/KwittPNA13,
  author    = {Roland Kwitt and
               Danielle F. Pace and
               Marc Niethammer and
               Stephen R. Aylward},
  editor    = {Kensaku Mori and
               Ichiro Sakuma and
               Yoshinobu Sato and
               Christian Barillot and
               Nassir Navab},
  title     = {Studying Cerebral Vasculature Using Structure Proximity and Graph
               Kernels},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2013 - 16th International Conference, Nagoya, Japan, September 22-26,
               2013, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8150},
  pages     = {534--541},
  publisher = {Springer},
  year      = {2013},
  url       = {https://drive.google.com/file/d/1RWvn-7M9nOo8G52pSI-uNOGIXfB9I8li},
  doi       = {10.1007/978-3-642-40763-5\_66},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/KwittPNA13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {An approach to study population differences in cerebral vasculature is proposed. This is done by 1) extending the concept of encoding cerebral blood vessel networks as spatial graphs and 2) quantifying graph similarity in a kernel-based discriminant classifier setup. We argue that augmenting graph vertices with information about their proximity to selected brain structures adds discriminative information and consequently leads to a more expressive encoding. Using graph-kernels then allows us to quantify graph similarity in a principled way. To demonstrate our approach, we assess the hypothesis that gender differences manifest as variations in the architecture of cerebral blood vessels, an observation that previously had only been tested and confirmed for the Circle of Willis. Our results strongly support this hypothesis, i.e, we can demonstrate non-trivial, statistically significant deviations from random gender classification in a cross-validation setup on 40 healthy patients.},
  keywords = {MICCAI,brain,vasculature}
}

@inproceedings{DBLP:conf/miccai/HongDMKN13,
  author    = {Yi Hong and
               Brad Davis and
               J. S. Marron and
               Roland Kwitt and
               Marc Niethammer},
  editor    = {Kensaku Mori and
               Ichiro Sakuma and
               Yoshinobu Sato and
               Christian Barillot and
               Nassir Navab},
  title     = {Weighted Functional Boxplot with Application to Statistical Atlas
               Construction},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2013 - 16th International Conference, Nagoya, Japan, September 22-26,
               2013, Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {8151},
  pages     = {584--591},
  publisher = {Springer},
  year      = {2013},
  url       = {https://drive.google.com/file/d/1R4V6qD5sul6SMX0glxlBv-kQxeGQR9Zo},
  doi       = {10.1007/978-3-642-40760-4\_73},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/HongDMKN13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Atlas-building from population data is widely used in medical imaging. However, the emphasis of atlas-building approaches is typically to compute a mean / median shape or image based on population data. In this work, we focus on the statistical characterization of the population data, once spatial alignment has been achieved. We introduce and propose the use of the weighted functional boxplot. This allows the generalization of concepts such as the median, percentiles, or outliers to spaces where the data objects are functions, shapes, or images, and allows spatio-temporal atlas-building based on kernel regression. In our experiments, we demonstrate the utility of the approach to construct statistical atlases for pediatric upper airways and corpora callosa revealing their growth patterns. Furthermore, we show how such atlas information can be used to assess the effect of airway surgery in children.},
  keywords = {airway,shape,MICCAI}
}

@inproceedings{DBLP:conf/miip/LyuKSYESSNS13,
  author    = {Ilwoo Lyu and
               Sun Hyung Kim and
               Joon{-}Kyung Seong and
               Sang Wook Yoo and
               Alan C. Evans and
               Yundi Shi and
               Mar Sanchez and
               Marc Niethammer and
               Martin A. Styner},
  editor    = {S{\'{e}}bastien Ourselin and
               David R. Haynor},
  title     = {Cortical correspondence via sulcal curve-constrained spherical registration
               with application to Macaque studies},
  booktitle = {Medical Imaging 2013: Image Processing, Lake Buena Vista (Orlando
               Area), Florida, USA, February 10-12, 2013},
  series    = {{SPIE} Proceedings},
  volume    = {8669},
  pages     = {86692X},
  publisher = {{SPIE}},
  year      = {2013},
  url       = {https://doi.org/10.1117/12.2006459},
  doi       = {10.1117/12.2006459},
  timestamp = {Wed, 14 Nov 2018 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/conf/miip/LyuKSYESSNS13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this work, we present a novel cortical correspondence method with application to the macaque brain. The correspondence method is based on sulcal curve constraints on a spherical deformable registration using spherical harmonics to parameterize the spherical deformation. Starting from structural MR images, we first apply existing preprocessing steps: brain tissue segmentation using the Automatic Brain Classification tool (ABC), as well as cortical surface reconstruction and spherical parametrization of the cortical surface via Constrained Laplacian-based Automated Segmentation with Proximities (CLASP). Then, initial correspondence between two cortical surfaces is automatically determined by a curve labeling method using sulcal landmarks extracted along sulcal fundic regions. Since the initial correspondence is limited to sulcal regions, we use spherical harmonics to extrapolate and regularize this correspondence to the entire cortical surface. To further improve the correspondence, we compute a spherical registration that optimizes the spherical harmonic parameterized deformation using a metric that incorporates the error over the sulcal landmarks as well as the normalized cross correlation of sulcal depth maps over the whole cortical surface. For evaluation, a normal 18-months-old macaque brain (for both left and right hemispheres) was matched to a prior macaque brain template with 9 manually labeled, major sulcal curves. The results show successful registration using the proposed registration approach. Evaluation results for optimal parameter settings are presented as well.},
  keywords = {SPIE,registration,brain}
}

@article{DBLP:journals/tmi/LeeFNKL12,
  author    = {Huai{-}Ping Lee and
               Mark Foskey and
               Marc Niethammer and
               Pavel Krajcevski and
               Ming C. Lin},
  title     = {Simulation-Based Joint Estimation of Body Deformation and Elasticity
               Parameters for Medical Image Analysis},
  journal   = {{IEEE} Trans. Medical Imaging},
  volume    = {31},
  number    = {11},
  pages     = {2156--2168},
  year      = {2012},
  url       = {https://drive.google.com/file/d/1yGPA2w22o9MqEigG_MWKmYvX-o5tAVhy},
  doi       = {10.1109/TMI.2012.2212450},
  timestamp = {Thu, 18 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/tmi/LeeFNKL12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Estimation of tissue stiffness is an important means of noninvasive cancer detection. Existing elasticity reconstruction methods usually depend on a dense displacement field (inferred from ultrasound or MR images) and known external forces. Many imaging modalities, however, cannot provide details within an organ and therefore cannot provide such a displacement field. Furthermore, force exertion and measurement can be difficult for some internal organs, making boundary forces another missing parameter. We propose a general method for estimating elasticity and boundary forces automatically using an iterative optimization framework, given the desired (target) output surface. During the optimization, the input model is deformed by the simulator, and an objective function based on the distance between the deformed surface and the target surface is minimized numerically. The optimization framework does not depend on a particular simulation method and is therefore suitable for different physical models. We show a positive correlation between clinical prostate cancer stage (a clinical measure of severity) and the recovered elasticity of the organ. Since the surface correspondence is established, our method also provides a nonrigid image registration, where the quality of the deformation fields is guaranteed, as they are computed using a physics-based simulation.},
  keywords = {TMI}
}

@inproceedings{DBLP:conf/icra/BergWGNM12,
  author    = {Jur van den Berg and
               David Wilkie and
               Stephen J. Guy and
               Marc Niethammer and
               Dinesh Manocha},
  title     = {LQG-obstacles: Feedback control with collision avoidance for mobile
               robots with motion and sensing uncertainty},
  booktitle = {{IEEE} International Conference on Robotics and Automation, {ICRA}
               2012, 14-18 May, 2012, St. Paul, Minnesota, {USA}},
  pages     = {346--353},
  publisher = {{IEEE}},
  year      = {2012},
  url       = {https://drive.google.com/file/d/1xfSQ6_OqqqM-OHEPfJ_bbLWKlUC4lK3g},
  doi       = {10.1109/ICRA.2012.6224648},
  timestamp = {Wed, 16 Oct 2019 14:14:51 +0200},
  biburl    = {https://dblp.org/rec/conf/icra/BergWGNM12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper presents LQG-Obstacles, a new concept that combines linear-quadratic feedback control of mobile robots with guaranteed avoidance of collisions with obstacles. Our approach generalizes the concept of Velocity Obstacles [3] to any robotic system with a linear Gaussian dynamics model. We integrate a Kalman filter for state estimation and an LQR feedback controller into a closed-loop dynamics model of which a higher-level control objective is the “control input”. We then define the LQG-Obstacle as the set of control objectives that result in a collision with high probability. Selecting a control objective outside the LQG-Obstacle then produces collisionfree motion. We demonstrate the potential of LQG-Obstacles by safely and smoothly navigating a simulated quadrotor helicopter with complex non-linear dynamics and motion and sensing uncertainty through three-dimensional environments with obstacles and narrow passages.},
  keywords = {ICRA,collision}
}

@inproceedings{DBLP:conf/isbi/ShanCN12,
  author    = {Liang Shan and
               Cecil Charles and
               Marc Niethammer},
  title     = {Automatic multi-atlas-based cartilage segmentation from knee {MR}
               images},
  booktitle = {9th {IEEE} International Symposium on Biomedical Imaging: From Nano
               to Macro, {ISBI} 2012, May 2-5, 2012, Barcelona, Spain, Proceedings},
  pages     = {1028--1031},
  publisher = {{IEEE}},
  year      = {2012},
  url       = {https://drive.google.com/file/d/1LZxXG1-IZ-AVkDpyG6lMztAgEx44d04I},
  doi       = {10.1109/ISBI.2012.6235733},
  timestamp = {Tue, 21 Jan 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/conf/isbi/ShanCN12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper, we propose a multi-atlas-based method to automatically segment the femoral and tibial cartilage from T1 weighted magnetic resonance (MR) knee images. The segmentation result is a joint decision of the spatial priors from a multi-atlas registration and the local likelihoods within a Bayesian framework. The cartilage likelihoods are obtained from a probabilistic k nearest neighbor classification. Validation results on 18 knee MR images against the manual expert segmentations from a dataset acquired for osteoarthritis research show good performance for the segmentation of femoral and tibial cartilage (mean Dice similarity coefficient of 75.2\% and 81.7\% respectively).},
  keywords = {ISBI,knee,segmentation}
}

@inproceedings{DBLP:conf/miccai/ZhangNSY12,
  author    = {Pei Zhang and
               Marc Niethammer and
               Dinggang Shen and
               Pew{-}Thian Yap},
  editor    = {Nicholas Ayache and
               Herv{\'{e}} Delingette and
               Polina Golland and
               Kensaku Mori},
  title     = {Large Deformation Diffeomorphic Registration of Diffusion-Weighted Images},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2012 - 15th International Conference, Nice, France, October 1-5, 2012,
               Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {7511},
  pages     = {171--178},
  publisher = {Springer},
  year      = {2012},
  url       = {https://drive.google.com/file/d/19gqcXxT-ReTcll_0Zl16o2macVCpblQ6},
  doi       = {10.1007/978-3-642-33418-4\_22},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/ZhangNSY12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Registration of Diffusion-weighted imaging (DWI) data emerges as an important topic in magnetic resonance (MR) image analysis. As existing methods are often designed for specific diffusion models, it is difficult to fit to the registered data different models other than the one used for registration. In this paper we describe a diffeomorphic registration algorithm for DWI data in a large deformation setting. Our method generates spatially normalized DWI data and it is thus possible to fit various diffusion models after registration for comparison purposes. Our algorithm includes (1) a reorientation component, where each diffusion profile (DWI signal as a function on a unit sphere) is decomposed, reoriented and recomposed to form the orientation-corrected DWI profile, and (2) a large deformation diffeomorphic registration component to ensure one-to-one mapping in a large-structural-variation scenario. In addition our algorithm uses a geodesic shooting mechanism to avoid the huge computational resources that are needed to register high-dimensional vector-valued data. We also incorporate into our algorithm a multi-kernel strategy where anatomical structures at different scales are considered simultaneously during registration. We demonstrate the efficacy of our method using in vivo data.},
  keywords = {MICCAI,LDDMM,registration,brain}
}

@inproceedings{DBLP:conf/miccai/HongJSSN12,
  author    = {Yi Hong and
               Sarang C. Joshi and
               Mar Sanchez and
               Martin Styner and
               Marc Niethammer},
  editor    = {Nicholas Ayache and
               Herv{\'{e}} Delingette and
               Polina Golland and
               Kensaku Mori},
  title     = {Metamorphic Geodesic Regression},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2012 - 15th International Conference, Nice, France, October 1-5, 2012,
               Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {7512},
  pages     = {197--205},
  publisher = {Springer},
  year      = {2012},
  url       = {https://drive.google.com/file/d/14hZQKaVlyTVnJcnQL_FYDNUo0hw0532K},
  doi       = {10.1007/978-3-642-33454-2\_25},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/HongJSSN12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We propose a metamorphic geodesic regression approach approximating spatial transformations for image time-series while simultaneously accounting for intensity changes. Such changes occur for example in magnetic resonance imaging (MRI) studies of the developing brain due to myelination. To simplify computations we propose an approximate metamorphic geodesic regression formulation that only requires pairwise computations of image metamorphoses. The approximated solution is an appropriately weighted average of initial momenta. To obtain initial momenta reliably, we develop a shooting method for image metamorphosis.},
  keywords = {MICCAI,metamorphosis,registration,brain}
}

@inproceedings{DBLP:conf/miccai/CsapoDSSSN12,
  author    = {Istvan Csapo and
               Brad Davis and
               Yundi Shi and
               Mar Sanchez and
               Martin Styner and
               Marc Niethammer},
  editor    = {Nicholas Ayache and
               Herv{\'{e}} Delingette and
               Polina Golland and
               Kensaku Mori},
  title     = {Longitudinal Image Registration with Non-uniform Appearance Change},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2012 - 15th International Conference, Nice, France, October 1-5, 2012,
               Proceedings, Part {III}},
  series    = {Lecture Notes in Computer Science},
  volume    = {7512},
  pages     = {280--288},
  publisher = {Springer},
  year      = {2012},
  url       = {https://drive.google.com/file/d/1L_5pn3XmM5emmdmcI28CayCKWe1CPiqk},
  doi       = {10.1007/978-3-642-33454-2\_35},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/CsapoDSSSN12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Longitudinal imaging studies are frequently used to investigate temporal changes in brain morphology. Image intensity may also change over time, for example when studying brain maturation. However, such intensity changes are not accounted for in image similarity measures for standard image registration methods. Hence, (i) local similarity measures, (ii) methods estimating intensity transformations between images, and (iii) metamorphosis approaches have been developed to either achieve robustness with respect to intensity changes or to simultaneously capture spatial and intensity changes. For these methods, longitudinal intensity changes are not explicitly modeled and images are treated as independent static samples. Here, we propose a model-based image similarity measure for longitudinal image registration in the presence of spatially non-uniform intensity change.},
  keywords = {MICCAI,registration,brain}
}

@inproceedings{DBLP:conf/mmbia/ShanCN12,
  author    = {Liang Shan and
               Cecil Charles and
               Marc Niethammer},
  title     = {Automatic atlas-based three-label cartilage segmentation from {MR}
               knee images},
  booktitle = {2012 {IEEE} Workshop on Mathematical Methods in Biomedical Image Analysis,
               {MMBIA} 2012, Breckenridge, CO, USA, January 9-10, 2012},
  pages     = {241--246},
  publisher = {{IEEE}},
  year      = {2012},
  url       = {https://drive.google.com/file/d/15uTyoJfNmbfB4QIkKRUIOnfhaC_iSL3_},
  doi       = {10.1109/MMBIA.2012.6164757},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/mmbia/ShanCN12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper, we propose a multi-atlas-based method to automatically segment the femoral and tibial cartilage from T1 weighted magnetic resonance (MR) knee images. The segmentation result is a joint decision of the spatial priors from a multi-atlas registration and the local likelihoods within a Bayesian framework. The cartilage likelihoods are obtained from a probabilistic k nearest neighbor classification. Validation results on 18 knee MR images against the manual expert segmentations from a dataset acquired for osteoarthritis research show good performance for the segmentation of femoral and tibial cartilage (mean Dice similarity coefficient of 75.2\% and 81.7\% respectively).}},
  keywords = {MMBIA,knee,segmentation}
}

@inproceedings{DBLP:conf/wbir/HongSSSN12,
  author    = {Yi Hong and
               Yundi Shi and
               Martin Styner and
               Mar Sanchez and
               Marc Niethammer},
  editor    = {Benoit M. Dawant and
               Gary E. Christensen and
               J. Michael Fitzpatrick and
               Daniel Rueckert},
  title     = {Simple Geodesic Regression for Image Time-Series},
  booktitle = {Biomedical Image Registration - 5th International Workshop, {WBIR}
               2012, Nashville, TN, USA, July 7-8, 2012. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {7359},
  pages     = {11--20},
  publisher = {Springer},
  year      = {2012},
  url       = {https://drive.google.com/file/d/118z2ne5oksvhtyHinueXINAyDzrZVt5u},
  doi       = {10.1007/978-3-642-31340-0\_2},
  timestamp = {Sun, 02 Jun 2019 21:20:26 +0200},
  biburl    = {https://dblp.org/rec/conf/wbir/HongSSSN12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Geodesic regression generalizes linear regression to general Riemannian manifolds. Applied to images, it allows for a compact approximation of an image time-series through an initial image and an initial momentum. Geodesic regression requires the definition of a squared residual (squared distance) between the regression geodesic and the measurement images. In principle, this squared distance should also be defined through a geodesic connecting an image on the regression geodesic to its respective measurement. However, in practice only standard registration distances (such as sum of squared distances) are used, to reduce computation time. This paper describes a simplified geodesic regression method which approximates the registration-based distances with respect to a fixed initial image. This results in dramatically simplified computations. In particular, the method becomes straightforward to implement using readily available large displacement diffeomorphic metric mapping (LDDMM) shooting algorithms and decouples the problem into pairwise image registrations allowing parallel computations. We evaluate the approach using 2D synthetic images and real 3D brain images.},
  keywords = {WBIR,registration,brain,regression}
}

@inproceedings{DBLP:conf/wbir/CsapoDSSSN12,
  author    = {Istvan Csapo and
               Brad Davis and
               Yundi Shi and
               Mar Sanchez and
               Martin Styner and
               Marc Niethammer},
  editor    = {Benoit M. Dawant and
               Gary E. Christensen and
               J. Michael Fitzpatrick and
               Daniel Rueckert},
  title     = {Temporally-Dependent Image Similarity Measure for Longitudinal Analysis},
  booktitle = {Biomedical Image Registration - 5th International Workshop, {WBIR}
               2012, Nashville, TN, USA, July 7-8, 2012. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {7359},
  pages     = {99--109},
  publisher = {Springer},
  year      = {2012},
  url       = {https://drive.google.com/file/d/1WIQgL6LVDpZT4MZqiux7Q6vtwvFbzDxG},
  doi       = {10.1007/978-3-642-31340-0\_11},
  timestamp = {Sun, 02 Jun 2019 21:20:26 +0200},
  biburl    = {https://dblp.org/rec/conf/wbir/CsapoDSSSN12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Current longitudinal image registration methods rely on the assumption that image appearance between time-points remains constant or changes uniformly within intensity classes. This assumption, however, is not valid for magnetic resonance imaging of brain development. Registration methods developed to align images with non-uniform appearance change either (i) locally minimize some global similarity measure, or (ii) iteratively estimate an intensity transformation that makes the images similar. However, these methods treat the individual images as independent static samples and are inadequate for the strong nonuniform appearance changes seen in neurodevelopmental data. Here, we propose a model-based similarity measure intended for aligning longitudinal images that locally estimates a temporal model of intensity change. Unlike previous approaches, the model-based formulation is able to capture complex appearance changes between time-points and we demonstrate that it is critical when using a deformable transformation model.},
  keywords = {WBIR,registration,brain}
}

@inproceedings{DBLP:conf/wbir/CaoZMPCN12,
  author    = {Tian Cao and
               Christopher Zach and
               Shannon Modla and
               Debbie Powell and
               Kirk Czymmek and
               Marc Niethammer},
  editor    = {Benoit M. Dawant and
               Gary E. Christensen and
               J. Michael Fitzpatrick and
               Daniel Rueckert},
  title     = {Registration for Correlative Microscopy Using Image Analogies},
  booktitle = {Biomedical Image Registration - 5th International Workshop, {WBIR}
               2012, Nashville, TN, USA, July 7-8, 2012. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {7359},
  pages     = {296--306},
  publisher = {Springer},
  year      = {2012},
  url       = {https://drive.google.com/file/d/1oZAeIYIysy-9NflHvz0GJA8y9QzGCLZa},
  doi       = {10.1007/978-3-642-31340-0\_31},
  timestamp = {Sun, 02 Jun 2019 21:20:26 +0200},
  biburl    = {https://dblp.org/rec/conf/wbir/CaoZMPCN12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Correlative microscopy is a methodology combining the functionality of light microscopy with the high resolution of electron microscopy and other microscopy technologies for the same biological specimen. In this paper, we propose an image registration method for correlative microscopy, which is challenging due to the distinct appearance of biological structures when imaged with different modalities. Our method is based on image analogies and allows to transform images of a given modality into the appearance-space of another modality. Hence, the registration between two different types of microscopy images can be transformed to a mono-modality image registration. We use a sparse representation model to obtain image analogies. The method makes use of representative corresponding image training patches of two different imaging modalities to learn a dictionary capturing appearance relations. We test our approach on backscattered electron (BSE) Scanning Electron Microscopy (SEM)/confocal and Transmission Electron Microscopy (TEM)/confocal images and show improvements over direct registration using a mutual-information similarity measure to account for differences in image appearance.},
  keywords = {WBIR,registration,microscopy}
}

@proceedings{DBLP:conf/miccai/2012stia,
  editor    = {Stanley Durrleman and
               Tom Fletcher and
               Guido Gerig and
               Marc Niethammer},
  title     = {Spatio-temporal Image Analysis for Longitudinal and Time-Series Image
               Data - Second International Workshop, {STIA} 2012, Held in Conjunction
               with {MICCAI} 2012, Nice, France, October 1, 2012. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {7570},
  publisher = {Springer},
  year      = {2012},
  url       = {https://doi.org/10.1007/978-3-642-33555-6},
  doi       = {10.1007/978-3-642-33555-6},
  isbn      = {978-3-642-33554-9},
  timestamp = {Tue, 14 May 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/2012stia.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  keywords = {MICCAI}
}

@article{DBLP:journals/cgf/KabulPRN11,
  author    = {Ilknur Kabul and
               Stephen M. Pizer and
               Julian G. Rosenman and
               Marc Niethammer},
  title     = {An Optimal Control Approach for Texture Metamorphosis},
  journal   = {Comput. Graph. Forum},
  volume    = {30},
  number    = {8},
  pages     = {2341--2353},
  year      = {2011},
  url       = {https://drive.google.com/file/d/1SReU-fXIHlwvjxAG30h7J2tIC8JhlqkJ},
  doi       = {10.1111/j.1467-8659.2011.02067.x},
  timestamp = {Fri, 26 May 2017 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/cgf/KabulPRN11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper, we introduce a new texture metamorphosis approach for interpolating texture samples from a source texture into a target texture. We use a new energy optimization scheme derived from optimal control principles which exploits the structure of the metamorphosis optimality conditions. Our approach considers the change in pixel position and pixel appearance in a single framework. In contrast to previous techniques that compute a global warping based on feature masks of textures, our approach allows to transform one texture into another by considering both intensity values and structural features of textures simultaneously. We demonstrate the usefulness of our approach for different textures, such as stochastic, semi‐structural and regular textures, with different levels of complexities. Our method produces visually appealing transformation sequences with no user interaction.},
  keywords = {CGF,metamorphosis}
}

@inproceedings{DBLP:conf/isbi/PaceEYAN11,
  author    = {Danielle F. Pace and
               Andinet Enquobahrie and
               Hua Yang and
               Stephen R. Aylward and
               Marc Niethammer},
  title     = {Deformable image registration of sliding organs using anisotropic
               diffusive regularization},
  booktitle = {Proceedings of the 8th {IEEE} International Symposium on Biomedical
               Imaging: From Nano to Macro, {ISBI} 2011, March 30 - April 2, 2011,
               Chicago, Illinois, {USA}},
  pages     = {407--413},
  publisher = {{IEEE}},
  year      = {2011},
  url       = {https://drive.google.com/file/d/1w6O2MvJjx7By3mTm2mXHSo-8hG7mzLCf},
  doi       = {10.1109/ISBI.2011.5872434},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/PaceEYAN11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Traditional deformable image registration imposes a uniform smoothness constraint on the deformation field. This is not appropriate when registering images visualizing organs that slide relative to each other, and therefore leads to registration inaccuracies. In this paper, we present a deformation field regularization term that is based on anisotropic diffusion and accommodates the deformation field discontinuities that are expected when considering sliding motion. The registration algorithm was assessed first using artificial images of geometric objects. In a second validation, monomodal chest images depicting both respiratory and cardiac motion were generated using an anatomically-realistic software phantom and then registered. Registration accuracy was assessed based on the distances between corresponding segmented organ surfaces. Compared to an established diffusive regularization approach, the anisotropic diffusive regularization gave deformation fields that represented more plausible image correspondences, while giving rise to similar transformed moving images and comparable registration accuracy.},
  keywords = {ISBI,registration,lung}
}

@inproceedings{DBLP:conf/miccai/PaceNA11,
  author    = {Danielle F. Pace and
               Marc Niethammer and
               Stephen R. Aylward},
  editor    = {Hiroyuki Yoshida and
               Georgios Sakas and
               Marius George Linguraru},
  title     = {Sliding Geometries in Deformable Image Registration},
  booktitle = {Abdominal Imaging. Computational and Clinical Applications - Third
               International Workshop, Held in Conjunction with {MICCAI} 2011, Toronto,
               ON, Canada, September 18, 2011, Revised Selected Papers},
  series    = {Lecture Notes in Computer Science},
  volume    = {7029},
  pages     = {141--148},
  publisher = {Springer},
  year      = {2011},
  url       = {https://drive.google.com/file/d/1pUU8Dp7h8djHzKKLXORnLobcezhz3gVq},
  doi       = {10.1007/978-3-642-28557-8\_18},
  timestamp = {Tue, 14 May 2019 10:00:50 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/PaceNA11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Regularization is used in deformable image registration to encourage plausible displacement fields, and significantly impacts the derived correspondences. Sliding motion, such as that between the lungs and chest wall and between the abdominal organs, complicates registration because many regularizations are global smoothness constraints that produce errors at object boundaries. We present locally adaptive regularizations that handle sliding objects with locally planar and tubular geometries. These regularizations allow discontinuities to develop in the displacement field at sliding interfaces and increase the independence with which regions surrounding distinct geometric structures can behave. Validation is performed by registering inhale and exhale abdominal computed tomography (CT) images and artificial images of a sliding tube. The sliding registration methods produce more realistic correspondences that may better reflect the underlying physical motion, while performing as well as the diffusive regularization with respect to image match.},
  keywords = {lung,MICCAI,registration}
}

@inproceedings{DBLP:conf/miccai/NiethammerHPVIHA11,
  author    = {Marc Niethammer and
               Gabriel L. Hart and
               Danielle F. Pace and
               Paul M. Vespa and
               Andrei Irimia and
               John D. Van Horn and
               Stephen R. Aylward},
  editor    = {Gabor Fichtinger and
               Anne L. Martel and
               Terry M. Peters},
  title     = {Geometric Metamorphosis},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2011 - 14th International Conference, Toronto, Canada, September 18-22,
               2011, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {6892},
  pages     = {639--646},
  publisher = {Springer},
  year      = {2011},
  url       = {https://drive.google.com/file/d/1jYIEJXDAbmecFVsVu-vQ945CUS28nO_j},
  doi       = {10.1007/978-3-642-23629-7\_78},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/NiethammerHPVIHA11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {. Standard image registration methods do not account for changes in image appearance. Hence, metamorphosis approaches have been developed which jointly estimate a space deformation and a change in image appearance to construct a spatio-temporal trajectory smoothly transforming a source to a target image. For standard metamorphosis, geometric changes are not explicitly modeled. We propose a geometric metamorphosis formulation, which explains changes in image appearance by a global deformation, a deformation of a geometric model, and an image composition model. This work is motivated by the clinical challenge of predicting the long-term effects of traumatic brain injuries based on time-series images. This work is also applicable to the quantification of tumor progression (e.g., estimating its infiltrating and displacing components) and predicting chronic blood perfusion changes after stroke. We demonstrate the utility of the method using simulated data as well as scans from a clinical traumatic brain injury patient.},
  keywords = {MICCAI,metamorphosis,brain}
}

@inproceedings{DBLP:conf/miccai/NiethammerHV11,
  author    = {Marc Niethammer and
               Yang Huang and
               Fran{\c{c}}ois{-}Xavier Vialard},
  editor    = {Gabor Fichtinger and
               Anne L. Martel and
               Terry M. Peters},
  title     = {Geodesic Regression for Image Time-Series},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2011 - 14th International Conference, Toronto, Canada, September 18-22,
               2011, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {6892},
  pages     = {655--662},
  publisher = {Springer},
  year      = {2011},
  url       = {https://drive.google.com/file/d/1mG9S3ScrW2CHUH5zMdQOiiroL6jqjhY0},
  doi       = {10.1007/978-3-642-23629-7\_80},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/NiethammerHV11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Registration of image-time series has so far been accomplished (i) by concatenating registrations between image pairs, (ii) by solving a joint estimation problem resulting in piecewise geodesic paths between image pairs, (iii) by kernel based local averaging or (iv) by augmenting the joint estimation with additional temporal irregularity penalties. Here, we propose a generative model extending least squares linear regression to the space of images by using a second-order dynamic formulation for image registration. Unlike previous approaches, the formulation allows for a compact representation of an approximation to the full spatio-temporal trajectory through its initial values. The method also opens up possibilities to design image-based approximation algorithms. The resulting optimization problem is solved using an adjoint method.},
  keywords = {MICCAI,LDDMM,regression,brain}
}

@inproceedings{DBLP:conf/miip/VachetHNOCWPS11,
  author    = {Clement Vachet and
               Heather Cody Hazlett and
               Marc Niethammer and
               Ipek Oguz and
               Joshua E. Cates and
               Ross T. Whitaker and
               Joseph Piven and
               Martin Styner},
  editor    = {Benoit M. Dawant and
               David R. Haynor},
  title     = {Group-wise automatic mesh-based analysis of cortical thickness},
  booktitle = {Medical Imaging 2011: Image Processing, Lake Buena Vista, Florida,
               USA, February 14-16, 2011},
  series    = {{SPIE} Proceedings},
  volume    = {7962},
  pages     = {796227},
  publisher = {{SPIE}},
  year      = {2011},
  url       = {https://doi.org/10.1117/12.878300},
  doi       = {10.1117/12.878300},
  timestamp = {Sun, 04 Jun 2017 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miip/VachetHNOCWPS11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {The analysis of neuroimaging data from pediatric populations presents several challenges. There are normal variations in brain shape from infancy to adulthood and normal developmental changes related to tissue maturation. Measurement of cortical thickness is one important way to analyze such developmental tissue changes. We developed a novel framework that allows group-wise automatic mesh-based analysis of cortical thickness. Our approach is divided into four main parts. First an individual pre-processing pipeline is applied on each subject to create genus-zero inflated white matter cortical surfaces with cortical thickness measurements. The second part performs an entropy-based group-wise shape correspondence on these meshes using a particle system, which establishes a trade-off between an even sampling of the cortical surfaces and the similarity of corresponding points across the population using sulcal depth information and spatial proximity. A novel automatic initial particle sampling is performed using a matched 98-lobe parcellation map prior to a particle-splitting phase. Third, corresponding re-sampled surfaces are computed with interpolated cortical thickness measurements, which are finally analyzed via a statistical vertex-wise analysis module. This framework consists of a pipeline of automated 3D Slicer compatible modules. It has been tested on a small pediatric dataset and incorporated in an open-source C++ based high-level module called GAMBIT. GAMBIT's setup allows efficient batch processing, grid computing and quality control. The current research focuses on the use of an average template for correspondence and surface re-sampling, as well as thorough validation of the framework and its application to clinical pediatric studies.},
  keywords = {SPIE,brain}
}

@inproceedings{DBLP:conf/miip/LiIGYNAM11,
  author    = {Wen Li and
               Luis Ib{\'{a}}{\~{n}}ez and
               Arnaud Gelas and
               B. T. Thomas Yeo and
               Marc Niethammer and
               Nancy Andreasen and
               Vincent A. Magnotta},
  editor    = {Benoit M. Dawant and
               David R. Haynor},
  title     = {An automated pipeline for cortical surface generation and registration
               of the cerebral cortex},
  booktitle = {Medical Imaging 2011: Image Processing, Lake Buena Vista, Florida,
               USA, February 14-16, 2011},
  series    = {{SPIE} Proceedings},
  volume    = {7962},
  pages     = {796229},
  publisher = {{SPIE}},
  year      = {2011},
  url       = {https://doi.org/10.1117/12.876509},
  doi       = {10.1117/12.876509},
  timestamp = {Sat, 19 Oct 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miip/LiIGYNAM11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {The human cerebral cortex is one of the most complicated structures in the body. It has a highly convoluted structure with much of the cortical sheet buried in sulci. Based on cytoarchitectural and functional imaging studies, it is possible to segment the cerebral cortex into several subregions. While it is only possible to differentiate the true anatomical subregions based on cytoarchitecture, the surface morphometry aligns closely with the underlying cytoarchitecture and provides features that allow the surface of the cortex to be parcellated based on the sulcal and gyral patterns that are readily visible on the MR images. We have developed a fully automated pipeline for the generation and registration of cortical surfaces in the spherical domain. The pipeline initiates with the BRAINS AutoWorkup pipeline. Subsequently, topology correction and surface generation is performed to generate a genus zero surface and mapped to a sphere. Several surface features are then calculated to drive the registration between the atlas surface and other datasets. A spherical diffeomorphic demons algorithm is used to co-register an atlas surface onto a subject surface. A lobar based atlas of the cerebral cortex was created from a manual parcellation of the cortex. The atlas surface was then co-registered to five additional subjects using a spherical diffeomorphic demons algorithm. The labels from the atlas surface were warped on the subject surface and compared to the manual raters. The average Dice overlap index was 0.89 across all regions.},
  keywords = {SPIE,brain}
}

@inproceedings{DBLP:conf/miip/LeeECNBPSJSO11,
  author    = {Joohwi Lee and
               Cindy Ehlers and
               Fulton Crews and
               Marc Niethammer and
               Fran{\c{c}}ois Budin and
               Beatriz Paniagua and
               Kathy Sulik and
               Josephine Johns and
               Martin Styner and
               Ipek Oguz},
  editor    = {Benoit M. Dawant and
               David R. Haynor},
  title     = {Automatic cortical thickness analysis on rodent brain},
  booktitle = {Medical Imaging 2011: Image Processing, Lake Buena Vista, Florida,
               USA, February 14-16, 2011},
  series    = {{SPIE} Proceedings},
  volume    = {7962},
  pages     = {796248},
  publisher = {{SPIE}},
  year      = {2011},
  url       = {https://doi.org/10.1117/12.878305},
  doi       = {10.1117/12.878305},
  timestamp = {Sat, 19 Oct 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miip/LeeECNBPSJSO11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Localized difference in the cortex is one of the most useful morphometric traits in human and animal brain studies. There are many tools and methods already developed to automatically measure and analyze cortical thickness for the human brain. However, these tools cannot be directly applied to rodent brains due to the different scales; even adult rodent brains are 50 to 100 times smaller than humans. This paper describes an algorithm for automatically measuring the cortical thickness of mouse and rat brains. The algorithm consists of three steps: segmentation, thickness measurement, and statistical analysis among experimental groups. The segmentation step provides the neocortex separation from other brain structures and thus is a preprocessing step for the thickness measurement. In the thickness measurement step, the thickness is computed by solving a Laplacian PDE and a transport equation. The Laplacian PDE first creates streamlines as an analogy of cortical columns; the transport equation computes the length of the streamlines. The result is stored as a thickness map over the neocortex surface. For the statistical analysis, it is important to sample thickness at corresponding points. This is achieved by the particle correspondence algorithm which minimizes entropy between dynamically moving sample points called particles. Since the computational cost of the correspondence algorithm may limit the number of corresponding points, we use thin-plate spline based interpolation to increase the number of corresponding sample points. As a driving application, we measured the thickness difference to assess the effects of adolescent intermittent ethanol exposure that persist into adulthood and performed t-test between the control and exposed rat groups. We found significantly differing regions in both hemispheres.},
  keywords = {SPIE,brain}
}

@article{DBLP:journals/ejasp/KerberSNLJ10,
  author    = {Florian Kerber and
               Helge Sprenger and
               Marc Niethammer and
               Kritsakorn Luangvilai and
               Laurence J. Jacobs},
  title     = {Attenuation Analysis of Lamb Waves Using the Chirplet Transform},
  journal   = {{EURASIP} J. Adv. Signal Process.},
  volume    = {2010},
  year      = {2010},
  url       = {https://doi.org/10.1155/2010/375171},
  doi       = {10.1155/2010/375171},
  timestamp = {Thu, 12 Mar 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/ejasp/KerberSNLJ10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Guided Lamb waves are commonly used in nondestructive evaluation to monitor plate-like structures or to characterize properties of composite or layered materials. However, the dispersive propagation and multimode excitability of Lamb waves complicate their analysis. Advanced signal processing techniques are therefore required to resolve both the time and frequency content of the time-domain wave signals. The chirplet transform (CT) has been introduced as a generalized time-frequency representation (TFR) incorporating more flexibility to adjust the window function to the group delay of the signal when compared to the more classical short-time Fourier transform (STFT). Exploiting this additional degree of freedom, this paper applies an adaptive algorithm based on the CT to calculate mode displacement ratios and attenuation of Lamb waves in elastic plate structures. The CT-based algorithm has a clear performance advantage when calculating mode displacement ratios and attenuation for numerically-simulated Lamb wave signals. For experimental data, the CT retains an advantage over the STFT although measurement noise and parameter uncertainties lead to larger overall deviations from the theoretically expected solutions.},
  keywords = {EURASIP,Lamb waves}
}

@inproceedings{DBLP:conf/isbi/LeeFNL10,
  author    = {Huai{-}Ping Lee and
               Mark Foskey and
               Marc Niethammer and
               Ming C. Lin},
  title     = {Physically-based deformable image registration with material property
               and boundary condition estimation},
  booktitle = {Proceedings of the 2010 {IEEE} International Symposium on Biomedical
               Imaging: From Nano to Macro, Rotterdam, The Netherlands, 14-17 April,
               2010},
  pages     = {532--535},
  publisher = {{IEEE}},
  year      = {2010},
  url       = {https://drive.google.com/file/d/1GMPl1egbcUelQ_m_-HG6Q8Ewke2e-RKX},
  doi       = {10.1109/ISBI.2010.5490293},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/LeeFNL10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We propose a new deformable medical image registration method that uses a physically-based simulator and an iterative optimizer to estimate the simulation parameters determining the deformation field between the two images. Although a simulation-based registration method can enforce physical constraints exactly and considers different material properties, it requires hand adjustment of material properties, and boundary conditions cannot be acquired directly from the images. We treat the material properties and boundary conditions as parameters for the optimizer, and integrate the physically-based simulation into the optimization loop to generate a physically accurate deformation automatically.},
  keywords = {ISBI,registration}
}

@inproceedings{DBLP:conf/isbi/ShanZN10,
  author    = {Liang Shan and
               Christopher Zach and
               Marc Niethammer},
  title     = {Automatic three-label bone segmentation from knee {MR} images},
  booktitle = {Proceedings of the 2010 {IEEE} International Symposium on Biomedical
               Imaging: From Nano to Macro, Rotterdam, The Netherlands, 14-17 April,
               2010},
  pages     = {1325--1328},
  publisher = {{IEEE}},
  year      = {2010},
  url       = {https://drive.google.com/file/d/1vx9NdLkIjNBrIXcUkwDQ08v145d9-IcW},
  doi       = {10.1109/ISBI.2010.5490241},
  timestamp = {Tue, 21 Jan 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/conf/isbi/ShanZN10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We propose a novel fully automatic three-label bone segmentation approach applied to knee segmentation (femur and tibia) from T1 and T2* magnetic resonance (MR) images. The three-label segmentation approach guarantees separate segmentations of femur and tibia which cannot be assured by general binary segmentation methods. The proposed approach is based on a convex optimization problem by embedding label assignment into higher dimensions. Appearance information is used in the segmentation to favor the segmentation of the cortical bone. We validate the proposed three-label segmentation method on nine knee MR images against manual segmentations for femur and tibia.},
  keywords = {ISBI,segmentation,knee}
}

@inproceedings{DBLP:conf/miar/NiethammerBZSMSS10,
  author    = {Marc Niethammer and
               Alexis Boucharin and
               Christopher Zach and
               Yundi Shi and
               Eric Maltbie and
               Mar Sanchez and
               Martin Styner},
  editor    = {Hongen Liao and
               Eddie Edwards and
               Xiaochuan Pan and
               Yong Fan and
               Guang{-}Zhong Yang},
  title     = {{DTI} Connectivity by Segmentation},
  booktitle = {Medical Imaging and Augmented Reality - 5th International Workshop,
               {MIAR} 2010, Beijing, China, September 19-20, 2010. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {6326},
  pages     = {200--210},
  publisher = {Springer},
  year      = {2010},
  url       = {https://drive.google.com/file/d/1D1-cVBnv5AB6-sLqFH6_8Zrhx6YjAN9Q},
  doi       = {10.1007/978-3-642-15699-1\_21},
  timestamp = {Tue, 14 May 2019 10:00:53 +0200},
  biburl    = {https://dblp.org/rec/conf/miar/NiethammerBZSMSS10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper proposes a new method to compute connectivity information from diffusion weighted images. It is inspired by graph-based approaches to connectivity definition, but formulates the estimation problem in the continuum. In particular, it defines the connectivity through the minimum cut in tensor-weighted space. It is therefore closely related to prior work on segmentation using continuous versions of graph cuts. A numerical solution based on a staggered grid is proposed which allows for the computation of flux directly through diffusion tensors. The resulting global connectivity measure is the maximum diffusive flow supported between two regions of interest.},
  keywords = {brain,diffusion,segmentation,MIAR}
}

@inproceedings{DBLP:conf/miccai/NiethammerBMWT10,
  author    = {Marc Niethammer and
               David Borland and
               J. S. Marron and
               John T. Woosley and
               Nancy E. Thomas},
  editor    = {Fei Wang and
               Pingkun Yan and
               Kenji Suzuki and
               Dinggang Shen},
  title     = {Appearance Normalization of Histology Slides},
  booktitle = {Machine Learning in Medical Imaging, First International Workshop,
               {MLMI} 2010, Held in Conjunction with {MICCAI} 2010, Beijing, China,
               September 20, 2010. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {6357},
  pages     = {58--66},
  publisher = {Springer},
  year      = {2010},
  url       = {https://drive.google.com/file/d/1ol0vcg7BgnAeD2kzeM_WZ7Cvc2fpCDbZ},
  doi       = {10.1007/978-3-642-15948-0\_8},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/NiethammerBMWT10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper presents a method for automatic color and intensity normalization of digitized histology slides stained with two different agents. In comparison to previous approaches, prior information on the stain vectors is used in the estimation process, resulting in improved stability of the estimates. Due to the prevalence of hematoxylin and eosin staining for histology slides, the proposed method has significant practical utility. In particular, it can be used as a first step to standardize appearances across slides, that is very effective at countering effects due to differing stain amounts and protocols, and to slide fading. The approach is validated using synthetic experiments and 13 real datasets.},
  keywords = {histology,MICCAI}
}

@inproceedings{DBLP:conf/miigp/KarasevMNKT10,
  author    = {Peter Karasev and
               James G. Malcolm and
               Marc Niethammer and
               Ron Kikinis and
               Allen R. Tannenbaum},
  editor    = {Kenneth H. Wong and
               Michael I. Miga},
  title     = {User-driven 3D mesh region targeting},
  booktitle = {Medical Imaging 2010: Visualization, Image-Guided Procedures, and
               Modeling, San Diego, California, United States, 13-18 February 2010},
  series    = {{SPIE} Proceedings},
  volume    = {7625},
  pages     = {762513},
  publisher = {{SPIE}},
  year      = {2010},
  url       = {https://drive.google.com/file/d/1DIMD-JGj7FbfbP7PJ5oznKuHS_OuHM6w},
  doi       = {10.1117/12.845661},
  timestamp = {Fri, 06 Jul 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miigp/KarasevMNKT10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We present a method for the fast selection of a region on a 3D mesh using geometric information. This is done using a weighted arc length minimization with a conformal factor based on the mean curvature of the 3D surface. A careful analysis of the geometric estimation process enables our geometric curve shortening to use a reliable smooth estimate of curvature and its gradient. The result is a robust way for a user to easily interact with particular regions of a 3D mesh construced from medical imaging. We describe the applicability of the method for real-time clinician use. In this study, we focus on building a robust and semi-automatic method for extracting selected folds on the cortical surface, specifically for isolating gyri by drawing a curve along the surrounding sulci. It is desirable to make this process semi-automatic because manually drawing a curve through the complex 3D mesh is extremely tedious, while automatic methods cannot realistically be expected to select the exact closed contour a user desires for a given dataset. In the technique described here, a user places a handful of seed points surrounding the gyri of interest; an initial curve is made from these points which then evolves to capture the region. We refer to this user-driven procedure as targeting or selection interchangeably.},
  keywords = {SPIE}
}

@inproceedings{DBLP:conf/miip/ShanZSCN10,
  author    = {Liang Shan and
               Christopher Zach and
               Martin Styner and
               Cecil Charles and
               Marc Niethammer},
  editor    = {Benoit M. Dawant and
               David R. Haynor},
  title     = {Automatic bone segmentation and alignment from {MR} knee images},
  booktitle = {Medical Imaging 2010: Image Processing, San Diego, California, USA,
               February 14-16, 2010},
  series    = {{SPIE} Proceedings},
  volume    = {7623},
  pages     = {76231K},
  publisher = {{SPIE}},
  year      = {2010},
  url       = {https://drive.google.com/file/d/1-LpAJ-ALe3M9BOvlPa_z-NKKAYDtA6rk},
  doi       = {10.1117/12.841167},
  timestamp = {Tue, 21 Jan 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/conf/miip/ShanZSCN10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Automatic image analysis of magnetic resonance (MR) images of the knee is simplified by bringing the knee into a reference position. While the knee is typically put into a reference position during image acquisition, this alignment will generally not be perfect. To correct for imperfections, we propose a two-step process of bone segmentation followed by elastic tissue deformation. The approach makes use of a fully-automatic segmentation of femur and tibia from T1 and T2* images. The segmentation algorithm is based on a continuous convex optimization problem, incorporating regional, and shape information. The regional terms are included from a probabilistic viewpoint, which readily allows the inclusion of shape information. Segmentation of the outer boundary of the cortical bone is encouraged by adding simple appearance-based information to the optimization problem. The resulting segmentation without the shape alignment step is globally optimal. Standard registration is problematic for knee alignment due to the distinct physical properties of the tissues constituting the knee (bone, muscle, etc.). We therefore develop an alternative alignment approach based on a simple elastic deformation model combined with strict enforcement of similarity transforms for femur and tibia based on the obtained segmentations.},
  keywords = {SPIE,knee,segmentation}
}

@article{DBLP:journals/cad/ReuterWSN09,
  author    = {Martin Reuter and
               Franz{-}Erich Wolter and
               Martha Elizabeth Shenton and
               Marc Niethammer},
  title     = {Laplace-Beltrami eigenvalues and topological features of eigenfunctions
               for statistical shape analysis},
  journal   = {Comput. Aided Des.},
  volume    = {41},
  number    = {10},
  pages     = {739--755},
  year      = {2009},
  url       = {https://drive.google.com/file/d/1n_gOTgbG6SH7uXfRC1Zv875nNCpsRGHv},
  doi       = {10.1016/j.cad.2009.02.007},
  timestamp = {Thu, 13 Feb 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/cad/ReuterWSN09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper proposes the use of the surface based Laplace-Beltrami and the volumetric Laplace eigenvalues and -functions as shape descriptors for the comparison and analysis of shapes. These spectral measures are isometry invariant and therefore allow for shape comparisons with minimal shape pre-processing. In particular, no registration, mapping, or remeshing is necessary. The discriminatory power of the 2D surface and 3D solid methods is demonstrated on a population of female caudate nuclei (a subcortical gray matter structure of the brain, involved in memory function, emotion processing, and learning) of normal control subjects and of subjects with schizotypal personality disorder. The behavior and properties of the Laplace-Beltrami eigenvalues and -functions are discussed extensively for both the Dirichlet and Neumann boundary condition showing advantages of the Neumann vs. the Dirichlet spectra in 3D. Furthermore, topological analyses employing the Morse-Smale complex (on the surfaces) and the Reeb graph (in the solids) are performed on selected eigenfunctions, yielding shape descriptors, that are capable of localizing geometric properties and detecting shape differences by indirectly registering topological features such as critical points, level sets and integral lines of the gradient field across subjects. The use of these topological features of the Laplace-Beltrami eigenfunctions in 2D and 3D for statistical shape analysis is novel.},
  keywords = {CAD,shape}
}

@article{DBLP:journals/neuroimage/NiethammerZMT09,
  author    = {Marc Niethammer and
               Christopher Zach and
               John Melonakos and
               Allen R. Tannenbaum},
  title     = {Near-tubular fiber bundle segmentation for diffusion weighted imaging:
               Segmentation through frame reorientation},
  journal   = {NeuroImage},
  volume    = {45},
  number    = {1},
  pages     = {S123--S132},
  year      = {2009},
  url       = {https://drive.google.com/file/d/1GrVdMUWweWO5nUEvd0OFWnc1AtKsDxs2},
  doi       = {10.1016/j.neuroimage.2008.11.001},
  timestamp = {Wed, 14 Nov 2018 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/neuroimage/NiethammerZMT09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper proposes a methodology to segment near-tubular fiber bundles from diffusion weighted magnetic resonance images (DW-MRI). Segmentation is simplified by locally reorienting diffusion information based on large-scale fiber bundle geometry. Segmentation is achieved through simple global statistical modeling of diffusion orientation. Utilizing a modification of a recent segmentation approach by Bresson et al. allows for a convex optimization formulation of the segmentation problem, combining orientation statistics and spatial regularization. The approach compares favorably with segmentation by full-brain streamline tractography.},
  keywords = {segmentation,brain,NeuroImage}
}

@article{DBLP:journals/neuroimage/VoineskosOLMANMPKWS09,
  author    = {Aristotle N. Voineskos and
               Lauren J. O'Donnell and
               Nancy J. Lobaugh and
               Douglas Markant and
               Stephanie Ameis and
               Marc Niethammer and
               Benoit H. Mulsant and
               Bruce G. Pollock and
               James L. Kennedy and
               Carl{-}Fredrik Westin and
               Martha Elizabeth Shenton},
  title     = {Quantitative examination of a novel clustering method using magnetic
               resonance diffusion tensor tractography},
  journal   = {NeuroImage},
  volume    = {45},
  number    = {2},
  pages     = {370--376},
  year      = {2009},
  url       = {https://doi.org/10.1016/j.neuroimage.2008.12.028},
  doi       = {10.1016/j.neuroimage.2008.12.028},
  timestamp = {Wed, 14 Nov 2018 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/neuroimage/VoineskosOLMANMPKWS09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {MR diffusion tensor imaging (DTI) can measure and visualize organization of white matter fibre tracts in vivo. DTI is a relatively new imaging technique, and new tools developed for quantifying fibre tracts require evaluation. The purpose of this study was to compare the reliability of a novel clustering approach with a multiple region of interest (MROI) approach in both healthy and disease (schizophrenia) populations. DTI images were acquired in 20 participants (n=10 patients with schizophrenia: 56 ± 15 years; n=10 controls: 51 ± 20 years) (1.5 Tesla GE system) with diffusion gradients applied in 23 non-collinear directions, repeated three times. Whole brain seeding and creation of fibre tracts were then performed. Interrater reliability of the clustering approach, and the MROI approach, were each evaluated and the methods compared. There was high spatial (voxelbased) agreement within and between the clustering and MROI methods. Fractional anisotropy, trace, and radial and axial diffusivity values showed high intraclass correlation (p<0.001 for all tracts) for each approach. Differences in scalar indices of diffusion between the clustering and MROI approach were minimal. The excellent interrater reliability of the clustering method and high agreement with the MROI method, quantitatively and spatially, indicates that the clustering method can be used with confidence. The clustering method avoids biases of ROI drawing and placement, and, not limited by a priori predictions, may be a more robust and efficient way to identify and measure white matter tracts of interest.},
  keywords = {diffusion,NeuroImage,brain}
}

@article{DBLP:journals/neuroimage/GerardinCCCDKNDLGEC09,
  author    = {Emilie Gerardin and
               Ga{\"{e}}l Ch{\'{e}}telat and
               Marie Chupin and
               R{\'{e}}mi Cuingnet and
               B{\'{e}}atrice Desgranges and
               Hosung Kim and
               Marc Niethammer and
               Bruno Dubois and
               St{\'{e}}phane Leh{\'{e}}ricy and
               Line Garnero and
               Francis Eustache and
               Olivier Colliot},
  title     = {Multidimensional classification of hippocampal shape features discriminates
               Alzheimer's disease and mild cognitive impairment from normal aging},
  journal   = {NeuroImage},
  volume    = {47},
  number    = {4},
  pages     = {1476--1486},
  year      = {2009},
  url       = {https://doi.org/10.1016/j.neuroimage.2009.05.036},
  doi       = {10.1016/j.neuroimage.2009.05.036},
  timestamp = {Sat, 19 Oct 2019 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/neuroimage/GerardinCCCDKNDLGEC09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We describe a new method to automatically discriminate between patients with Alzheimer's disease (AD) or mild cognitive impairment (MCI) and elderly controls, based on multidimensional classification of hippocampal shape features. This approach uses spherical harmonics (SPHARM) coefficients to model the shape of the hippocampi, which are segmented from magnetic resonance images (MRI) using a fully automatic method that we previously developed. SPHARM coefficients are used as features in a classification procedure based on support vector machines (SVM). The most relevant features for classification are selected using a bagging strategy. We evaluate the accuracy of our method in a group of 23 patients with AD (10 males, 13 females, age ±standard-deviation (SD)=73±6 years, mini-mental score (MMS)=24.4±2.8), 23 patients with amnestic MCI (10 males, 13 females, age±SD=74±8 years, MMS=27.3±1.4) and 25 elderly healthy controls (13 males,12 females, age±SD=64±8 years), using leave-one-out cross-validation. For AD vs controls, we obtain a correct classification rate of 94\%, a sensitivity of 96\%, and a specificity of 92\%. For MCI vs controls, we obtain a classification rate of 83\%, a sensitivity of 83\%, and a specificity of 84\%. This accuracy is superior to that of hippocampal volumetry and is comparable to recently published SVM-based whole-brain classification methods, which relied on a different strategy. This new method may become a useful tool to assist in the diagnosis of Alzheimer's disease.},
  keywords = {shape,NeuroImage,brain}
}

@inproceedings{DBLP:conf/cdc/NiethammerHZ09,
  author    = {Marc Niethammer and
               Gabriel L. Hart and
               Christopher Zach},
  title     = {An optimal control approach for the registration of image time-series},
  booktitle = {Proceedings of the 48th {IEEE} Conference on Decision and Control,
               {CDC} 2009, combined withe the 28th Chinese Control Conference, December
               16-18, 2009, Shanghai, China},
  pages     = {2427--2434},
  publisher = {{IEEE}},
  year      = {2009},
  url       = {https://drive.google.com/file/d/1gTrmj1GjplanVmA00nF_Z7kA4raR_CBT},
  doi       = {10.1109/CDC.2009.5399532},
  timestamp = {Wed, 16 Oct 2019 14:14:56 +0200},
  biburl    = {https://dblp.org/rec/conf/cdc/NiethammerHZ09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper discusses an optimal control approach for the registration of image time-series (growth modeling). It combines and augments work on an optimal control formulation to optical flow with theory from large-displacement diffeomorphic image registration. The unification of the two viewpoints leads to (i) a more efficient computation of the gradient of the optimization problem, (ii) an easier numerical implementation, and (iii) an intuitive interpretation of the adjoint equation underlying the optimization problem. Further, a novel formulation for the unbiased estimation of image correspondences across time is proposed.},
  keywords = {CDC,registration,LDDMM,brain}
}

@inproceedings{DBLP:conf/cvpr/HartZN09,
  author    = {Gabriel L. Hart and
               Christopher Zach and
               Marc Niethammer},
  title     = {An optimal control approach for deformable registration},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               Workshops 2009, Miami, FL, USA, 20-25 June, 2009},
  pages     = {9--16},
  publisher = {{IEEE} Computer Society},
  year      = {2009},
  url       = {https://drive.google.com/file/d/1AHueQBI6IKfHdk8k4GqvKrYduYcVTSAi},
  doi       = {10.1109/CVPRW.2009.5204344},
  timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/HartZN09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper addresses large-displacement-diffeomorphic mapping registration from an optimal control perspective. This viewpoint leads to two complementary formulations. One approach requires the explicit computation of coordinate maps, whereas the other is formulated strictly in the image domain (thus making it also applicable to manifolds which require multiple coordinate charts). We discuss their intrinsic relation as well as the advantages and disadvantages of the two approaches. Further, we propose a novel formulation for unbiased image registration, which naturally extends to the case of time-series of images. We discuss numerical implementation details and carefully evaluate the properties of the alternative algorithms.},
  keywords = {CVPR,LDDMM,registration,brain}
}

@inproceedings{DBLP:conf/cvpr/ZachNF09,
  author    = {Christopher Zach and
               Marc Niethammer and
               Jan{-}Michael Frahm},
  title     = {Continuous maximal flows and Wulff shapes: Application to MRFs},
  booktitle = {2009 {IEEE} Computer Society Conference on Computer Vision and Pattern
               Recognition {(CVPR} 2009), 20-25 June 2009, Miami, Florida, {USA}},
  pages     = {1911--1918},
  publisher = {{IEEE} Computer Society},
  year      = {2009},
  url       = {https://drive.google.com/file/d/1yWM4KipARSVek2-1mgQE_H9iOeSs4JXj},
  doi       = {10.1109/CVPR.2009.5206565},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/ZachNF09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Convex and continuous energy formulations for low level vision problems enable efficient search procedures for the corresponding globally optimal solutions. In this work we extend the well-established continuous, isotropic capacity-based maximal flow framework to the anisotropic setting. By using powerful results from convex analysis, a very simple and efficient minimization procedure is derived. Further, we show that many important properties carry over to the new anisotropic framework, e.g. globally optimal binary results can be achieved simply by thresholding the continuous solution. In addition, we unify the anisotropic continuous maximal flow approach with a recently proposed convex and continuous formulation for Markov random fields, thereby allowing more general smoothness priors to be incorporated. Dense stereo results are included to illustrate the capabilities of the proposed approach.},
  keywords = {CVPR,convex}
}

@inproceedings{DBLP:conf/dagm/ZachSN09,
  author    = {Christopher Zach and
               Liang Shan and
               Marc Niethammer},
  editor    = {Joachim Denzler and
               Gunther Notni and
               Herbert S{\"{u}}{\ss}e},
  title     = {Globally Optimal Finsler Active Contours},
  booktitle = {Pattern Recognition, 31st {DAGM} Symposium, Jena, Germany, September
               9-11, 2009. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {5748},
  pages     = {552--561},
  publisher = {Springer},
  year      = {2009},
  url       = {https://drive.google.com/file/d/1mHxbqIt3U7QaqySLePpuZQDNgTsFrioL},
  doi       = {10.1007/978-3-642-03798-6\_56},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/dagm/ZachSN09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We present a continuous and convex formulation for Finsler active contours using seed regions or utilizing a regional bias term. The utilization of general Finsler metrics instead of Riemannian metrics allows the segmentation boundary to favor appropriate locations (e.g. with strong image discontinuities) and suitable directions (e.g. aligned with dark to bright image gradients). Strong edges are not required everywhere along the desired segmentation boundary due to incorporation of a regional bias. The resulting optimization procedure is simple and efficient, and leads to binary segmentation results regardless of the underlying continuous formulation. We demonstrate the proposed method in several examples.},
  keywords = {DAGM,convex}
}

@inproceedings{DBLP:conf/ipmi/OguzNCWFVS09,
  author    = {Ipek Oguz and
               Marc Niethammer and
               Joshua E. Cates and
               Ross T. Whitaker and
               P. Thomas Fletcher and
               Clement Vachet and
               Martin Styner},
  editor    = {Jerry L. Prince and
               Dzung L. Pham and
               Kyle J. Myers},
  title     = {Cortical Correspondence with Probabilistic Fiber Connectivity},
  booktitle = {Information Processing in Medical Imaging, 21st International Conference,
               {IPMI} 2009, Williamsburg, VA, USA, July 5-10, 2009. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {5636},
  pages     = {651--663},
  publisher = {Springer},
  year      = {2009},
  url       = {https://drive.google.com/file/d/1S4NEs7casftVyi6lWD4mqcIMdYu2PGpX},
  doi       = {10.1007/978-3-642-02498-6\_54},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/ipmi/OguzNCWFVS09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper presents a novel method of optimizing point-based correspondence among populations of human cortical surfaces by combining structural cues with probabilistic connectivity maps. The proposed method establishes a tradeoff between an even sampling of the cortical surfaces (a low surface entropy) and the similarity of corresponding points across the population (a low ensemble entropy). The similarity metric, however, isn’t constrained to be just spatial proximity, but uses local sulcal depth measurements as well as probabilistic connectivity maps, computed from DWI scans via a stochastic tractography algorithm, to enhance the correspondence definition. We propose a novel method for projecting this fiber connectivity information on the cortical surface, using a surface evolution technique. Our cortical correspondence method does not require a spherical parameterization. Experimental results are presented, showing improved correspondence quality demonstrated by a cortical thickness analysis, as compared to correspondence methods using spatial metrics as the sole correspondence criterion.},
  keywords = {IPMI,diffusion,brain}
}

@inproceedings{DBLP:conf/isbi/MacenkoNMBWGST09,
  author    = {Marc Macenko and
               Marc Niethammer and
               J. S. Marron and
               David Borland and
               John T. Woosley and
               Xiaojun Guan and
               Charles Schmitt and
               Nancy E. Thomas},
  title     = {A Method for Normalizing Histology Slides for Quantitative Analysis},
  booktitle = {Proceedings of the 2009 {IEEE} International Symposium on Biomedical
               Imaging: From Nano to Macro, Boston, MA, USA, June 28 - July 1, 2009},
  pages     = {1107--1110},
  publisher = {{IEEE}},
  year      = {2009},
  url       = {https://drive.google.com/file/d/1eZGi1wUdyxVOYADXUbxZiVtajlztSnGL},
  doi       = {10.1109/ISBI.2009.5193250},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/MacenkoNMBWGST09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Inconsistencies in the preparation of histology slides make it difficult to perform quantitative analysis on their results. In this paper we provide two mechanisms for overcoming many of the known inconsistencies in the staining process, thereby bringing slides that were processed or stored under very different conditions into a common, normalized space to enable improved quantitative analysis.},
  keywords = {ISBI,histology}
}

@article{DBLP:journals/pami/NiethammerVT08,
  author    = {Marc Niethammer and
               Patricio A. Vela and
               Allen R. Tannenbaum},
  title     = {Geometric Observers for Dynamically Evolving Curves},
  journal   = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume    = {30},
  number    = {6},
  pages     = {1093--1108},
  year      = {2008},
  url       = {https://drive.google.com/file/d/1IzXZTSWvEhydxwiUnSnt61kIKeP9HqBV},
  doi       = {10.1109/TPAMI.2008.28},
  timestamp = {Wed, 14 Nov 2018 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/pami/NiethammerVT08.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper proposes a deterministic observer design for visual tracking based on nonparametric implicit (level-set) curve descriptions. The observer is continuous discrete with continuous-time system dynamics and discrete-time measurements. Its state-space consists of an estimated curve position augmented by additional states (e.g., velocities) associated with every point on the estimated curve. Multiple simulation models are proposed for state prediction. Measurements are performed through standard static segmentation algorithms and optical-flow computations. Special emphasis is given to the geometric formulation of the overall dynamical system. The discrete-time measurements lead to the problem of geometric curve interpolation and the discrete-time filtering of quantities propagated along with the estimated curve. Interpolation and filtering are intimately linked to the correspondence problem between curves. Correspondences are established by a Laplace-equation approach. The proposed scheme is implemented completely implicitly (by Eulerian numerical solutions of transport equations) and thus naturally allows for topological changes and subpixel accuracy on the computational grid.},
  keywords = {PAMI,curves}
}

@article{DBLP:journals/tcst/VelaNPTBW08,
  author    = {Patricio A. Vela and
               Marc Niethammer and
               Gallagher Pryor and
               Allen R. Tannenbaum and
               Robert Butts and
               Donald Washburn},
  title     = {Knowledge-Based Segmentation for Tracking Through Deep Turbulence},
  journal   = {{IEEE} Trans. Control. Syst. Technol.},
  volume    = {16},
  number    = {3},
  pages     = {469--474},
  year      = {2008},
  url       = {https://doi.org/10.1109/TCST.2007.899723},
  doi       = {10.1109/TCST.2007.899723},
  timestamp = {Mon, 08 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/tcst/VelaNPTBW08.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {A combined knowledge-based segmentation/active contour algorithm is used for target tracking through turbulence. The algorithm utilizes Bayesian modeling for segmentation of noisy imagery obtained through longrange, laser imaging of a distance target, and active contours for tip tracking. The algorithm demonstrates improved target tracking performance when compared to weighted centroiding. Open-loop and closed-loop comparisons of the algorithms using simulated imagery validate the hypothesis.},
  keywords = {segmentation,TCST}
}

@article{DBLP:journals/tmi/Aja-FernandezNKSW08,
  author    = {Santiago Aja{-}Fern{\'{a}}ndez and
               Marc Niethammer and
               Marek Kubicki and
               Martha Elizabeth Shenton and
               Carl{-}Fredrik Westin},
  title     = {Restoration of {DWI} Data Using a Rician {LMMSE} Estimator},
  journal   = {{IEEE} Trans. Medical Imaging},
  volume    = {27},
  number    = {10},
  pages     = {1389--1403},
  year      = {2008},
  url       = {https://drive.google.com/file/d/1O-TzwyC4uzJ5YAfjqfem8JxmCzW9pZaN},
  doi       = {10.1109/TMI.2008.920609},
  timestamp = {Thu, 18 Jun 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/tmi/Aja-FernandezNKSW08.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper introduces and analyzes a linear minimum mean square error (LMMSE) estimator using a Rician noise model and its recursive version (RLMMSE) for the restoration of diffusion weighted images. A method to estimate the noise level based on local estimations of mean or variance is used to automatically parametrize the estimator. The restoration performance is evaluated using quality indexes and compared to alternative estimation schemes. The overall scheme is simple, robust, fast, and improves estimations. Filtering diffusion weighted magnetic resonance imaging (DW-MRI) with the proposed methodology leads to more accurate tensor estimations. Real and synthetic datasets are analyzed.},
  keywords = {TMI,diffusion,brain}
}

@inproceedings{DBLP:conf/miip/RathiDNMLST08,
  author    = {Yogesh Rathi and
               Samuel Dambreville and
               Marc Niethammer and
               James G. Malcolm and
               James J. Levitt and
               Martha Elizabeth Shenton and
               Allen R. Tannenbaum},
  editor    = {Joseph M. Reinhardt and
               Josien P. W. Pluim},
  title     = {Segmenting images analytically in shape space},
  booktitle = {Medical Imaging 2008: Image Processing, San Diego, California, United
               States, 16-21 February 2008},
  series    = {{SPIE} Proceedings},
  volume    = {6914},
  pages     = {691405},
  publisher = {{SPIE}},
  year      = {2008},
  url       = {https://drive.google.com/file/d/1FqUzsV6xpSoLB5X7CEPI80aZ9VpeaQYK},
  doi       = {10.1117/12.769511},
  timestamp = {Fri, 06 Jul 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miip/RathiDNMLST08.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper presents a novel analytic technique to perform shape-driven segmentation. In our approach, shapes are represented using binary maps, and linear PCA is utilized to provide shape priors for segmentation. Intensity based probability distributions are then employed to convert a given test volume into a binary map representation, and a novel energy functional is proposed whose minimum can be analytically computed to obtain the desired segmentation in the shape space. We compare the proposed method with the log-likelihood based energy to elucidate some key differences. Our algorithm is applied to the segmentation of brain caudate nucleus and hippocampus from MRI data, which is of interest in the study of schizophrenia and Alzheimer’s disease. Our validation (we compute the Hausdorff distance and the DICE coefficient between the automatic segmentation and ground-truth) shows that the proposed algorithm is very fast, requires no initialization and outperforms the log-likelihood based energy.},
  keywords = {segmentation,brain,SPIE}
}

@inproceedings{DBLP:conf/vmv/ZachGFN08,
  author    = {Christopher Zach and
               David Gallup and
               Jan{-}Michael Frahm and
               Marc Niethammer},
  editor    = {Oliver Deussen and
               Daniel A. Keim and
               Dietmar Saupe},
  title     = {Fast Global Labeling for Real-Time Stereo Using Multiple Plane Sweeps},
  booktitle = {Proceedings of the Vision, Modeling, and Visualization Conference
               2008, {VMV} 2008, Konstanz, Germany, October 8-10, 2008},
  pages     = {243--252},
  publisher = {Aka GmbH},
  year      = {2008},
  timestamp = {Tue, 23 Feb 2010 12:52:45 +0100},
  url = {https://drive.google.com/file/d/1JZBmX_xJWzFFxFOIwK4EP7YvEvWesLkn},
  biburl    = {https://dblp.org/rec/conf/vmv/ZachGFN08.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This work presents a real-time, data-parallel approach for global label assignment on regular grids. The labels are selected according to a Markov ran-dom field energy with a Potts prior term for binary interactions. We apply the proposed method to accelerate the clean-up step of a real-time dense stereo method based on plane sweeping with multi-ple sweeping directions, where the label set directly corresponds to the employed directions. In this set-ting the Potts smoothness model is suitable, since the set of labels does not possess an intrinsic metric or total order. The observed run-times are approximately 30 times faster than the ones obtained by graph cut approaches.},
  keywords = {VMV}
}

@inproceedings{DBLP:conf/bmvc/DambrevilleNYT07,
  author    = {Samuel Dambreville and
               Marc Niethammer and
               Anthony J. Yezzi and
               Allen R. Tannenbaum},
  editor    = {Nasir M. Rajpoot and
               Abhir H. Bhalerao},
  title     = {A Variational Framework Combining Level-sets and Thresholding},
  booktitle = {Proceedings of the British Machine Vision Conference 2007, University
               of Warwick, UK, September 10-13, 2007},
  pages     = {1--10},
  publisher = {British Machine Vision Association},
  year      = {2007},
  url       = {https://drive.google.com/file/d/1uQ1jDul7b1Enm-zK1CAuQoekoaPv0PMN},
  doi       = {10.5244/C.21.53},
  timestamp = {Fri, 06 Jul 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/bmvc/DambrevilleNYT07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Segmentation involves separating distinct regions in an image. In this note, we present a novel variational approach to perform this task. We propose an energy functional that naturally combines two segmentation techniques usually applied separately: intensity thresholding and geometric active contours. Although our method can deal with more complex image statistics, intensity averages are used to separate regions, in this present work. The proposed approach affords interesting properties that can lead to sensible segmentation results.},
  keywords = {BMVC,segmentation}
}

@inproceedings{DBLP:conf/bmvc/MohanMTNK07,
  author    = {Vandana Mohan and
               John Melonakos and
               Allen R. Tannenbaum and
               Marc Niethammer and
               Marek Kubicki},
  editor    = {Nasir M. Rajpoot and
               Abhir H. Bhalerao},
  title     = {Finsler Level Set Segmentation for Imagery in Oriented Domains},
  booktitle = {Proceedings of the British Machine Vision Conference 2007, University
               of Warwick, UK, September 10-13, 2007},
  pages     = {1--9},
  publisher = {British Machine Vision Association},
  year      = {2007},
  url       = {https://drive.google.com/file/d/199S4Ouuqc-MzY1eqcioBl0lYTZohK9kl},
  doi       = {10.5244/C.21.46},
  timestamp = {Fri, 06 Jul 2018 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/bmvc/MohanMTNK07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper, we present a novel directional level set segmentation framework employing the theory of Finsler active contours. The framework provides a natural way to perform segmentation of image data in oriented domains. We share examples of this technique on diffusion-weighted magnetic resonance imagery (DW-MRI) for the segmentation of neural fiber bundles and we show examples of texture based segmentation using structure tensors. We also demonstrate that for some applications higher accuracy is achieved by the proposed framework than by level set methods that employ Riemannian metrics. This gain is attributed to the relaxation of the tensor model constraint which is imposed upon the metric in the Riemannian case.},
  keywords = {BMVC,segmentation}
}

@inproceedings{DBLP:conf/cw/ReuterNWBS07,
  author    = {Martin Reuter and
               Marc Niethammer and
               Franz{-}Erich Wolter and
               Sylvain Bouix and
               Martha Elizabeth Shenton},
  editor    = {Franz{-}Erich Wolter and
               Alexei Sourin},
  title     = {Global Medical Shape Analysis Using the Volumetric Laplace Spectrum},
  booktitle = {2007 International Conference on Cyberworlds, {CW} 2007, Hannover,
               Germany, October 24-26, 2007},
  pages     = {417--426},
  publisher = {{IEEE} Computer Society},
  year      = {2007},
  url       = {https://drive.google.com/file/d/1yZNCTD_maG8STPneKJXdNgp79NF83uZv},
  doi       = {10.1109/CW.2007.42},
  timestamp = {Wed, 16 Oct 2019 14:14:49 +0200},
  biburl    = {https://dblp.org/rec/conf/cw/ReuterNWBS07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper proposes to use the volumetric Laplace spectrum as a global shape descriptor for medical shape analysis. The approach allows for shape comparisons using minimal shape preprocessing. In particular, no registration, mapping, or remeshing is necessary. All computations can be performed directly on the voxel representations of the shapes. The discriminatory power of the method is tested on a population of female caudate shapes (brain structure) of normal control subjects and of subjects with schizotypal personality disorder. The behavior and properties of the volumetric Laplace spectrum are discussed extensively for both the Dirichlet and Neumann boundary condition showing advantages of the Neumann spectra. Both, the computations of spectra on 3D voxel data for shape matching as well as the use of the Neumann spectrum for shape analysis are completely new.},
  keywords = {CW,shape}
}

@inproceedings{DBLP:conf/iccv/MelonakosNMKMT07,
  author    = {John Melonakos and
               Marc Niethammer and
               Vandana Mohan and
               Marek Kubicki and
               James V. Miller and
               Allen R. Tannenbaum},
  title     = {Locally-Constrained Region-Based Methods for {DW-MRI} Segmentation},
  booktitle = {{IEEE} 11th International Conference on Computer Vision, {ICCV} 2007,
               Rio de Janeiro, Brazil, October 14-20, 2007},
  pages     = {1--8},
  publisher = {{IEEE} Computer Society},
  year      = {2007},
  url       = {https://doi.org/10.1109/ICCV.2007.4409167},
  doi       = {10.1109/ICCV.2007.4409167},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/iccv/MelonakosNMKMT07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper, we describe a method for segmenting fiber bundles from diffusion-weighted magnetic resonance images using a locally-constrained region based approach. From a pre-computed optimal path, the algorithm propagates outward capturing only those voxels which are locally connected to the fiber bundle. Rather than attempting to find large numbers of open curves or single fibers, which individually have questionable meaning, this method segments the full fiber bundle region. The strengths of this approach include its ease-of-use, computational speed, and applicability to a wide range of fiber bundles. In this work, we show results for segmenting the cingulum bundle. Finally, we explain how this approach and extensions thereto overcome a major problem that typical region-based flows experience when attempting to segment neural fiber bundles.},
  keywords = {ICCV,segmentation,diffusion}
}

@inproceedings{DBLP:conf/isbi/NainSNLSGBT07,
  author    = {Delphine Nain and
               Martin Andreas Styner and
               Marc Niethammer and
               James J. Levitt and
               Martha Elizabeth Shenton and
               Guido Gerig and
               Aaron F. Bobick and
               Allen R. Tannenbaum},
  title     = {Statistical Shape Analysis of Brain Structures Using Spherical Wavelets},
  booktitle = {Proceedings of the 2007 {IEEE} International Symposium on Biomedical
               Imaging: From Nano to Macro, Washington, DC, USA, April 12-16, 2007},
  pages     = {209--212},
  publisher = {{IEEE}},
  year      = {2007},
  url       = {https://drive.google.com/file/d/1VO0T83aoaU9hIg8ObPfs4sgO8tsQUdEX},
  doi       = {10.1109/ISBI.2007.356825},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/isbi/NainSNLSGBT07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We present a novel method of statistical surface-based morphometry based on the use of non-parametric permutation tests and a spherical wavelet (SWC) shape representation. As an application, we analyze two brain structures, the caudate nucleus and the hippocampus, and compare the results obtained to shape analysis using a sampled point representation. Our results show that the SWC representation indicates new areas of significance preserved under the FDR correction for both the left caudate nucleus and left hippocampus. Additionally, the spherical wavelet representation provides a natural way to interpret the significance results in terms of scale in addition to knowing the spatial location of the regions.},
  keywords = {ISBI,brain,shape}
}

@inproceedings{DBLP:conf/miccai/KindlmannENHW07,
  author    = {Gordon L. Kindlmann and
               Ra{\'{u}}l San Jos{\'{e}} Est{\'{e}}par and
               Marc Niethammer and
               Steven Haker and
               Carl{-}Fredrik Westin},
  editor    = {Nicholas Ayache and
               S{\'{e}}bastien Ourselin and
               Anthony J. Maeder},
  title     = {Geodesic-Loxodromes for Diffusion Tensor Interpolation and Difference
               Measurement},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2007, 10th International Conference, Brisbane, Australia, October
               29 - November 2, 2007, Proceedings, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {4791},
  pages     = {1--9},
  publisher = {Springer},
  year      = {2007},
  url       = {https://drive.google.com/file/d/1LMnwRLRUBqWEzxN3a9mqRYXzOSohGWsx},
  doi       = {10.1007/978-3-540-75757-3\_1},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/KindlmannENHW07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In algorithms for processing diffusion tensor images, two common ingredients are interpolating tensors, and measuring the distance between them. We propose a new class of interpolation paths for tensors, termed geodesic-loxodromes, which explicitly preserve clinically important tensor attributes, such as mean diffusivity or fractional anisotropy, while using basic differential geometry to interpolate tensor orientation. This contrasts with previous Riemannian and Log-Euclidean methods that preserve the determinant. Path integrals of tangents of geodesic-loxodromes generate novel measures of over-all difference between two tensors, and of difference in shape and in orientation.},
  keywords = {MICCAI,diffusion,brain}
}

@inproceedings{DBLP:conf/miccai/MelonakosMNSKT07,
  author    = {John Melonakos and
               Vandana Mohan and
               Marc Niethammer and
               Kate Smith and
               Marek Kubicki and
               Allen R. Tannenbaum},
  editor    = {Nicholas Ayache and
               S{\'{e}}bastien Ourselin and
               Anthony J. Maeder},
  title     = {Finsler Tractography for White Matter Connectivity Analysis of the
               Cingulum Bundle},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2007, 10th International Conference, Brisbane, Australia, October
               29 - November 2, 2007, Proceedings, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {4791},
  pages     = {36--43},
  publisher = {Springer},
  year      = {2007},
  url       = {https://drive.google.com/file/d/1OTDcW5aRNj9LZ5IVLNbHGEVyqBev-JWK},
  doi       = {10.1007/978-3-540-75757-3\_5},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/MelonakosMNSKT07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper, we present a novel approach for the segmentation of white matter tracts based on Finsler active contours. This technique provides an optimal measure of connectivity, explicitly segments the connecting fiber bundle, and is equipped with a metric which is able to utilize the directional information of high angular resolution data. We demonstrate the effectiveness of the algorithm for segmenting the cingulum bundle.},
  keywords = {brain,diffusion,MICCAI}
}

@inproceedings{DBLP:conf/miccai/NiethammerBAWS07,
  author    = {Marc Niethammer and
               Sylvain Bouix and
               Santiago Aja{-}Fern{\'{a}}ndez and
               Carl{-}Fredrik Westin and
               Martha Elizabeth Shenton},
  editor    = {Nicholas Ayache and
               S{\'{e}}bastien Ourselin and
               Anthony J. Maeder},
  title     = {Outlier Rejection for Diffusion Weighted Imaging},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2007, 10th International Conference, Brisbane, Australia, October
               29 - November 2, 2007, Proceedings, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {4791},
  pages     = {161--168},
  publisher = {Springer},
  year      = {2007},
  url       = {https://drive.google.com/file/d/1uat7VFdkfwNhqPdlJRKt-i3rjn51A8hb},
  doi       = {10.1007/978-3-540-75757-3\_20},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/NiethammerBAWS07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper introduces an outlier rejection and signal reconstruction method for high angular resolution diffusion weighted imaging. The approach is based on the thresholding of Laplacian measurements over the sphere of the apparent diffusion coefficient profiles defined for a given set of gradient directions. Exemplary results are presented.},
  keywords = {MICCAI,diffusion,brain}
}

@inproceedings{DBLP:conf/miccai/NiethammerRWBPKS07,
  author    = {Marc Niethammer and
               Martin Reuter and
               Franz{-}Erich Wolter and
               Sylvain Bouix and
               Niklas Peinecke and
               Min{-}Seong Koo and
               Martha Elizabeth Shenton},
  editor    = {Nicholas Ayache and
               S{\'{e}}bastien Ourselin and
               Anthony J. Maeder},
  title     = {Global Medical Shape Analysis Using the Laplace-Beltrami Spectrum},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2007, 10th International Conference, Brisbane, Australia, October
               29 - November 2, 2007, Proceedings, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {4791},
  pages     = {850--857},
  publisher = {Springer},
  year      = {2007},
  url       = {https://drive.google.com/file/d/1jAFoK69aUm3SRmdHRt-Xj6Fbp_qpzKI6},
  doi       = {10.1007/978-3-540-75757-3\_103},
  timestamp = {Wed, 25 Sep 2019 18:20:36 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/NiethammerRWBPKS07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {This paper proposes to use the Laplace-Beltrami spectrum (LBS) as a global shape descriptor for medical shape analysis, allowing for shape comparisons using minimal shape preprocessing: no registration, mapping, or remeshing is necessary. The discriminatory power of the method is tested on a population of female caudate shapes of normal control subjects and of subjects with schizotypal personality disorder.},
  keywords = {MICCAI,shape,brain}
}

@inproceedings{DBLP:conf/sip/DambrevilleNYT07,
  author    = {Samuel Dambreville and
               Marc Niethammer and
               Anthony J. Yezzi and
               Allen R. Tannenbaum},
  editor    = {Rui J. P. de Figueiredo},
  title     = {A variational segmentation framework using active contours and thresholding},
  booktitle = {Signal and Image Processing {(SIP} 2007), Proceedings of the {IASTED}
               International Conference, August 20-22, 2007, Honolulu, HI, {USA}},
  pages     = {180--185},
  publisher = {{IASTED/ACTA} Press},
  year      = {2007},
  timestamp = {Fri, 06 Jul 2018 01:00:00 +0200},
  url = {https://drive.google.com/file/d/1aLBzhS2PCBZZKNE0Q81hnOVYjIKPQZDm},
  biburl    = {https://dblp.org/rec/conf/sip/DambrevilleNYT07.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Segmentation involves separating distinct regions in an image. In this note, we present a novel variational approach to perform this task. We propose an energy functional that naturally combines two segmentation techniques usually applied separately: intensity thresholding and geometric active contours. Although our method can deal with more complex image statistics, intensity averages are used to separate regions, in this present work. The proposed approach affords interesting properties that can lead to sensible segmentation results.},
  keywords = {SIP,segmentation}
}

@article{DBLP:journals/tac/NiethammerTA06,
  author    = {Marc Niethammer and
               Allen R. Tannenbaum and
               Sigurd B. Angenent},
  title     = {Dynamic active contours for visual tracking},
  journal   = {{IEEE} Trans. Autom. Control.},
  volume    = {51},
  number    = {4},
  pages     = {562--579},
  year      = {2006},
  url       = {https://drive.google.com/file/d/1BQORE-BTKDgXmuWPJDoV_tK5Bo2FH7kA},
  doi       = {10.1109/TAC.2006.872837},
  timestamp = {Wed, 20 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/tac/NiethammerTA06.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Visual tracking using active contours is usually set in a static framework. The active contour tracks the object of interest in a given frame of an image sequence. A subsequent prediction step ensures good initial placement for the next frame. This approach is unnatural; the curve evolution gets decoupled from the actual dynamics of the objects to be tracked. True dynamical approaches exist, all being marker particle based and thus prone to the shortcomings of such particle-based implementations. In particular, topological changes are not handled naturally in this framework. The now classical level set approach is tailored for evolutions of manifolds of codimension one. However, dynamic curve evolution is at least a codimension two problem. We propose an efficient, level set based approach for dynamic curve evolution, which addresses the artificial separation of segmentation and prediction while retaining all the desirable properties of the level set formulation. It is based on a new energy minimization functional which, for the first time, puts dynamics into the geodesic active contour framework.},
  keywords = {TAC,curves}
}

@article{DBLP:journals/tip/NiethammerKMT06,
  author    = {Marc Niethammer and
               William D. Kalies and
               Konstantin Mischaikow and
               Allen R. Tannenbaum},
  title     = {On the detection of simple points in higher dimensions using cubical homology},
  journal   = {{IEEE} Trans. Image Process.},
  volume    = {15},
  number    = {8},
  pages     = {2462--2469},
  year      = {2006},
  url       = {https://drive.google.com/file/d/1DV2LNmx2UYGpzZ-1UzML_HniAZbwpeLc},
  doi       = {10.1109/TIP.2006.877309},
  timestamp = {Sun, 10 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/journals/tip/NiethammerKMT06.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Simple point detection is an important task for several problems in discrete geometry, such as topology preserving thinning in image processing to compute discrete skeletons. In this paper, the approach to simple point detection is based on techniques from cubical homology, a framework ideally suited for problems in image processing. A (d-dimensional) unitary cube (for a d-dimensional digital image) is associated with every discrete picture element, instead of a point in /spl epsi//sup d/ (the d- dimensional Euclidean space) as has been done previously. A simple point in this setting then refers to the removal of a unitary cube without changing the topology of the cubical complex induced by the digital image. The main result is a characterization of a simple point p (i.e., simple unitary cube) in terms of the homology groups of the (3/sup d/-1) neighborhood of p for arbitrary, finite dimensions d.},
  keywords = {TIP,topology}
}

@inproceedings{DBLP:conf/miccai/NiethammerBWS06,
  author    = {Marc Niethammer and
               Sylvain Bouix and
               Carl{-}Fredrik Westin and
               Martha Elizabeth Shenton},
  editor    = {Rasmus Larsen and
               Mads Nielsen and
               Jon Sporring},
  title     = {Fiber Bundle Estimation and Parameterization},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention - {MICCAI}
               2006, 9th International Conference, Copenhagen, Denmark, October 1-6,
               2006, Proceedings, Part {II}},
  series    = {Lecture Notes in Computer Science},
  volume    = {4191},
  pages     = {252--259},
  publisher = {Springer},
  year      = {2006},
  url       = {https://drive.google.com/file/d/1HA9bI5Nff6RzO2tQnHDWhRidS_GDxGkw},
  doi       = {10.1007/11866763\_31},
  timestamp = {Sat, 30 May 2020 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/conf/miccai/NiethammerBWS06.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Individual white matter fibers cannot be resolved by current magnetic resonance (MR) technology. Many fibers of a fiber bundle will pass through an individual volume element (voxel). Individual visualized fiber tracts are thus the result of interpolation on a relatively coarse voxel grid, and an infinite number of them may be generated in a given volume by interpolation. This paper aims at creating a level set representation of a fiber bundle to describe this apparent continuum of fibers. It further introduces a coordinate system warped to the fiber bundle geometry, allowing for the definition of geometrically meaningful fiber bundle measures.},
  keywords = {MICCAI,diffusion,brain}
}

@inproceedings{DBLP:conf/miigp/PichonNN06,
  author    = {Eric Pichon and
               Delphine Nain and
               Marc Niethammer},
  editor    = {Kevin R. Cleary and
               Robert L. Galloway Jr.},
  title     = {A Laplace equation approach for shape comparison},
  booktitle = {Medical Imaging 2006: Visualization, Image-Guided Procedures, and
               Display, San Diego, California, United States, 11-16 February 2006},
  series    = {{SPIE} Proceedings},
  volume    = {6141},
  pages     = {614119},
  publisher = {{SPIE}},
  year      = {2006},
  url       = {https://drive.google.com/file/d/1hHBu7xGEMsaTOkOCVJ6cI8I0bIXMRwfc},
  doi       = {10.1117/12.651135},
  timestamp = {Fri, 25 May 2018 12:25:22 +0200},
  biburl    = {https://dblp.org/rec/conf/miigp/PichonNN06.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper we propose a principled approach for shape comparison. Given two surfaces, one to one correspondences are determined using the Laplace equation. The distance between corresponding points is then used to define both global and local dissimilarity statistics between the surfaces. This technique provides a powerful method to compare shapes both locally and globally for the purpose of segmentation, registration or shape analysis. For improved accuracy, we propose a Boundary Element Method. Our approach is applicable to datasets of any dimension and offers subpixel resolution. We illustrate the usefulness of the technique for validation of segmentation, by defining global dissimilarity statistics and visualizing errors locally on color-coded surfaces. We also show how our technique can be applied to multiple shapes comparison.},
  keywords = {SPIE,shape,brain}
}

@article{DBLP:journals/ijcv/NiethammerVT05,
  author    = {Marc Niethammer and
               Patricio A. Vela and
               Allen R. Tannenbaum},
  title     = {On the Evolution of Vector Distance Functions of Closed Curves},
  journal   = {Int. J. Comput. Vis.},
  volume    = {65},
  number    = {1-2},
  pages     = {5--27},
  year      = {2005},
  url       = {https://drive.google.com/file/d/1uAIrP1SkJV5Xd27yDMYq0FV_58OymYqB},
  doi       = {10.1007/s11263-005-3849-9},
  timestamp = {Fri, 13 Mar 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/ijcv/NiethammerVT05.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Inspired by the work by Gomes et al., we describe and analyze a vector distance function approach for the implicit evolution of closed curves of codimension larger than one. The approach is set up in complete generality, and then applied to the evolution of dynamic geometric active contours in  (codimension three case). In order to carry this out one needs an explicit expression for the zero level set for which we propose a discrete connectivity method. This leads us to make connections with the new theory of cubical homology. We provide some explicit simulation results in order to illustrate the methodology.},
  keywords = {IJCV,curves}
}

@phdthesis{DBLP:phd/basesearch/Niethammer04,
  author    = {Marc Niethammer},
  title     = {Dynamic Level Sets for Visual Tracking},
  school    = {Georgia Institute of Technology, Atlanta, GA, {USA}},
  year      = {2004},
  url       = {http://hdl.handle.net/1853/7606},
  timestamp = {Thu, 16 Mar 2017 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/phd/basesearch/Niethammer04.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  keywords = {curves}
}

@article{DBLP:journals/ijcv/NiethammerBSTG04,
  author    = {Marc Niethammer and
               Santiago Betel{\'{u}} and
               Guillermo Sapiro and
               Allen R. Tannenbaum and
               Peter J. Giblin},
  title     = {Area-Based Medial Axis of Planar Curves},
  journal   = {Int. J. Comput. Vis.},
  volume    = {60},
  number    = {3},
  pages     = {203--224},
  year      = {2004},
  url       = {https://drive.google.com/file/d/1P-SRVDXaZFn_EfOCy8193KRhsudZwvdg},
  doi       = {10.1023/B:VISI.0000036835.28674.d0},
  timestamp = {Fri, 13 Mar 2020 00:00:00 +0100},
  biburl    = {https://dblp.org/rec/journals/ijcv/NiethammerBSTG04.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {A new definition of affine invariant medial axis of planar closed curves is introduced. A point belongs to the affine medial axis if and only if it is equidistant from at least two points of the curve, with the distance being a minimum and given by the areas between the curve and its corresponding chords. The medial axis is robust, eliminating the need for curve denoising. In a dynamical interpretation of this affine medial axis, the medial axis points are the affine shock positions of the affine erosion of the curve. We propose a simple method to compute the medial axis and give examples. We also demonstrate how to use this method to detect affine skew symmetry in real images.},
  keywords = {IJCV,curves}
}

@inproceedings{DBLP:conf/cvpr/NiethammerT04,
  author    = {Marc Niethammer and
               Allen R. Tannenbaum},
  title     = {Dynamic Geodesic Snakes for Visual Tracking},
  booktitle = {2004 {IEEE} Computer Society Conference on Computer Vision and Pattern
               Recognition {(CVPR} 2004), with CD-ROM, 27 June - 2 July 2004, Washington,
               DC, {USA}},
  pages     = {660--667},
  publisher = {{IEEE} Computer Society},
  year      = {2004},
  url       = {https://drive.google.com/file/d/1Ce6lLZJDE7eVAuCu-Yim-ozeC5fOV2Vd},
  doi       = {10.1109/CVPR.2004.86},
  timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/NiethammerT04.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {Visual tracking using active contours is usually accomplished in a static framework. The active contour tracks the object of interest in a given frame of an image sequence, and then a subsequent prediction step ensures good initial placement for the next frame. This approach is unnatural; the curve evolution gets decoupled from the actual dynamics of the objects to be tracked. True dynamic approaches exist, all being marker particle based, and thus prone to the shortcomings of such particle-based implementations. In particular, topological changes are not handled naturally in this framework. The now ”classical” level set approach is tailored for codimension one evolutions. However, dynamic curve evolution is at least of codimension two. We propose a natural, efficient, level set based approach for dynamic curve evolution which removes the artificial separation of segmentation and prediction, while retaining all the desirable properties of level set formulations. This is based on a new energy minimization functional which for the first time puts dynamics into the geodesic active contour framework.},
  keywords = {CVPR,curves}
}

@inproceedings{DBLP:conf/icip/PichonNS03,
  author    = {Eric Pichon and
               Marc Niethammer and
               Guillermo Sapiro},
  title     = {Color histogram equalization through mesh deformation},
  booktitle = {Proceedings of the 2003 International Conference on Image Processing,
               {ICIP} 2003, Barcelona, Catalonia, Spain, September 14-18, 2003},
  pages     = {117--120},
  publisher = {{IEEE}},
  year      = {2003},
  url       = {https://drive.google.com/file/d/1YK_ANg-Os7gAXog48sX0lU0yK9TEr_nV},
  doi       = {10.1109/ICIP.2003.1246630},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/icip/PichonNS03.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper we propose an extension of grayscale histogram equalization for color images. For aesthetic reasons, previously proposed color histogram equalization techniques do not generate uniform color histograms. Our method will always generate an almost uniform color histogram thus making an optimal use of the color space. This is particularly interesting for pseudo-color scientific visualization. The method is based on deforming a mesh in color space to fit the existing histogram and then map it to a uniform histogram. It is a natural extension of grayscale histogram equalization and it can be applied to spatial and color space of any dimension.},
  keywords = {ICIP}
}

@inproceedings{DBLP:conf/icip/NiethammerPTM03,
  author    = {Marc Niethammer and
               Eric Pichon and
               Allen R. Tannenbaum and
               Peter J. Mucha},
  title     = {A stokes flow boundary integral measurement of tubular structure cross
               sections in two dimensions},
  booktitle = {Proceedings of the 2003 International Conference on Image Processing,
               {ICIP} 2003, Barcelona, Catalonia, Spain, September 14-18, 2003},
  pages     = {825--828},
  publisher = {{IEEE}},
  year      = {2003},
  url       = {https://drive.google.com/file/d/1TNS5qQV28KyU4o-iAW9PEvVBq6fGhAFS},
  doi       = {10.1109/ICIP.2003.1247090},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/icip/NiethammerPTM03.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {In this paper we will develop a method to determine cross sections of arbitrary two-dimensional tubular structures, which are allowed to branch, by means of a Stokes flow based boundary integral formulation. The measure for the cross sections for a point on the boundary of a given structure will be the path obtained by integrating perpendicularly to the flow lines from one side of the boundary to the other. Special emphasis will be put on the behavior at branching points, the behavior at vortices, and the necessary boundary conditions. The method can be extended to three dimensional problems.},
  keywords = {ICIP,flow,shape}
}

@inproceedings{DBLP:conf/icip/MischaikowPKNST02,
  author    = {Konstantin Mischaikow and
               Pawel Pilarczyk and
               William D. Kalies and
               Marc Niethammer and
               Andrew Stein and
               Allen R. Tannenbaum},
  title     = {Analysis of blood vessel topology by cubical homology},
  booktitle = {Proceedings of the 2002 International Conference on Image Processing,
               {ICIP} 2002, Rochester, New York, USA, September 22-25, 2002},
  pages     = {969--972},
  publisher = {{IEEE}},
  year      = {2002},
  url       = {https://drive.google.com/file/d/16B_ho8KSYer_dvoIwBjLpeZumMzxb3TM},
  doi       = {10.1109/ICIP.2002.1040114},
  timestamp = {Wed, 16 Oct 2019 14:14:52 +0200},
  biburl    = {https://dblp.org/rec/conf/icip/MischaikowPKNST02.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  abstract = {We segment and topologically classify brain vessel data obtained from magnetic resonance angiography (MRA). The segmentation is done adaptively and the classification by means of cubical homology, i.e. the computation of homology groups. In this way the number of connected components; (measured by H/sub 0/), the tunnels (given by H/sub 1/) and the voids (given by H/sub 2/) are determined, resulting in a topological characterization of the blood vessels.},
  keywords = {ICIP,topology,brain}
}

