@article{DBLP:journals/corr/abs-2002-04805,
 abstract = {We study regularization in the context of small sample-size learning with over-parameterized neural networks. Specifically, we shift focus from architectural properties, such as norms on the network weights, to properties of the internal representations before a linear classifier. Specifically, we impose a topological constraint on samples drawn from the probability measure induced in that space. This provably leads to mass concentration effects around the representations of training instances, ie, a property beneficial for generalization. By leveraging previous work to impose topological constraints in a neural network setting, we provide empirical evidence (across various vision benchmarks) to support our claim for better generalization.},
 archiveprefix = {arXiv},
 author = {Christoph D. Hofer and
Florian Graf and
Marc Niethammer and
Roland Kwitt},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/corr/abs-2002-04805.bib},
 eprint = {2002.04805},
 journal = {CoRR},
 timestamp = {Fri, 14 Feb 2020 00:00:00 +0100},
 title = {Topologically Densified Distributions},
 url = {https://arxiv.org/abs/2002.04805},
 volume = {abs/2002.04805},
 year = {2020}
}

