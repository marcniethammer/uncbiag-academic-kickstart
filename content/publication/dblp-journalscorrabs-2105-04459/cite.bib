@article{DBLP:journals/corr/abs-2105-04459,
 abstract = {Learning maps between data samples is fundamental. Applications range from representation learning, image translation and generative modeling, to the estimation of spatial deformations. Such maps relate feature vectors, or map between feature spaces. Well-behaved maps should be regular, which can be imposed explicitly or may emanate from the data itself. We explore what induces regularity for spatial transformations, e.g., when computing image registrations. Classical optimization-based models compute maps between pairs of samples and rely on an appropriate regularizer for well-posedness. Recent deep learning approaches have attempted to avoid using such regularizers altogether by relying on the sample population instead. We explore if it is possible to obtain spatial regularity using an inverse consistency loss only and elucidate what explains map regularity in such a context. We find that deep networks combined with an inverse consistency loss and randomized off-grid interpolation yield well behaved, approximately diffeomorphic, spatial transformations. Despite the simplicity of this approach, our experiments present compelling evidence, on both synthetic and real data, that regular maps can be obtained without carefully tuned explicit regularizers, while achieving competitive registration performance.},
 archiveprefix = {arXiv},
 author = {Hastings Greer and
Roland Kwitt and
Fran√ßois-Xavier Vialard and
Marc Niethammer},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/corr/abs-2105-04459.bib},
 eprint = {2105.04459},
 journal = {CoRR},
 keywords = {deep learning,knee,registration,ICCV},
 timestamp = {Fri, 14 May 2021 12:13:30 +0200},
 title = {ICON: Learning Regular Maps Through Inverse Consistency},
 url = {https://drive.google.com/file/d/1kaqRx9DXqB4ksDZ1ztuCKETVN9s8F8lg},
 volume = {abs/2105.04459},
 year = {2021}
}

